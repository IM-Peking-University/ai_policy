1. AI Authorship Large Language Models (LLMs), such as ChatGPT, do not currently satisfy our authorship criteria. Notably an attribution of authorship carries with it accountability for the work, which cannot be effectively applied to LLMs. Use of an LLM should be properly documented in the Methods section (and if a Methods section is not available, in a suitable alternative part) of the manuscript. The use of an LLM (or other AI-tool) for “AI assisted copy editing” purposes does not need to be declared. In this context, we define the term ""AI assisted copy editing"" as AI-assisted improvements to human-generated texts for readability and style, and to ensure that the texts are free of errors in grammar, spelling, punctuation and tone. These AI-assisted improvements may include wording and formatting changes to the texts, but do not include generative editorial work and autonomous content creation. In all cases, there must be human accountability for the final version of the text and agreement from the authors that the edits reflect their original work.  Generative AI Images The fast moving area of generative AI image creation has resulted in novel legal copyright and research integrity issues. As publishers, we strictly follow existing copyright law and best practices regarding publication ethics. While legal issues relating to AI-generated images and videos remain broadly unresolved, Springer Nature journals are unable to permit its use for publication.   Exceptions:  Images/art obtained from agencies that we have contractual relationships with that have created images in a legally acceptable manner. Images and videos that are directly referenced in a piece that is specifically about AI and such cases will be reviewed on a case-by-case basis. The use of generative AI tools developed with specific sets of underlying scientific data that can be attributed, checked and verified for accuracy, provided that ethics, copyright and terms of use restrictions are adhered to. *All exceptions must be labelled clearly as generated by AI within the image field.  As we expect things to develop rapidly in this field in the near future, we will review this policy regularly and adapt it if necessary.  Please note: Not all AI tools are generative. The use of non-generative machine learning tools to manipulate, combine or enhance existing images or figures should be disclosed in the relevant caption upon submission to allow a case-by-case review. AI use by peer reviewers Peer reviewers play a vital role in scientific publishing. Their expert evaluations and recommendations guide editors in their decisions and ensure that published research is valid, rigorous, and credible. Editors select peer reviewers primarily because of their in-depth knowledge of the subject matter or methods of the work they are asked to evaluate. This expertise is invaluable and irreplaceable. Peer reviewers are accountable for the accuracy and views expressed in their reports, and the peer review process operates on a principle of mutual trust between authors, reviewers and editors. Despite rapid progress, generative AI tools have considerable limitations: they can lack up-to-date knowledge and may produce nonsensical, biased or false information. Manuscripts may also include sensitive or proprietary information that should not be shared outside the peer review process. For these reasons we ask that, while Springer Nature explores providing our peer reviewers with access to safe AI tools, peer reviewers do not upload manuscripts into generative AI tools. If any part of the evaluation of the claims made in the manuscript was in any way supported by an AI tool, we ask peer reviewers to declare the use of such tools transparently in the peer review report."
2. The use of artificial intelligence (AI) tools such as ChatGPT or Large Language Models in research publications is expanding rapidly. COPE joins organisations, such as WAME and the JAMA Network among others, to state that AI tools cannot be listed as an author of a paper.  AI tools cannot meet the requirements for authorship as they cannot take responsibility for the submitted work. As non-legal entities, they cannot assert the presence or absence of conflicts of interest nor manage copyright and license agreements.  Authors who use AI tools in the writing of a manuscript, production of images or graphical elements of the paper, or in the collection and analysis of data, must be transparent in disclosing in the Materials and Methods (or similar section) of the paper how the AI tool was used and which tool was used. Authors are fully responsible for the content of their manuscript, even those parts produced by an AI tool, and are thus liable for any breach of publication ethics."
3. Generative Artificial Intelligence tools (GenAI)—such as ChatGPT and others based on large language models (LLMs)—can increase productivity and foster innovation if used appropriately in a safe, ethical and secure manner. STM has general guidance for all stakeholders in scholarly publishing which addresses the role of generative AI technologies. If an author has used a GenAI tool to develop any portion of a manuscript, its use must be described, transparently and in detail, in the Methods section (or via a disclosure or within the Acknowledgements section, as applicable). The author is fully responsible for the accuracy of any information provided by the tool and for correctly referencing any supporting work on which that information depends. GenAI tools must not be used to create, alter or manipulate original research data and results. Tools that are used to improve spelling, grammar, and general editing are not included in the scope of these guidelines. The final decision about whether use of a GenAI tool is appropriate or permissible in the circumstances of a submitted manuscript or a published article lies with the journal’s editor or other party responsible for the publication’s editorial policy.GenAI tools cannot be considered capable of initiating an original piece of research without direction by humans. Tools cannot be accountable for a published work or for research design, which is a generally held requirement of authorship (as discussed in the Authorship section in these guidelines), nor does it have legal standing or the ability to hold or assign copyright. Therefore—in accordance with COPE’s position statement on Authorship and AI tools—these tools cannot fulfil the role of, nor be listed as, an author of an article.GenAI tools should be used only on a limited basis in connection with peer review. A GenAI tool can be used by an editor or peer reviewer to improve the quality of the written feedback in a peer review report. This use must be transparently declared upon submission of the peer review report to the manuscript’s handling editor. Independent of this limited use case, editors or peer reviewers should not upload manuscripts (or any parts of manuscripts including figures and tables) into GenAI tools or services. GenAI tools may use input data for training or other purposes, which could violate the confidentiality of the peer review process, privacy of authors and reviewers, and the copyright of the manuscript under review. Moreover, the peer review process is a human endeavor and responsibility and accountability for submitting a peer review report, in line with a journal’s editorial polices and peer review model, sits with those individuals who have accepted an invitation from a journal to undertake the peer review of a submitted manuscript. This process should not be delegated to a GenAI tool. "
4. The use of AI tools (e.g. large language models, machine learning, or similar tools) must be disclosed at the time of submission as well as in the “Other disclosures” section of the manuscript’s structured disclosures. Basic tools used for checking grammar, spelling, references, etc., do not need to be disclosed. Please include a description of the content that was created or edited with the tool, as well as the name and manufacturer of the tool used. In addition, authors must include in the body of the manuscript a similar description of how they used AI tools in their work and which tools they used. In Research Reports or Reviews, this description would appear in the Method section; in other types of articles, it should be incorporated to best suit the structure of the article. Although the use of AI tools in scholarly work is not prohibited, authors should avoid including AI-generated images in their submissions (exceptions may be requested by emailing the editorial office at academicmedicine@aamc.org and will be considered on a case-by-case basis).  ​AI tools may not be listed or designated as authors. Authors are accountable for the quality and integrity of their scholarly work. Authors of the manuscript are fully responsible for the entirety of its contents, including those parts produced by an AI tool.​"
5. Declaration of generative AI in scientific writing The below guidance only refers to the writing process, and not to the use of AI tools to analyse and draw insights from data as part of the research process.  Where authors use generative artificial intelligence (AI) and AI-assisted technologies in the writing process, authors should only use these technologies to improve readability and language. Applying the technology should be done with human oversight and control, and authors should carefully review and edit the result, as AI can generate authoritative-sounding output that can be incorrect, incomplete or biased. AI and AI-assisted technologies should not be listed as an author or co-author, or be cited as an author. Authorship implies responsibilities and tasks that can only be attributed to and performed by humans, as outlined in Elsevier's AI policy for authors.  Authors should disclose in their manuscript the use of AI and AI-assisted technologies in the writing process by following the instructions below. A statement will appear in the published work. Please note that authors are ultimately responsible and accountable for the contents of the work.  Disclosure instructions  Authors must disclose the use of generative AI and AI-assisted technologies in the writing process by adding a statement at the end of their manuscript in the core manuscript file, before the References list. The statement should be placed in a new section entitled 'Declaration of Generative AI and AI-assisted technologies in the writing process'  Statement: During the preparation of this work the author(s) used [NAME TOOL / SERVICE] in order to [REASON]. After using this tool/service, the author(s) reviewed and edited the content as needed and take(s) full responsibility for the content of the publication  This declaration does not apply to the use of basic tools for checking grammar, spelling, references etc. If there is nothing to disclose, there is no need to add a statement.  Author certify that the submitted article will not constitute ""Redundant Publication"". The Council of Science Editors defines redundant publication as ""reporting (publishing or attempting to publish) substantially the same work more than once, without attribution of the original source(s): (CBE Views 1996;19(4):76-77). Characteristics of reports that are substantially similar include (a) ""at least one of the authors must be common to all reports (if there are no common authors, it is more likely plagiarism than redundant publication)""; (b) ""the subject or study populations are often the same or similar""; (c) ""the methodology is typically identical or nearly so""; and (d) "" the results and their interpretation generally vary little, if at all."""
6. AOM Artificial Intelligence (AI) Policy The AOM has adopted an AI Policy at the point of submission for journals and the Annual Meeting.  This policy is consistent with the Committee on Publication Ethics (C.O.P.E) position statement on AI.  Artificial Intelligence: Work submitted to AOM must be created by the authors and not the product of artificial intelligence tools unless appropriate to the research question and properly cited.  AOM AI Policy Highlights AI tools cannot be listed as an author of a paper. AI tools cannot be used as a resource in reviewing a paper. Use of AI tools are only allowed to support the following: Spelling Grammar Data Collection/Analysis For AOM Journal Submissions: Authors must be transparent in disclosing any AI use in the manuscript cover letter and in the article acknowledgements. Effective Immediately.  For AOM Meeting Submissions: Authors must be transparent in disclosing any AI use on the title page (first page) of the uploaded manuscript. Effective with submissions to the 2025 Annual Meeting.  This policy may evolve further as we work with our publishing partners to understand how emerging technologies can help or hinder the process of preparing research for publication. Please visit the AOM.org author resources page for updates and the latest information.  AOM recognizes the value of large language models (LLMs) (e.g., ChatGPT) and generative AI as productivity tools that can assist authors in preparing their article for submission; to generate initial ideas for a structure, or when summarizing, paraphrasing, language polishing etc. However, it is important to note that all language models have limitations and are unable to replicate human creative and critical thinking. Human intervention with these tools is essential to ensure that content presented is accurate and appropriate to the reader. Therefore the AOM requires authors to be aware of the limitations of language models when submitting or reviewing for the AOM.  Guidance for Authors Authors are required to:  Notify AOM of any AI use as part of the manuscript submission process (as outlined above).  Clearly indicate the use of language models in the manuscript cover letter and acknowledgements (for journal submissions) or on the manuscript title page (for Annual Meeting submissions), including which model was used and for what purpose.   Verify the accuracy, validity, and appropriateness of the content and any citations generated by language models and correct any errors or inconsistencies. Provide a list of sources used to generate content and citations, including those generated by language models.   Be conscious of the potential for plagiarism where the LLM may have reproduced substantial text from other sources. Check the original sources to be sure you are not plagiarizing someone else’s work. Acknowledge the limitations of language models in the manuscript, including the potential for bias, errors, and gaps in knowledge. Citations: Authors should cite their AI use as outlined within the Chicago Manual of style. See https://www.chicagomanualofstyle.org/qanda/data/faq/topics/Documentation/faq0422.html We will take appropriate corrective action where we identify published articles with undisclosed use of such tools.  Guidance for Editors and Reviewers Editors and reviewers should evaluate the appropriateness of the use of AI and ensure that the generated content is accurate and valid.  Editors and Reviewers must uphold the confidentiality of the peer review process. Editors must not share information about submitted manuscripts or peer review reports with generative AI or LLMs such as ChatGPT.  Reviewers must not use artificial intelligence tools to generate review reports, including but not limited to ChatGPT.  This policy may evolve further as we work with our publishing partners to understand how emerging technologies can help or hinder the process of preparing research for publication.  Please visit the AOM.org author resources page for updates and the latest information."
7. Declaration of generative AI in scientific writing Authors must declare the use of generative AI in scientific writing upon submission of the paper. The following guidance refers only to the writing process, and not to the use of AI tools to analyse and draw insights from data as part of the research process:  Generative AI and AI-assisted technologies should only be used in the writing process to improve the readability and language of the manuscript.  The technology must be applied with human oversight and control and authors should carefully review and edit the result, as AI can generate authoritative-sounding output that can be incorrect, incomplete or biased. Authors are ultimately responsible and accountable for the contents of the work.  Authors must not list or cite AI and AI-assisted technologies as an author or co-author on the manuscript since authorship implies responsibilities and tasks that can only be attributed to and performed by humans.  The use of generative AI and AI-assisted technologies in scientific writing must be declared by adding a statement at the end of the manuscript when the paper is first submitted. The statement will appear in the published work and should be placed in a new section before the references list. An example:  Title of new section: Declaration of generative AI and AI-assisted technologies in the writing process.  Statement: During the preparation of this work the author(s) used [NAME TOOL / SERVICE] in order to [REASON]. After using this tool/service, the author(s) reviewed and edited the content as needed and take(s) full responsibility for the content of the published article.  The declaration does not apply to the use of basic tools, such as tools used to check grammar, spelling and references. If you have nothing to disclose, you do not need to add a statement.  Please read Elsevier’s author policy on the use of generative AI and AI-assisted technologies, which can be found in our GenAI Policies for journals.  Please note: to protect authors’ rights and the confidentiality of their research, this journal does not currently allow the use of generative AI or AI-assisted technologies such as ChatGPT or similar services by reviewers or editors in the peer review and manuscript evaluation process, as is stated in our GenAI Policies for journals. We are actively evaluating compliant AI tools and may revise this policy in the future."
8. Use of Generative AI and AI-Assisted Technology Definitions This policy refers to generative AI and AI-assisted technologies, such as Large Language Models, when they are used during the scientific writing process. This policy does not refer to spelling and grammar checker tools (e.g., Grammarly, Paperpal Preflight), which are tools that may be AI-assisted and are used to improve grammar and spelling. This policy does not refer to reference managers (e.g., Mendeley, EndNote), which are tools that may be AI-assisted that can be used to collect, organize, and use references to scholarly works. This policy does not refer to AI and AI-assisted tools used in the research design and analysis stage (e.g., machine learning) that can be used in the research process to create, collect, analyze and process data. Policy for Authors It is the collective expectation of the scholarly community that authors are the original source of any written scholarly work, except as appropriately cited. Except as noted herein, authors may use generative AI and AI-assisted tools to assist with the generation of scholarly work, as long as they disclose the specific use(s) of the tool and the tool(s) used. The technology should be used with human oversight and control. Authors should carefully review and edit the output because AI can generate authoritative-sounding output that can be incorrect, incomplete, biased, or infringe on existing copyrights. Authors are accountable for all information contained in an article regardless of how it is produced, including ensuring that any AI tools used do not infringe on the copyright and other ownership rights of third parties.  Use of AI and AI-assisted writing tools must be consistent with the AAA policies on Authorship (https://aaahq.org/portals/0/documents/about/policies&proceduresmanual/aaapublicationsethicspolicy-authorship.pdf) and Plagiarism (https://aaahq.org/portals/0/documents/about/policies&proceduresmanual/plagiarismpolicy.pdf).  Authors need to disclose the use of AI and AI-assisted tools in their work. Disclosure supports transparency among authors, reviewers, editors, and readers of the work. The use of AI and AI-assisted technologies in research design and analysis should be described as part of the methodology of the work. The use of AI and AI-assisted tools for uses other than research design and analysis is disclosed at the end of the manuscript in a separate section, immediately before the reference section of the paper. This section is titled “Declaration of Generative AI and AI-Assisted Technologies in the Writing Process.” In that statement, the authors should specify the tool(s) used, the extent of use, and the reason(s) for using the tool(s). We suggest that authors use the following format when preparing their statement:  During the preparation of this work, the author(s) used [NAME TOOL/SERVICE] in order to [EXTENT/REASON]. After using this tool/service, the author(s) reviewed and edited the content as needed and take(s) full responsibility for the content of the publication. Authors should not list AI or AI-assisted tools as an author or co-author or cite AI or AI-assisted tools as authors. Authorship implies a willingness to assume responsibility for the study.  Note that the use of spelling and grammar checking tools and reference manager tools, which may rely on AI or AI-assisted technologies, does not require disclosure. However, use of AI or AI-assisted technologies (e.g., ChatGPT) to check spelling or grammar requires disclosure, since these tools are not limited in the scope of their output.  Exceptions We do not permit the use of AI or AI-assisted tools to create or alter images in submitted manuscripts. Images are representations or likenesses of objects, people, or scenes, typically captured through photography, artwork, or other visual mediums, but do not include data-driven visualizations such as author-created graphs, charts, infographics, or plots. It is not acceptable to enhance, obscure, move, remove, or introduce a specific feature within an image. Adjustments of existing images (which must be cited) for brightness, contrast, or color balance are acceptable if and as long as they do not obscure or eliminate any information present in the original. Manipulating images for improved clarity is accepted, but manipulation for other purposes could be seen as scientific ethical abuse and will be dealt with accordingly.  The only exception is if the use of AI or AI-assisted tools in the creation or alteration of images is part of the research design or research methods. If this is done, we require a clear description of the content that was created or altered, an explanation of how the AI or AI-assisted tools were used in the creation or alteration process, and the name of the model or tool, version and extension numbers, and manufacturer.  Preventative Actions This AI use policy and all other publication policies will be prominently displayed on all AAA journal websites and notices of changes emailed to all members.  The submission process for all AAA journals will include a summary of the policy.  Did you use generative AI to help write this manuscript? If you used generative AI or AI-assisted technology, include the following statement directly before the references at the end of your manuscript.  Declaration of Generative AI and AI-Assisted Technologies in the Writing Process  During the preparation of this work the author(s) used [NAME TOOL/SERVICE] in order to [EXTENT/REASON]. After using this tool/service, the author(s) reviewed and edited the content as needed and take(s) full responsibility for the content of the publication.) Each author team is responsible for agreeing on what the team will disclose about the use of AI and AI-assisted technologies in a paper that is submitted for review and for ensuring that the work does not infringe on third party rights. The paper must also comply with the AAA’s plagiarism policy.  Detailed Process, Suspected Undisclosed Use of AI in a Submission An editor who learns of possible undisclosed use of AI or AI-assisted technologies or other failures to comply with this policy (e.g., failure to adequately review AI output) from either a reviewer, an editorial assistant, or other sources will be responsible for reviewing the submitting author’s(s’) disclosures about AI use and evaluating the paper. If concerns remain after reviewing the evidence, the editor will contact the corresponding author, explain the concern, and ask for further clarification. The editor will also contact the AAA Publications Director and CEO to alert them to the situation. If the clarification is satisfactory, review of the paper will continue without prejudice.  If the editor determines that the manuscript contains undisclosed use of AI, but this issue is not extensive, the editor may send a written request to the author(s) and identify the disclosure that needs to be added before the manuscript can be considered further. The editor will copy the AAA Publications Director and CEO on the correspondence.  If the editor concludes the additional disclosure is insufficient and the author(s) is(are) unwilling to change the disclosure further, the editor will communicate in writing to the manuscript’s author(s) that the review process is suspended. The editor will provide a copy of this correspondence to the AAA Publications Director and CEO.  Detailed Process, Suspected Undisclosed Use of AI in a Published Article The corrective action(s) that may be taken if an editor becomes aware of suspected undisclosed use of AI in an article published after the enactment of this policy will require the same evidence-gathering process and notification of the AAA CEO and Publications Director. The corrective actions may also include publication of an erratum statement, an expression of concern, or a retraction.  Policy for Reviewers and Editors It is the collective expectation of the scholarly community that reviewing a manuscript or making an editorial decision implies responsibilities that can only be attributed to humans. The critical thinking and assessment required for peer-review are outside the scope of generative AI and AI-assisted technologies, and there is a risk that the technology will generate incorrect, incomplete, or biased conclusions. These considerations, together with the principle that submitted manuscripts are to be treated as confidential documents, underpins our AI and AI-assisted tools use policies for reviewers and editors.  The AAA policy embraces new AI-driven technologies that support reviewers and editors in the editorial process, such as those used during the screening process to conduct completeness and plagiarism checks and identify suitable reviewers. These identity-protected technologies conform to the RELX Responsible AI Principles. Our policy states that:  Reviewers or editors may use generative AI and AI-assisted tools to assist with the evaluation of a manuscript as long as the use of these tools is not the sole basis for the review or editorial decision. Appropriate uses include outlining or preparing independent literature reviews to assist in evaluating the paper. Reviewers must review the output of any tools used for accuracy. Reviewers or editors should not upload the manuscript or any part of it into a generative AI or AI-assisted tool unless the tool follows the RELX Responsible AI principles, guarantees anonymity, and does not use the material for future model training. Reviewers are responsible for ensuring that any AI or AI-assisted tool used conforms to this guidance. This confidentiality requirement extends to the peer review report and any other communication about the manuscript, such as decision letters or the decision notification, as they may also contain confidential information about the manuscript and/or the authors. Reviewers should disclose to editors whether and how they have used AI and AI-assisted tools to assist in preparing their review report. The human reviewer and editor take final responsibility for the content of their review report, publication recommendation for a manuscript, and/or decision letter. We will continue to develop and adopt in-house or licensed technologies that can assist editors and reviewers while respecting confidentiality and proprietary and data privacy rights.   Preventative Actions This AI use policy and all other publication policies will be prominently displayed on all AAA journal websites and notices of changes emailed to all members.  This AI use policy will be summarized in all reviewer invitations from all AAA journals as:  While reviewers may use generative AI and AI-assisted tools to assist with the evaluation of manuscripts, the reviewer must review the output of these tools for accuracy. The human reviewer takes final responsibility for the content of their review and publication recommendation for a manuscript.  Reviewers should not upload the manuscript, any part of the manuscript, or the peer review report into a generative AI or AI-assisted tool unless the tool follows the RELX Responsible AI principles, guarantees anonymity, and does not use the material for future model training. Frequently Asked Questions (FAQs) Does this policy apply to education cases published in AAA journals? Yes, authors of all types of articles must disclose whether they have used AI or AI-assisted tools in the writing process. Does this policy require that authors disclose the use of AI or AI-assisted tools in the research or case writing process? Yes, use of these tools during the research or case writing process should be disclosed in the method section or in the discussion of case development and testing. Does the policy’s prohibition of AI-generated or AI-altered images apply to supplementary materials submitted with the manuscript that will not be published (e.g., experimental or survey instruments). No, materials that will not be published with the article are not prohibited from using AI-generated or AI-altered images."
9. Generative AI tools and technologies, such as ChatGPT, may not be listed as authors of an ACM published Work. The use of generative AI tools and technologies to create content is permitted but must be fully disclosed in the Work. For example, the authors could include the following statement in the Acknowledgements section of the Work: ChatGPT was utilized to generate sections of this Work, including text, tables, graphs, code, data, citations, etc.). If you are uncertain ­about the need to disclose the use of a particular tool, err on the side of caution, and include a disclosure in the acknowledgements section of the Work."
10. Artificial intelligence (AI) tools do not qualify for authorship. The use of AI tools for text or image generation should be disclosed in the manuscript within the Acknowledgment section with a description of when and how the tools were used. For more substantial use cases or descriptions of AI tool use, authors should provide full details within the Methods or other appropriate section of the manuscript."
11. Declaration of generative AI in scientific writing The below guidance only refers to the writing process, and not to the use of AI tools to analyse and draw insights from data as part of the research process.  Where authors use generative artificial intelligence (AI) and AI-assisted technologies in the writing process, authors should only use these technologies to improve readability and language. Applying the technology should be done with human oversight and control, and authors should carefully review and edit the result, as AI can generate authoritative-sounding output that can be incorrect, incomplete or biased. AI and AI-assisted technologies should not be listed as an author or co-author, or be cited as an author. Authorship implies responsibilities and tasks that can only be attributed to and performed by humans, as outlined in Elsevier's AI policy for authors.  Authors should disclose in their manuscript the use of AI and AI-assisted technologies in the writing process by following the instructions below. A statement will appear in the published work. Please note that authors are ultimately responsible and accountable for the contents of the work.  Disclosure instructions  Authors must disclose the use of generative AI and AI-assisted technologies in the writing process by adding a statement at the end of their manuscript in the core manuscript file, before the References list. The statement should be placed in a new section entitled 'Declaration of Generative AI and AI-assisted technologies in the writing process'  Statement: During the preparation of this work the author(s) used [NAME TOOL / SERVICE] in order to [REASON]. After using this tool/service, the author(s) reviewed and edited the content as needed and take(s) full responsibility for the content of the publication  This declaration does not apply to the use of basic tools for checking grammar, spelling, references etc. If there is nothing to disclose, there is no need to add a statement."
12. Use of large language models: As of February 15, 2023, the use of large language models (LLMs) including Chat Generative Pre-Trained Transformer (ChatGPT, OpenAI, San Francisco, CA, USA) are allowed by the Editorial office. Please read this editorial for further details. If authors submitting their work to ActaDV opt to use LLMs to help in the writing process, it is mandatory to state this in the Acknowledgements section. Please state the exact program used including how it was used. We would like to remind all submitting authors that textbook knowledge should consistently be avoided. It is essential that a balanced, unbiased, and accurate literature review is always responsibly compiled by the listed authors and must never be left to LLM. When utilizing LLMs in writing, their application should be limited to enhancing readability and language. LLMs should not supplant essential authoring responsibilities, such as generating scientific, educational, or medical insights, or drawing scientific conclusions. It is crucial to use these technologies under human supervision and to rigorously review and edit the resulting content. Content generated by LLMs may sound credible but can be erroneous, incomplete, or biased. The authors of a manuscript bear full responsibility and accountability for their work's content.  Importantly, authors must never assign authorship or co-authorship to LLMs or any other machine learning technologies. Authorship involves responsibilities and duties uniquely attributable to humans, including addressing questions regarding the work's accuracy and integrity, approving the final manuscript, and consenting to its submission. Authors must also ensure the originality of their work, and verify the qualifications for authorship of the listed authors."
13. Artificial Intelligence Generated Content (AIGC) tools—such as ChatGPT and others based on large language models (LLMs)—cannot be considered capable of initiating an original piece of research without direction by human authors. They also cannot be accountable for a published work or for research design, which is a generally held requirement of authorship (as discussed in the previous section), nor do they have legal standing or the ability to hold or assign copyright. Therefore—in accordance with COPE’s position statement on AI tools—these tools cannot fulfill the role of, nor be listed as, an author of an article. If an author has used this kind of tool to develop any portion of a manuscript, its use must be described, transparently and in detail, in the Methods or Acknowledgements section. The author is fully responsible for the accuracy of any information provided by the tool and for correctly referencing any supporting work on which that information depends. Tools that are used to improve spelling, grammar, and general editing are not included in the scope of these guidelines. The final decision about whether use of an AIGC tool is appropriate or permissible in the circumstances of a submitted manuscript or a published article lies with the journal’s editor or other party responsible for the publication’s editorial policy."
14. Sage recognizes the transformative potential of AI-powered writing assistants and tools such as ChatGPT. These technologies can support the writing and research process by providing authors with fresh ideas, alleviating writer's block, and optimizing editing tasks. While these tools can offer enhanced efficiency, it's also important to understand their limitations and to use them in ways which adhere to principles of academic and scientific integrity. As a publisher, Sage supports and believes in the value of human creativity and human authorship. Large Language Models (LLMs) cannot be listed as an author of a work, nor take responsibility for the text they generate. As such, human oversight, intervention and accountability is essential to ensure the accuracy and integrity of the content we publish.  We acknowledge that many academics and scholars are already using assistive and generative tools to enhance their productivity and assist in their academic writing. We have developed these guidelines to support authors submitting articles for Sage Journals, publishing books with Sage or Corwin, or working with us to create content for our Learning Resources products. The distinction between Assistive AI tools and Generative AI tools For the purposes of these guidelines, we distinguish between Assistive AI tools and Generative AI tools as follows: Assistive AI toolsAssistive AI tools make suggestions, corrections, and improvements to content you’ve authored yourself. Tools like Google's Gmail and Microsoft's Outlook and Word have offered to flag spelling or grammatical errors for many years. More recently, these assistive tools have introduced features to proactively make suggestions for the next word or phrase or to suggest better or more concise phrasing to improve clarity. Content that you've crafted on your own, but refined or improved with the help of this kind of Assistive AI tool is considered “AI-assisted”.Generative AI toolsThis term refers to tools such as ChatGPT or Dall-e which produce content, whether in the form of text, images, or translations. Even if you've made significant changes to the content afterwards, if an AI tool was the primary creator of the content, the content would be considered ""AI-generated”.Disclosure We believe that AI-assisted writing will become more common as AI tools are increasingly embedded within tools such as Microsoft Word and Google Docs. You are not required to disclose the use of assistive AI tools in your submission, but all content, including AI-assisted content, must undergo rigorous human review prior to submission. This is to ensure the content aligns with our standards for quality and authenticity.You are required to inform us of any AI-generated content appearing in your work (including text, images, or translations) when you submit any form of content to Sage or Corwin, including journal articles, manuscripts and book proposals. This will allow the editorial team to make an informed publishing decision regarding your submission.Where we identify published articles or content with undisclosed use of generative AI tools for content generation, we will take appropriate corrective action.Things to consider before using Generative AI toolsIf you do decide to use AI to generate content or images in your submission, you must follow these guidelines prior to submitting your work to Sage or Corwin. Disclosure: As outlined above you must clearly reveal any AI-generated content within your submission. Detail where the AI-generated content appears, using the disclosure template found at the end of these guidelines and provide this disclosure along with your submission.  Carefully verify the accuracy, validity, and appropriateness of AI-generated content or AI-produced citations: Large Language Models (LLMs) can sometimes ""hallucinate"" – producing incorrect or misleading information, especially when used outside of the domain of their training data or when dealing with complex or ambiguous topics. While their outputs may appear linguistically sound, they might not be scientifically accurate or correct and LLMs may produce nonexistent citations. Remember, some LLMs might only have been trained on data up to a specific year, potentially resulting in incorrect or incomplete knowledge of a topic.  Carefully check sources & citations: Offer a comprehensive list of resources utilized for content and citations, including those produced by AI. Meticulously cross-check citations for their accuracy to ensure proper referencing. Appropriately cite AI-generated content: Where you are including content generated by AI, appropriate citation should be included following the appropriate referencing convention. (For example, in Harvard style ChatGPT. 2023. San Francisco: OpenAI. ChatGPT: Microsoft Windows). Avoid plagiarism and copyright infringement: LLMs could inadvertently reproduce significant text chunks from existing sources without due citation, infringing others' intellectual property. As the work's author, you bear responsibility for confirming that there is no plagiarized content in your submission. Be aware of bias: Because LLMs have been trained on text that includes biases, and because there is inherent bias in AI tools because of human programming, AI-generated text may reproduce these biases, such as racism or sexism, or may overlook perspectives of populations that have been historically marginalized. Relying on LLMs to generate text or images can inadvertently propagate these biases so you should carefully review all AI-generated content to ensure it’s inclusive, impartial, and appeals to a broad readership. Acknowledge limitations: In your submission, if you have included AI-generated content, you should appropriately acknowledge the constraints of LLMs, including the potential for bias, inaccuracies, and knowledge gaps. Take responsibility: AI tools like ChatGPT cannot be recognized as a co-author in your submission. As the author, you (and any co-authors) are entirely responsible for the work you submit.  Check for specific guidelines: If you are submitting an article to a Sage Journal, check the submission guidelines of your targeted journal, ensuring compliance with any AI-related policies they might have in place, as they may differ from these guidelines. Stay updated: Follow the latest developments in the debates around AI-generated content to ensure you understand the possible ramifications and ethical challenges of using AI-generated content in your submission. Prohibited use Do not use generative AI to artificially create or modify core research data.Never share any sensitive personal or proprietary information on an AI platform like ChatGPT as this may expose sensitive information or intellectual property to others. Any information that you share with AI tools like ChatGPT is collected for business purposes.Editors and Reviewers must uphold the confidentiality of the peer review process. Editors must not share information about submitted manuscripts or peer review reports in generative AI tools such a ChatGPT. Reviewers must not use AI tools, including but not limited to ChatGPT, to generate review reports.Further informationWorld Association of Medical Editors (WAME) recommendations on chat bots, ChatGPT and scholarly manuscripts(opens in a new tab).Committee on Publication Ethics (COPE)’s position statement on Authorship and AI tools(opens in a new tab).STM Whitepaper on Generative AI in Scholarly Communication(opens in a new tab).If you have questions on these guidelines or would like to discuss how you plan to use AI in your writing, please reach out to your Sage or Corwin editor or contact.  Template for disclosure of the use of Generative AI tools in your submission  Full title of your submission: Type of submission (e.g., research article, book chapter): Name of the Generative AI tool used: Brief description of how the tool was used in your writing process: Your full name:Your primary contact at Sage or Corwin:The name of the Generative AI Tool(s) used in your submission:(https://www.software.ac.uk/publication/how-cite-and-describe-software(opens in a new tab)) Rationale for AI use:Explain your reasoning for using AI and the tool(s) you selected. How it was used? What did you use AI to do? Final prompt given:Final response generated:Please include all of the prompts & responses used in your submission and indicate where in your submission the AI generated content appears.  "
15. Artificial Intelligence (AI) Authoring Tools: Authors who use AI tools in the writing of a manuscript, production of images or graphical elements of the paper, or in the collection and analysis of data, must be transparent in disclosing in the Materials and Methods (or similar section) of the paper how the AI tool was used and which tool was used. Authors are fully responsible for the content of their manuscript, even those parts produced by an AI tool, and are thus liable for any breach of publication ethics."
16. AI-based tools and technologies for content generation Authors must be aware that using AI-based tools and technologies for article content generation, e.g. large language models (LLMs), generative AI, and chatbots (e.g. ChatGPT), is not in line with our authorship criteria.  All authors are wholly responsible for the originality, validity and integrity of the content of their submissions. Therefore, LLMs and other similar types of tools do not meet the criteria for authorship.  Where AI tools are used in content generation, they must be acknowledged and documented appropriately in the authored work."
17. Appropriate use of Articial Intelligence (AI) in Published Research Mary Ann Liebert, publishers, Inc. understands that emerging computing methodologies and tools are critical parts of advancing research. The policies below will be reviewed and updated as technologies, best practices and ethical considerations in AI evolve. Transparency and Disclosure Liebert Journals require authors to disclose any use of AI systems in their research and manuscript preparation. Authors are required to provide descriptions of an AI system’s use in their Materials and Methods section. Include the name and version of the software, the date of the original use, and all relevant prompts, queries or cues that initiated the AI’s response. Potential biases and limitations of the outcomes of AI use should be discussed by the authors when presenting their results. Authorship and Contributions AI systems are not authors and should not be used or named as authors on a manuscript. Authorship of a scholarly work requires responsibility for the conduct of the research and the content of the written work created as a result of that research. The contributions of each author should be stated in the paper, noting their specic roles in the research and writing. An AI system used to generate any part of the content must be stated in the Methods section, as above. The listed authors are expected to review a nal text and accept responsibility for its accuracy. Peer Review All scholarly works considered for publication undergo thorough and rigorous peer review. Manuscripts with AIgenerated content are no exception. Reviewers will evaluate the rigor, methodology, and signicance of the research, considering the involvement of AI systems. Reviewers should consider the appropriateness of the use of AI tools when they assess the work, along with the authors’ discussion of their use. If any AI tools were used by the Reviewer in the process of preparing their comments, this must be acknowledged to the Editor as part of your report."
18. The use and declaration of AI and AI-assisted technologies in scientific writing  Where authors use artificial intelligence (AI) and AI-assisted technologies in the writing process, authors should:  Only use these technologies to improve readability and language, not to replace key researcher tasks such as interpreting data or drawing scientific conclusions.  Apply the technology with human oversight and control, and carefully review and edit the result, as AI can generate authoritative-sounding output that can be incorrect, incomplete or biased.  Not list AI and AI-assisted technologies as an author or co-author, or cite AI as an author. Authorship implies responsibilities and tasks that can only be attributed to and performed by humans, as outlined in  Elsevier’s AI policy for authors  Disclose in their manuscript the use of AI and AI-assisted technologies in the writing process by following the instructions below. A statement will appear in the published work. Please note that authors are ultimately responsible and accountable for the contents of the work."
19. Editors expect peer reviewers to adhere to high standards of professionalism in writing their reviews, which should be free of biased language. Reviewers are also expected to be as accurate as possible in their assessments and comments on the manuscripts so that both authors and editors can better define the course of action to be taken after the evaluations. Please note that papers or proposals that are sent out for review are confidential documents and should not be shared or discussed with anyone other than those involved in the peer review process. Sharing with third-party tools such as Large Language Models (for example, ChatGPT) would constitute a breach of confidentialityTreat text generated by AI as personal communication but include the date (not only the year) or include as an endnote; do not include in your references cited list."
20. When submitting papers for peer review, all authors must provide disclosure statements identifying potential conflicts of interest. If authors have nothing to disclose, they are obligated to submit a statement explicitly stating this. Disclosure statements should also include whether IRB approval was obtained for the project, and if not, state the reason(s). For published papers, a brief summary of potential conflicts of interest should appear in the acknowledgement footnote. The entire disclosure statement is posted with the paper on the journal's website. View the full Disclosure Policy."
21. Artificial intelligence technologies (AI), machine learning, and similar technologies, including chatbots like ChatGPT (Chat Generative Pretrained Transformer), have been used in the drafting of scientific manuscripts. Authors who choose to use this technology must disclose at the time of manuscript submission their use of AI, the type of AI utilized, and how they used AI. In addition, when incorporating AI-generated statements, authors must provide correct references in the established literature for all AI-generated items to ensure accuracy and appropriate attribution. AI technology does not qualify for authorship credit, since it cannot guarantee the veracity of the language generated, but its use must be acknowledged in the manuscript."
22. The use of automated assistive writing technologies and tools (commonly referred to as artificial intelligence or machine learning tools) is permitted provided that their use is documented and authors assume responsibility for the content. As with human-generated content, authors are responsible for the accuracy, validity, and originality of computer-generated content. Per ICMJE Authorship Criteria, automated assistive writing technologies do not qualify for authorship as they are unable to provide approval or consent for submission. Per ICMJE recommendations for writing assistance, these tools should be listed in the Acknowledgements; if involved in the research design, the tools should be documented in the Methods. For additional information, see the World Association of Medical Editor recommendations."
23. World Scientific recognizes that the use of artificial intelligence tools (AI) in academic research and writing is an evolving practice. AI-based tools and technologies include but are not limited to large language models (LLMs), generative AI, and chatbots (for example, ChatGPT). Authors are accountable for the originality and integrity of the content of their manuscript. In choosing to use AI tools, authors are expected to do so responsibly and in accordance with our editorial policies on authorship and principles of publishing ethics.  Therefore, World Scientific joins COPE to state that AI tools cannot be listed as an author of a paper as they cannot take responsibility for submitted work, and their use should be fully transparent.  Authors who use AI tools in the writing of a manuscript, production of images or graphical elements of the paper, or in the collection and analysis of data, must be transparent in disclosing in the Materials and Methods (or similar section such as acknowledgement section or introduction) of the paper on how the AI tool was used and which tool was used. The final decision about whether use of an AI generated content tool is appropriate or permissible in a submitted manuscript lies with the journal's editor or other party responsible for the publication's editorial policy."
24. Declaration of generative AI in scientific writing: The below guidance only refers to the writing process, and not to the use of AI tools to analyse and draw insights from data as part of the research process. Where authors use generative artificial intelligence (AI) and AI-assisted technologies in the writing process, authors should only use these technologies to improve readability and language. Applying the technology should be done with human oversight and control, and authors should carefully review and edit the result, as AI can generate authoritative-sounding output that can be incorrect, incomplete or biased. AI and AI-assisted technologies should not be listed as an author or co-author, or be cited as an author. Authorship implies responsibilities and tasks that can only be attributed to and performed by humans, as outlined in Elsevier’s AI policy for authors. Authors should disclose in their manuscript the use of AI and AI-assisted technologies in the writing process by following the instructions below. A statement will appear in the published work. Please note that authors are ultimately responsible and accountable for the contents of the work"
25. AJCC aligns with the positions of COPE and ICJME (International Committee of Medical Journal Editors) on the use of artificial intelligence (AI) in publication.  Artificial intelligence tools cannot be listed as authors because they cannot take responsibility for the submitted work, one of the requirements for authorship. Authors must disclose the use of AI in the development of their submission (eg, body of manuscript, tables, figures). If authors use AI in the development of the manuscript, they must fact check and cite all information generated by AI. "
26. Artificial Intelligence Policy: Use of AI in Manuscript Preparation  Images No data within an image may be enhanced, obscured, moved, removed, or introduced by digital manipulation or automated assistive image technologies and tools (commonly referred to as artificial intelligence or machine learning tools). This includes the use of touch-up tools, such as cloning and healing tools in Photoshop, or any feature that deliberately obscures manipulations.   Writing Use of AI writing tools must be disclosed at submission. This includes but is not limited to ChatGPT, Jasper AI, GoogleBard (LaMDA), Bing AI, DeepMind Sparrow, and Codewhisper. Please note this does not include EndNote, RefWorks, or Mendeley, or Microsoft Word grammar or spell check. The journal does not consider Artificial Intelligence authoring tools to meet the requirements for Authorship as recommended by the ICMJE. Authors who use AI tools in the writing of a manuscript, production of images or graphical elements of the paper, or in the collection and analysis of data, must be transparent in disclosing in the Materials and Methods (or similar section) of the paper how the AI tool was used and which tool was used. Authors are fully responsible for the content of their manuscript, even those parts produced by an AI tool, and are thus liable for any breach of publication ethics.  Plagiarism Detection: AJG is a member of CrossCheck by CrossRef and iThenticate. iThenticate is a plagiarism screening service that verifies the originality of content submitted before publication. iThenticate checks submissions against millions of published research papers, and billions of web content. Authors, researchers and freelancers can also use iThenticate to screen their work before submission by visiting www.ithenticate.com. If a case of plagiarism comes to light after a paper is published, the Journal will conduct a preliminary investigation, utilizing the guidelines of the Committee on Publication Ethics. If plagiarism is proven, the Journal will contact the author’s institute and funding agencies as appropriate. The paper containing the plagiarism may also be formally retracted or subject to correction."
27. Declaration of generative AI in scientific writing The below guidance only refers to the writing process, and not to the use of AI tools to analyse and draw insights from data as part of the research process.  Where authors use generative artificial intelligence (AI) and AI-assisted technologies in the writing process, authors should only use these technologies to improve readability and language. Applying the technology should be done with human oversight and control, and authors should carefully review and edit the result, as AI can generate authoritative-sounding output that can be incorrect, incomplete or biased. AI and AI-assisted technologies should not be listed as an author or co-author, or be cited as an author. Authorship implies responsibilities and tasks that can only be attributed to and performed by humans, as outlined in Elsevier's AI policy for authors.  Authors should disclose in their manuscript the use of AI and AI-assisted technologies in the writing process by following the instructions below. A statement will appear in the published work. Please note that authors are ultimately responsible and accountable for the contents of the work.  Disclosure instructions  Authors must disclose the use of generative AI and AI-assisted technologies in the writing process by adding a statement at the end of their manuscript in the core manuscript file, before the References list. The statement should be placed in a new section entitled 'Declaration of Generative AI and AI-assisted technologies in the writing process'  Statement: During the preparation of this work the author(s) used [NAME TOOL / SERVICE] in order to [REASON]. After using this tool/service, the author(s) reviewed and edited the content as needed and take(s) full responsibility for the content of the publication  This declaration does not apply to the use of basic tools for checking grammar, spelling, references etc. If there is nothing to disclose, there is no need to add a statement.  Prior Publication. At the time of submission, editorial manager (EM) will prompt the corresponding author to state whether any portion the data or results are under consideration by another journal or have been published elsewhere.  AJIC disapproves of duplicate publication. Authors should avoid reporting results of the same component of a study in separate manuscripts submitted to separate journals. For example, authors should refrain from submitting data from the same study that is analyzed in a similar fashion to construct two seemingly distinct papers. The Journal does not consider conference abstracts that report preliminary research findings as an instance of prior publication."
28. Where authors use AI and AI-assisted technologies in the writing process, these technologies should only be used to improve readability and language of the work and not to replace key researcher tasks such as producing scientific insights, analyzing and interpreting data or drawing scientific conclusions. Applying the technology should be done with human oversight and control and authors should carefully review and edit the result, because AI can generate authoritative-sounding output that can be incorrect, incomplete or biased. The authors are ultimately responsible and accountable for the contents of the work.  Authors should disclose in their manuscript the use of AI and AI-assisted technologies and a statement will appear in the published work. Declaring the use of these technologies supports transparency and trust between authors, readers, reviewers, editors and contributors and facilitates compliance with the terms of use of the relevant tool or technology.  Authors should not list AI and AI-assisted technologies as an author or co-author, nor cite AI as an author. Authorship implies responsibilities and tasks that can only be attributed to and performed by humans. Please see the authorship section for further guidance on authorship criteria."
29. Johns Hopkins University Press recognizes the benefits and risks of generative AI (e.g., ChatGPT, Bard, and Bing) as it relates to the scholarship and research of our authors across our books and journals programs. Following is our policy regarding generative AI for all of our publications. Authorship. Authors are accountable and legally responsible for the entirety of their work. Therefore, AI and Large Language Models (LLMs) tools do not qualify as authors and cannot be listed as such on any publication. The Press will not accept any work that is substantially written by an AI or LLM tool. Transparency. Authors must disclose their use of AI or LLMs in the work they are submitting for possible publication. This must be done in two ways. First, the use of AI or LLMs must be acknowledged by a general statement of such use at the beginning of an article, in the front matter of a book, or in another prominent place in the work. Second, any use of generative AI or LLMs in text, images, graphs, tables, or other parts of the work must be cited as would be done with any external source. Specific citation styles for generative AI can be found in the following style guides from MLA, Chicago, and APA. Responsibility and Accountability. The author is fully responsible for the entirety of their work. They must ensure that it is original, accurate, does not plagiarize other’s work, and appropriately cites and references others’ work, including any content that is generated by AI or LLMs. The author accepts full responsibility and is solely accountable for any liability that may ensue from the use of AI or LLMs. The individual journals published by Johns Hopkins University Press may have more specific guidelines for the use of generative AI and LLMs. We will continue to monitor developments with these rapidly evolving technologies and are committed to adapting our policies accordingly."
30. As of now, please note that programs such as ChatGPT do not satisfy authorship criteria, and cannot be listed as an author of a manuscript, commentary, or letter. Attribution of authorship implies accountability for the work, which cannot be applied to LLMs. Use of an LLM must be documented in the Methods section or as an acknowledgment at the end of the manuscript. This information must include a description of the content that was created or edited, the name of the language model or tool, version number, and manufacturer/developer. The manuscript authors accept full responsibility for the text’s factual and citation accuracy; mathematical, logical, and commonsense reasoning; and originality."
31. Artificial intelligence authoring tools and authorship policy. The journal does not consider Artificial Intelligence authoring tools to meet the requirements for Authorship as recommended by the ICMJE. The use of such tools may be included in the article’s Acknowledgements.
32. For this policy, AI refers to generative LLM AI tools and does not include grammar-checking software, citation software, or plagiarism detectors.  When a generative artificial intelligence (AI) model is used in the drafting of a manuscript for an APA publication, the use of AI must be disclosed in the methods section and cited. AI cannot be named as an author on an APA scholarly publication. When AI is cited in an APA scholarly publication, the author must employ the software citation template, which includes specifying in the methods section how, when, and to what extent AI was used. Authors in APA publications are required to upload the full output of the AI as supplemental material. The authors are responsible for the accuracy of any information in their article. Authors must verify any information and citations provided to them by an AI tool. Authors may use but must disclose AI tools for specific purposes such as editing. No submitted content may be entered into generative AI tools as this violates the confidentiality of the process."
33. Authors who use AI tools in the writing of a manuscript, production of images or graphical elements of the paper, or in the collection and analysis of data, must be transparent in disclosing in the Materials and Methods (or similar section) of the paper how the AI tool was used and which tool was used. Authors are fully responsible for the content of their manuscript, even those parts produced by an AI tool, and are thus liable for any breach of publication ethics. Visit: www.copyright.gov for more copyright information."
34. Manuscript Preparation and Artificial Intelligence About Our Policy (Approved May 15, 2023)  The purpose of this policy is to emphasize the importance of transparency and accountability regarding the use of AI in scientific research, while also recognizing the potential value of AI and AI-assisted tools in the research and publication process. By requiring proper documentation of the use of AI tools, the APS can help researchers ensure that their work is replicable and trustworthy. This policy is not in reference to the many scientific instruments and tools that utilize AI software to analyze raw data and output graphical results (e.g., microscopy, biomedical imaging, etc.).  Our Manuscript Preparation and AI Policy Authorship: AI and AI-assisted tools do not qualify for authorship (see “Authorship” at /ethics#policy) and cannot be considered an author of any article published in APS journals. Referencing: The use of AI or AI-assisted tools must be properly referenced in the Materials and Methods section of an article if AI tools were used as part of the design and performance of experiments or conclusions generation. If AI tools were used in the preparation of the manuscript (such as writing or revising), the authors should use the Acknowledgments section. The following statement should be used in either case: “[Tool Name, Version, and Model] was used for [list actual process for which AI was used and reason for its use]. The tool was used in a manner that does not conflict with APS ethical policies and the authors take full responsibility for the content.” Authors may be asked to supply the method of the application (e.g., query structure, syntax) if this is not already specified in the manuscript. Ethics: Intellectual contribution and data interpretation are the duties and obligations of the authors, but AI or AI-assisted tools may assist in generating text, data analysis, or other tasks. The overall responsibility for the content of the paper remains with the human authors. As always, authors should ensure that any AI-generated text provides proper attribution to previously published work. Authors are ultimately responsible for the content of the paper and will be held accountable if ethical situations arise. Figure Preparation: We encourage authors to review the ethical guidelines on figure preparation before submitting their articles (see Preparing Figures). As a reminder, it is not acceptable to fabricate, alter, or delete specific features within an image. Details for the use of AI software in scientific instruments and tools should be provided as part of the Materials and Methods section, along with a description of how the software was used to generate or alter content that is presented as part of the research. Exclusions: This policy does not apply to AI tools solely focused on grammar enhancement, such as grammar and spelling checkers (e.g., Grammarly, Wordtune, etc.), or reference managers (e.g., Endnote, Mendeley, etc.). Peer Review and Artificial Intelligence About Our Policy (Approved August 11, 2023)  The purpose of this policy is to ensure that reviews submitted by reviewers are authentic, unbiased, and reflect the reviewer's personal insights and expertise. Developers of generative AI tools, such as ChatGPT, are unable to provide any guarantee on where data are sent, viewed, or stored, and cannot assure the security or confidentiality of the content. Hence, this policy ensures that the security and confidentiality of the peer review process is upheld.  Our Peer Review and Artificial Intelligence Policy To maintain the integrity of the peer review process and uphold a fair evaluation of the scientific manuscript, reviewers are prohibited from using large language models, such as ChatGPT, or any similar AI technology, in the process of constructing their reviews. All reviews must be based on the reviewer's personal knowledge, expertise, and experiences related to the scientific work being evaluated. This policy does not apply to AI tools solely focused on grammar enhancement, such as grammar and spelling checkers. In cases where the usage of large language models is suspected, APS may employ various means, including manual review, automated analysis, or third-party services, to investigate the authenticity of the reviews. Any violation of this policy may result in the termination of the reviewer's relationship with APS.  Policy Review These policies will be reviewed periodically to ensure that they remain current and effective."
35. The American Psychiatric Association has adopted the following policies regarding the use of generative artificial/augmented intelligence (AI) in any manuscript or book submitted for potential publication:  If a generative AI tool was used at any stage in the creation of a submitted work, both the relevant text of the submitted work and the cover letter or email accompanying the submission must fully identify all details of the AI use (including the tool used and the relevant output) Submitted works may not include images produced with generative AI at this time Only human persons can be listed as authors of a work (i.e., no AI tool may be identified as author) Authors are responsible for all material contained within the submitted work, including any material first produced through the use of generative AI. This comprises responsibility for the accuracy of such material (i.e., confirming that it is not incorrect, incomplete or biased) and for ensuring that all relevant material includes appropriate attribution and does not constitute plagiarism Material produced through a generative AI tool may not be cited as a primary source "
36. No large language model (LLM)-driven chatbots, including ChatGPT, will be accepted as a credited author on a research paper. All author attributions must demonstrate accountability for the work, and AI tools cannot take such responsibility. All published ATS Journals articles will include a footnote reporting the author AI tool disclosure, based on the author disclosure provided on the title page at the time of submission.  At the time of submission, authors will declare artificial intelligence (AI) tool use as follows:  In the submission portal, authors will be required to declare whether an AI tool was used, which one was used, and how it was applied in preparing the manuscript. On the manuscript title page, authors must provide a statement declaring whether an AI tool was used and, if so, describe the use. Authors must continue to document the AI tool use in the relevant section of the manuscript."
37. Generative AI: Authors must disclose the use of large language models or other generative AI technologies in the manuscript’s preparation, including specific details regarding the relevant manuscript content, the particular technology applied (including name, version number, and manufacturer), and the manner in which the technology was used to create the content. Authors are responsible for any submitted materials created by generative AI technologies, including ensuring the accuracy of such material, the absence of plagiarism, and the appropriate attribution of sources."
38. ASHA journals require that text based – either in whole or in part – on output produced by generative artificial intelligence (AI), large language models (LLM), or similar technologies and included in a manuscript must be declared by the authors. Authors should consider this to include text first produced during the brainstorming/outlining process and later adapted into the manuscript. Declaration involves several statements within the manuscript submission system at first submission including:  An attestation that AI- or LLM-generated text has been included within the manuscript. An affirmation that all authors, both jointly and severally, assume responsibility for the accuracy, originality, and integrity of AI- or LLM-generated text included within the manuscript. Authors must also include the following details within the manuscript itself:  An Artificial Intelligence Statement disclosing the inclusion of AI- or LLM-generated text within the manuscript. This should be included at the end of the main text, before the Reference section. For example: Artificial Intelligence Statement: ChatGPT was used during [PLEASE ADD DETAILS HERE] with resulting text being revised by the authors prior to inclusion in the manuscript. A parenthetical citation immediately following the AI- or LLM-generated text as well as a corresponding entry within the Reference section. For example: Reference: OpenAI. (2023). ChatGPT (Mar 14 version) [Large language model]. https://chat.openai.com/chat ASHA journals prohibit the inclusion of AI-generated images or video. Additionally, ASHA journals prohibit the crediting of AI, LLM, or similar technologies as authors based on the following determinations:   AI or LLM fail to satisfy the four requirements for authorship. AI or LLM are unable to transfer copyright. AI or LLM are unable to hold, or declare, conflicts of interest. AI or LLM are unable to attest, either jointly or severally, to authorship queries and/or statements. Please note, the above stipulations do not apply to permissible use of AI in areas such as research design, data analysis/verification, or formatting (e.g., Paperpal Preflight). Nor do they alter similar ASHA journals policy relating to AI and potential scientific misconduct (e.g., image manipulation, etc.)."
39. The below guidance only refers to the writing process, and not to the use of AI tools to analyse and draw insights from data as part of the research process.  Where authors use generative artificial intelligence (AI) and AI-assisted technologies in the writing process, authors should only use these technologies to improve readability and language. Applying the technology should be done with human oversight and control, and authors should carefully review and edit the result, as AI can generate authoritative-sounding output that can be incorrect, incomplete or biased. AI and AI-assisted technologies should not be listed as an author or co-author, or be cited as an author. Authorship implies responsibilities and tasks that can only be attributed to and performed by humans, as outlined in Elsevier's AI policy for authors.  Authors should disclose in their manuscript the use of AI and AI-assisted technologies in the writing process by following the instructions below. A statement will appear in the published work. Please note that authors are ultimately responsible and accountable for the contents of the work.  Disclosure instructions  Authors must disclose the use of generative AI and AI-assisted technologies in the writing process by adding a statement at the end of their manuscript in the core manuscript file, before the References list. The statement should be placed in a new section entitled ‘Declaration of Generative AI and AI-assisted technologies in the writing process’.  Statement: During the preparation of this work the author(s) used [NAME TOOL / SERVICE] in order to [REASON]. After using this tool/service, the author(s) reviewed and edited the content as needed and take(s) full responsibility for the content of the publication.  This declaration does not apply to the use of basic tools for checking grammar, spelling, references etc. If there is nothing to disclose, there is no need to add a statement.  5.5 Generative AI and Figures, images and artwork  Please read our policy on the use of generative AI and AI-assisted tools in figures, images and artwork, which states:  We do not permit the use of Generative AI or AI-assisted tools to create or alter images in submitted manuscripts.  The only exception is if the use of AI or AI-assisted tools is part of the research design or methods (for example, in the field of biomedical imaging). If this is the case, such use must be described in a reproducible manner in the methods section, including the name of the model or tool, version and extension numbers, and manufacturer.  The use of generative AI or AI-assisted tools in the production of artwork such as for graphical abstracts is not permitted. The use of generative AI in the production of cover art may in some cases be allowed, if the author obtains prior permission from the journal editor and publisher, can demonstrate that all necessary rights have been cleared for the use of the relevant material, and ensures that there is correct content attribution."
40. During manuscript submission, the submitting author must provide contact information (full name, email address, institutional affiliation, and mailing address) for all of the coauthors. Because all of the author names are automatically imported into the electronic Journal Publishing Agreement, the names must be entered into the submission system. (Note that coauthors are not required to register in the ACS Publishing Center.) Author affiliation should reflect where the work was completed, even if the author has since left that institution. Authors may include a note with a current address if their institution has changed since the work was completed.  To expedite the processing of your manuscript, please format your author and affiliation information according the guidelines in this document.  Criteria for authorship can be found in Part B of the Ethical Guidelines to Publication of Chemical Research. Artificial intelligence (AI) tools do not qualify for authorship. The use of AI tools for text or image generation should be disclosed in the manuscript within the Acknowledgment section with a description of when and how the tools were used. For more substantial use cases or descriptions of AI tool use, authors should provide full details within the Methods or other appropriate section of the manuscript.  If any change in authorship is necessary after a manuscript has been submitted, confirmation is required that all of the authors (including those being added or removed) have been notified and have agreed to the change. To provide this confirmation, authors are asked to complete and sign an authorship change form and provide the completed form to the appropriate editorial office."
41. Author use of generative artificial intelligence (AI), such as ChatGPT, does not preclude their initial manuscript submission to Anesthesia & Analgesia. However, the Journal Editorial Board requires that author(s) confirm and outline, at the time of initial submission, their use of generative AI for any and all specific manuscript content, including text, tables, and figures. Use of generative AI to create reported data or cited references is strictly forbidden; doing so will result in immediate manuscript rejection and reporting of scientific/scholarly misconduct, by the Journal."
42. Natural language processing tools driven by artificial intelligence (AI) do not qualify as authors, and the Journal will screen for them in author lists. The use of AI (for example, to help generate content or images, write code, process data, or for translation) should be disclosed both in cover letters to editors and in the Methods or Acknowledgements section of manuscripts. Please see the COPE position statement on Authorship and AI for more details."
43. The Annals of Mathematics does not consider papers generated using AI products.  Only individuals who can take full responsibility for the contents of a submission can be named authors.
44. Tools that use generative artificial intelligence (AI), machine learning, large language models (LLMs), chatbots (such as ChatGPT), and AI-assisted image generators will be considered AI tools in this policy discussion.  ASM acknowledges that the current landscape of AI tools is complex and ever changing. The use of assistive AI tools that edit and refine human-generated content (e.g., chatbots, virtual assistants, and speech recognition systems) have long been available for researchers. Generative AI tools that create original content (e.g., large language models, image generators, and other composition algorithms) are rapidly developing as well. Therefore, this subject is undergoing continued evaluation and additional guidance may be incorporated in the future.  We recognize the potential of AI tools to improve the quality, accessibility, and clarity of human-generated content. However, maintaining the integrity of the scientific record is essential. To assist authors in navigating this landscape, we have outlined principles and rules on this page for how AI tools can be used in ASM journals. This underscores our commitment to preserving the authenticity and credibility of scholarly contributions.  Guidelines for Authors Using AI Tools Content completely generated by an AI tool without any significant human contribution is not allowed in ASM journals. AI tools should only be used to improve the language, accessibility, or quality of human-generated text. AI tools should not be used for images, cover art, videos, or schematics. If you use AI tools in your manuscript, it must be disclosed at submission in the cover letter. You can and may be requested to provide additional details (name and version of AI tool, purpose, prompts, input) in the manuscript. Certain exceptions can be allowed, such as manuscripts specifically about AI tools or machine learning. If you have questions, contact the staff, who will evaluate each case individually. AI tools can't be considered authors of ASM journal articles because they can't think, contribute intellectually, be held responsible for the content they generate, or sign copyright agreements. Authors are responsible for the accuracy of the text, figures, and references in their manuscript. To maintain originality and prevent plagiarism, avoid copying content, and eliminate any biases potentially introduced by AI tools."
45. Authors who use artificial intelligence (AI) tools in the creation of a manuscript for submission to the Archives must disclose in the Materials and Methods section how these tools were used and which tools were used. Authors are fully responsible for the content of their manuscript, even those parts produced by AI tools, and are thus liable for any breach • Authors should make certain that all identifying information, such as author names and affiliations, does not appear on the title page, text pages, and figures. However, all manuscripts should still include a title page (see Title Page below). • Manuscripts should be prepared in accordance with the American Medical Association (AMA) Manual of Style, 11th edition. • Double-space throughout the manuscript file, including title page, abstract, text, acknowledgments, references, legends for illustrations, and tables. The right margin should be unjustified (ragged). • The article file should not contain unnecessary formatting. Specifically, only use hard returns at the end of paragraphs and display lines; do not use an extra hard return between paragraphs; do not use tabs or extra space at the start of paragraphs or for list entries; do not indent runover lines in references; do not use different typefaces, page breaks, or headers; and turn off line spacing and hyphenation and justification. • Start each section on a new page, numbered consecutively in the upper right-hand corner, beginning with the title page. • Use conventional units of measurement throughout the manuscript, with conversion factors for System International (SI) units expressed once in parentheses after the first mention of the conventional unit. Example: ‘‘The blood glucose concentration of 126 mg/dL (to convert to millimoles per liter, multiply by 0.0555) was used as a criterion for diagnosing diabetes.’’ If several laboratory values are listed, reports of original data (Original Articles), submit a structured abstract of no more than 250 words under the headings of Context, Objective, Design, Results, and Conclusions. For review manuscripts, submit a structured abstract of no more than 250 words under the headings of Context, Objective, Data Sources, and Conclusions. For reports of the results of meta-analyses, submit a structured abstract of no more than 250 words under the headings of Context, Objective, Data Sources, Study Selection, Data Extraction, and Conclusions. Authors submitting manuscripts that report consensus statements should provide a structured abstract of no more than 250 words under the headings of Objective, Participants, Evidence, Consensus Process, and Conclusions. For detailed information concerning what to include under each abstract heading, refer to the AMA Manual of Style. • When writing abstracts, do not begin by repeating the manuscript’s title. Do not list anything in the abstract that is not also in the manuscript. Do not cite references in abstracts. References.—Number references in the order they are mentioned in the text; do not alphabetize. In text, tables, and legends, identify references with superscript Arabic numerals. Submit a preprint for references cited as in press. In listing references, follow AMA style, abbreviating names of journals according to Index Medicus. Note: List all authors and/or editors up to 6; if more than 6 authors, list the first 3, followed by ‘‘et al.’’ Provide the issue number in parentheses after the volume number. For online journals or articles published online ahead of print, provide the DOI number, if possible, rather than the URL. URLs used in references will not be made hyperlinks. Examples: 1. Guler ML, Daniels JA, Abraham SC, Montgomery EA. Expression of melanoma antigens in epithelioid gastrointestinal stromal tumors: a potential diagnostic pitfall. Arch Pathol Lab Med. 2008;132(8):1302–1306. For a reference to a chapter in a book: 2 Arch Pathol Lab Med Instructions for Authors of publication ethics. We suggest authors review the articles from Zielinski et al 2 and Stanbrook and colleagues 3 for additional information"
46. The below guidance only refers to the writing process, and not to the use of AI tools to analyze and draw insights from data as part of the research process.  Where authors use generative artificial intelligence (AI) and AI-assisted technologies in the writing process, authors should only use these technologies to improve readability and language. Applying the technology should be done with human oversight and control, and authors should carefully review and edit the result, as AI can generate authoritative-sounding output that can be incorrect, incomplete, or biased. AI and AI-assisted technologies should not be listed as an author or co-author or be cited as an author. Authorship implies responsibilities and tasks that can only be attributed to and performed by humans, as outlined in Elsevier's AI policy for authors.  Authors must disclose in their manuscript the use of AI and AI-assisted technologies in the writing process by following the instructions below. A statement will appear in the published work. Please note that authors are ultimately responsible and accountable for the contents of the work.  Disclosure instructions  Authors must disclose the use of generative AI and AI-assisted technologies in the writing process by adding a statement at the end of their manuscript in the core manuscript file, before the References list. This declaration does not apply to the use of basic tools for checking grammar, spelling, references etc. If there is nothing to disclose, there is no need to add a statement. The statement should be placed in a new section entitled 'Declaration of Generative AI and AI-assisted technologies in the writing process'.  Statement: During the preparation of this work the author(s) used NAME TOOL / SERVICE in order to REASON. After using this tool/service, the author(s) reviewed and edited the content as needed and take(s) full responsibility for the content of the publication."
47. Artificial intelligence involvement. Here, authors must disclose if any of the material has been partially or totally produced with the help of any artificial intelligence software or tool."
48. Declaration of generative AI in scientific writing  The below guidance only refers to the writing process, and not to the use of AI tools to analyse and draw insights from data as part of the research process.  Where authors use generative artificial intelligence (AI) and AI-assisted technologies in the writing process, authors should only use these technologies to improve readability and language. Applying the technology should be done with human oversight and control, and authors should carefully review and edit the result, as AI can generate authoritative-sounding output that can be incorrect, incomplete or biased. AI and AI-assisted technologies should not be listed as an author or co-author, or be cited as an author. Authorship implies responsibilities and tasks that can only be attributed to and performed by humans, as outlined in Elsevier's AI policy for authors.  Authors should disclose in their manuscript the use of AI and AI-assisted technologies in the writing process by following the instructions below. A statement will appear in the published work. Please note that authors are ultimately responsible and accountable for the contents of the work.  Disclosure instructions  Authors must disclose the use of generative AI and AI-assisted technologies in the writing process by adding a statement at the end of their manuscript in the core manuscript file, before the References list. The statement should be placed in a new section entitled ‘Declaration of Generative AI and AI-assisted technologies in the writing process’. Statement: During the preparation of this work the author(s) used [NAME TOOL / SERVICE] in order to [REASON]. After using this tool/service, the author(s) reviewed and edited the content as needed and take(s) full responsibility for the content of the publication.  This declaration does not apply to the use of basic tools for checking grammar, spelling, references etc. If there is nothing to disclose, there is no need to add a statement. Papers from IFAC technical meetings  Papers submitted to IFAC journals with prior publication in any copyrighted conference proceedings must be substantially different from the conference publication. Authors should indicate in the cover letter in detail how the journal paper differs from the relevant conference paper or papers. In particular, the additional original contribution in the journal paper has to be pointed out explicitly. In the journal paper, the conference paper has to be cited and discussed as any other paper in the list of references.  Automatica has priority access to papers presented at meetings sponsored by IFAC. If the authors of IFAC meeting papers have not been notified by one of the Automatica Editors within three months of the meeting that the paper is to be reviewed for possible publication in Automatica, then the paper can be considered as released for publication elsewhere provided that an acknowledgement to the IFAC meeting is given.  Conditions of publication: It is a condition of publication that manuscripts submitted to Automatica have not been published and will not be submitted or published elsewhere in English or any other language, without the written consent of the publisher. Responsibility for the contents of the paper rests upon the authors and not upon IFAC, the Editors, or the Publisher."
49. Articles, case studies, and chapters submitted to Emerald for consideration and review should be treated as confidential, meaning that sharing this material with another person or uploading it to an AI tool or Large Language Model (LLM) for assessment or evaluation would violate the author's confidentiality, as well as any proprietary and/or data privacy rights.This would also be the case for the peer review report itself if uploaded to an AI tool/LLM for copy-editing or copy-writing purposes, as it may contain confidential or identifiable information pertinent to the article or the author(s). There are additional concerns regarding the use of AI tools for peer review due to biases in the datasets of these models and the reliability of their ability to assess content, with the risk of generating false, flawed, or inaccurate results.As such, to maintain trust in the integrity of the published record, Emerald does not permit the use of AI tools or LLMs to assist in the review, evaluation, or decision-making process of any part of an article, case study, or chapter by either a member of a journal's Editorial Team or a reviewer, in accordance with Emerald's principles of peer review. Peer reviewers are responsible for the reviews they provide and accountable for their accuracy, rigour, and validity, which, as per COPE's position statement on AI tools, cannot be replicated by a non-human AI. Any breach of the integrity or trust of the review process as described above will be treated as peer review misconduct. "
50. Authors may make use of AI tools in preparing their articles. However, such tools may not be listed as an author, as they cannot be held accountable for the work. All co-authors of the text should carefully check for any errors introduced through the use of an AI tool. Authors who have employed an AI tool should document this use in the methods or acknowledgements sections."
51. AI Authorship Large Language Models (LLMs), such as ChatGPT, do not currently satisfy our authorship criteria. Notably an attribution of authorship carries with it accountability for the work, which cannot be effectively applied to LLMs. Use of an LLM should be properly documented in the Methods section (and if a Methods section is not available, in a suitable alternative part) of the manuscript.  Generative AI Images The fast moving area of generative AI image creation has resulted in novel legal copyright and research integrity issues. As publishers, we strictly follow existing copyright law and best practices regarding publication ethics. While legal issues relating to AI-generated images and videos remain broadly unresolved, Springer Nature journals are unable to permit its use for publication.   Exceptions are images/art obtained from agencies that we have contractual relationships with that have created images in a legally acceptable manner. Other exceptions to this policy include images and video that are directly referenced in a piece that is specifically about  AI and will be reviewed on a case-by-case basis.   As we expect things to develop rapidly in this field in the near future, we will review this policy regularly and adapt it if necessary.  Please note: Not all AI tools are generative. The use of non-generative machine learning tools to manipulate, combine or enhance existing images or figures should be disclosed in the relevant caption upon submission to allow a case-by-case review.  AI use by peer reviewers Peer reviewers play a vital role in scientific publishing. Their expert evaluations and recommendations guide editors in their decisions and ensure that published research is valid, rigorous, and credible. Editors select peer reviewers primarily because of their in-depth knowledge of the subject matter or methods of the work they are asked to evaluate. This expertise is invaluable and irreplaceable. Peer reviewers are accountable for the accuracy and views expressed in their reports, and the peer review process operates on a principle of mutual trust between authors, reviewers and editors. Despite rapid progress,  generative AI tools have considerable limitations: they can lack up-to-date knowledge and may produce nonsensical, biased or false information. Manuscripts may also include sensitive or proprietary information that should not be shared outside the peer review process. For these reasons we ask that, while Springer Nature explores providing our peer reviewers with access to safe AI tools, peer reviewers do not upload manuscripts into generative AI tools.  If any part of the evaluation of the claims made in the manuscript was in any way supported by an AI tool, we ask peer reviewers to declare the use of such tools transparently in the peer review report."
52. Please note that we do not accept papers that are generated by Artificial Intelligence (AI) or Machine Learning Tools primarily because such tools cannot take responsibility for the submitted work and therefore cannot be considered as authors. Where such tools or technologies are used as part of the design or methodology of a research study, their use should be clearly described in an acknowledgements section."
53. As a member of the Committee on Publication Ethics (COPE), our journal strives for the highest level of quality in content and process. Recent innovations have led us to address the use of AI tools in scholarly publishing with a primary goal of transparency. The journal presently uses AI to detect plagiarism with the software iThenticate. The use of AI-driven tools such as this requires oversight by editors and editorial staff and all decisions that result from the information gained through the use of the tool are made by the editors. No editorial decisions are made by or with AI resources to ensure the sanctity of our peer review process. Editorial decisions involving misconduct and research integrity that may or may not lead to corrections, retractions, or expressions of concern are made solely by the editors with no AI involvement after careful review of each individual case.  Manuscript submissions that are in part or wholly written by artificial intelligence-generated tools will be rejected without review and deemed unacceptable for publication. AI-assisted technologies may not be listed or cited as an author. Any use of such technology must be disclosed with this statement:  “During the preparation of this work, the author(s) used (NAME TOOL/SERVICE) to (REASON). After using this tool/service, the author(s) reviewed and edited the content as needed and take full responsibility for the content of the publication.”  Such technology should only be used to improve readability and language, not replace researcher tasks, data interpretation, or be used to analyze or draw scientific conclusions. This declaration doesn’t apply to the use of basic tools for checking grammar, syntax, references, etc. The editors reserve the right to question authors whose content appears to be written through an AI tool, or if such an instance is identified by reviewers during peer review.  We maintain that strict oversight by editors and editorial staff is the hallmark to ensuring a rigorous and fair peer review process meeting the highest ethical standards."
54. MDPI recognizes the opportunities and challenges presented by the rapid development of Generative Artificial Intelligence (GenAI) such as ChatGPT and other large language models (LLMs) for scholarly publishing. In order to provide transparency to the academic community, MDPI has developed the following policies based on the general guidance provided by STM and the Committee on Publication Ethics (COPE) position statement.Manuscript preparationWhere GenAI has been used for purposes such as generating text, data, graphics, study design, or data collection, analysis, or interpretation of data, authors are required to declare this during the submission process. Furthermore, for transparency, authors are required to disclose details of how the GenAI tool was used in the “Materials and Methods” section, and provide the GenAI tool’s product details in the “Acknowledgments” section.Recommended acknowledgement statement:“Duing the preparation of this manuscript/study, the author(s) used [tool name, version information] for the purposes of [description of use]. The authors have reviewed and edited the output and take full responsibility for the content of this publication.“The use of GenAI tools for the purposes of text editing (e.g., grammar, structure, spelling, punctuation and formatting) is not covered by this policy and does not need to be declared.Authors are fully responsible for the originality, validity, and integrity of the content of their manuscript, including any material contributed by GenAI tools, and must ensure, through careful review, that this content complies with all MDPI’s publication ethics policies including, but not limited to, Plagiarism, Data Fabrication and Image Manipulation and Intellectual Property.MDPI reserves the right to request further information, and editorial decisions will be made in line with MDPI’s Editorial Process and Terms and Conditions.AuthorshipGenAI tools and other large language models (LLMs) cannot be listed as authors. These tools do not meet MDPI’s requirements for authorship.GenAI use by reviewersGenAI tools and other large language models (LLMs) should not be used by reviewers in the preparation of review reports. Reviewers are solely responsible for the content of their reports and the utilization of these tools may violate confidentiality, proprietary, and data privacy rights. Some limited use to improve the written quality of the peer-review report, such as checking grammar, structure, spelling, punctuation, and formatting, may be acceptable but should be disclosed upon submission of the peer-review report. Under no circumstances should reviewers upload manuscripts, either in whole or in part; images; figures; tables; or any kind of communication related to manuscripts under review to any GenAI tools, as to do so violates MDPI's confidentiality policy relating to peer-review. If it is determined that AI tools have been inappropriately used in review report preparation, the report will be discarded.GenAI use in editorial decision makingAcademic Editors (Editors-in-Chief, Editorial Board Members and Guest Editors) play an essential role within peer-review to ensure the integrity and rigor of the process. Given this significant responsibility, Academic Editors must not use GenAI tools during the editorial review or decision-making process. Under no circumstances should Academic Editors upload manuscripts, either in whole or in part; images; figures; tables; or any kind of communication related to manuscripts under review to any GenAI tools, as to do so violates MDPI's confidentiality policy relating to peer-review. "
55. Generative Artificial Intelligence in Scientific Writing: Artificial intelligence (AI) tools such as ChatGPT or large language models cannot be listed as authors in research publications, in accordance with Committee on Publication Ethics (COPE) guidelines. Any use of AI tools must be disclosed in the Search Methods of the paper (i.e., how and which AI tool was used). Authors are fully responsible for the content of their manuscript, even those parts produced by an AI tool. The final decision about whether use of an AI tool is appropriate or permissible in a submitted manuscript lies with the journal's editor."
56. The concept of artificial intelligence is based on the assumption that machines can imitate the human thought process. Even before the industrial era, speculations of artificial intelligence could be seen in different civilizations. From the first day, this field of study faced several fluctuations; sometimes, it attracted a lot of attention, and sometimes it experienced winters due to some technological shortcomings. But, during the last decades, the field of artificial intelligence did not completely disappear. After each winter, artificial intelligence came into the picture, attracted a lot of attention, and became an important research field. There is a simple explanation for today's rise of artificial intelligence: now, thanks to the ever-improving ability of fast computation, artificial intelligence-based methods work perfectly in many applications. The major purpose of this issue is to explore the latest developments in artificial intelligence. Additionally, the application of these methods in various fields including economic and social challenges, games, agriculture, cyber security, finance, health, chemistry and biology, astronomy and space activities, energy, manufacturing, transport, etc. will be discussed. Any contribution that provides an added value to artificiall intelligence and its applications is of interest to this special issue. The topics of interest include – but not limited to– the following: • Novel theory and methodology of artificial intelligence • In-depth evaluation of the AI techniques • Emerging Trends of Deep Learning in AI • Application of Artificial Intelligence in Finance, Cyber Security, Health, Agriculture, Transports, Biological Sciences, Aerospace, etc. Guidelines Authors can submit their manuscripts through the online submission system www.acmij.az. They have to use “Special issue on Artificial intelligence; where do we stand?” for the submission. Only papers with new and outstanding results related to artificiall intelligence and its applications within this scope will be considered for review. Routinely submissions and papers with only theoretical values will be directly rejected without being sent to review. Please however feel free to contact chief_ed@acmij.az or executive_ed@acmij.az. Please note that papers will have to adhere to the journal space and style requirements"
57. Use of AI Tools: The MIT Press does not allow artificial intelligence (AI) tools such as ChatGPT or large language models (LLMs) to be listed as authors of our publications. The emerging consensus of scholarly organizations, including the Committee on Publication Ethics, is that AI tools do not meet the requirements for authorship since they cannot assume ethical and legal responsibility for their work."
58. GenAI Use Policy AJET Policy for Use of Artificial Intelligence in Publishing and Reviewing  The AJET editorial team acknowledge the increase in availability and use of Generative Artificial Intelligence (GenAI) in academic research and set out the following rules in relation to how authors and editorial members should work with GenAI.  1. Generative AI cannot be listed as an author on AJET publications. An author must be able to agree to and be accountable for the aspects of their authorship under the CRediT taxonomy, which an AI cannot do.  2. Authors need to acknowledge the contribution made by Generative AI tools to any aspects of the research published. In the acknowledgement section the authors should outline the specific tasks AI was used to complete, including (but not limited to) research design, data analyses, data visualisation, text creation/editing, etc.).  3. AJET Reviewers do not have permission to use Generative AI to complete any reviews of AJET articles. Sharing articles under review with third party AI providers for this purpose may contravene authors’ intellectual property rights to their work."
59. Criteria for authorship can be found in Part B of the Ethical Guidelines to Publication of Chemical Research. Artificial intelligence (AI) tools do not qualify for authorship. The use of AI tools for text or image generation should be disclosed in the manuscript within the Acknowledgment section with a description of when and how the tools were used. For more substantial use cases or descriptions of AI tool use, authors should provide full details within the Methods or other appropriate section of the manuscript."
60. Authors are permitted to use generative AI and AI-assisted technologies in the writing process. This must be done with oversight by authors, who should review and, where necessary, edit the output. The authors must take full responsibility for all content of the paper. In particular, AI and AI-assisted technologies do not qualify as authors, and the Journal will screen for them in author lists. Please see the COPE position statement on Authorship and AI for more details.  Authors must disclose their use of AI and AI-assisted technologies, both within the cover letter to the editor and within the manuscript. This should detail what AI-technology is used and for what reason. Where AI has been used, please also add a statement within the manuscript. This should appear before the Acknowledgement section, and be titled “Declaration of the use of generative AI and AI-assisted technologies”. It should read:  “During the preparation of this work the author(s) used [NAME TOOL/SERVICE] in order to [REASON]. After using this tool/service the author(s) reviewed and edited the content as necessary and take(s) full responsibility for the content of the publication.”  This declaration does not apply to the use of basic tools for checking grammar, spelling etc. If there is nothing to declare there is no need for a statement.  Papers will be judged solely on their content, and the use of generative AI within the writing of the paper will not prejudice the review of the paper."
61. Use of Artificial Intelligence Natural language processing tools driven by artificial intelligence (AI) do not qualify as authors, and JLB will screen for them in author lists. The use of AI (for example, to help generate content, write code, or process data) should be disclosed both in cover letters to editors and in the Methods or Acknowledgements section of manuscripts. Please see the COPE position statement on AI and authorship for more details.  Everyone listed as an author of an article must have made a substantial contribution to the manuscript. In the case of multiple-author contributions, please upload as a supplementary file a brief statement detailing the contribution of each author.  Authorship should be restricted to those individuals who have met each of three criteria: (a) made a significant contribution to the conception and design of the article or the analysis and interpretation of data or other scholarly effort, (b) participated in drafting the article or reviewing and/or revising it for content, and (c) approved the final version of the manuscript. In the case of papers with multiple authors, the corresponding author has the responsibility for: (a) including as coauthors all those who meet the three criteria defined in part 1 of this policy and excluding those who do not; and (b) obtaining from all coauthors their agreement to be designated as such, as well as their approval of the final version of the manuscript. Of course, any person can refuse to be a coauthor if he or she elects to do so. Coauthors assume full responsibility for all work submitted under their names and, as a coauthor, acknowledge that they meet each of the three criteria for authorship as defined in part 1 of this policy. Honorary or courtesy authorships are inconsistent with the principles of this policy and, as such, are unacceptable."
62. Neither symbolic figures such as Camille Noûs nor natural language processing tools driven by artificial intelligence (AI) such as ChatGPT qualify as authors, and will be screened for in author lists. The use of AI (for example, to help generate content, write code, or analyze data) must be disclosed both in cover letters to editors and in the Methods or Acknowledgements section of manuscripts. The authors bear full responsibility and must verify the correctness of the content created by AI."
63. Machine learning (ML)/artificial intelligence (AI) tools, such as ChatGPT, are not eligible for authorship. These tools may not be listed as an author on submissions to any journals in the Blood Journals portfolio and, to ensure that submissions to the journals remain confidential, these tools may not be used to write a review of a journal article. However, research that used ML/AI tools for data acquisition or analysis is eligible for submission. Submissions may include graphic outputs of ML/AI, but the role of ML/AI in creating the graphic must be specified in the legend. Text generated by AI may not be included."
64. BMJ considers artificial intelligence (AI) to include large language models such as Chat GPT, and any other technologies which use machine learning, deep learning, logical reasoning, knowledge representation, planning or navigation, natural-language processing, perception, emergent intelligence, or any other similar or equivalent technologies from time to time. This may include technologies that make automated decisions. We recognise the potential for both benefit and harm to academic literature from the use of AI technologies.  The policy Transparent reporting of AI technologies in content submitted to BMJ journals Decision making Authorship Responsibility for content produced or influenced by AI technology Detection and screening Peer review  The policy BMJ will consider content where AI technologies are used. Our approach is one of transparency. Where AI technology has been used this should be clearly described. Editors will consider the suitability of the use outlined. Our approach is in line with organisations including the World Association of Medical Editors (WAME) and the Committee on Publication Ethics (COPE).  This policy applies to all authors and contributors submitting content for publication in a BMJ title. It applies to all types of content, including original research, debate, opinion, journalism. It applies to all formats, including, without limitation, all text, audio, video and audio-visual material, abstracts, databases, tables, data, diagrams, photographs and other images or illustrative materials. The same principles apply to the use of AI in peer review comments submitted to journals and any other advice or material sent to us.   Transparent reporting of AI technologies in content submitted to BMJ journals We expect authors or others who are creating content to disclose and describe use of AI technologies in (a) any content which is submitted to us, (b) any other work by the authors which underpins or is otherwise connected with the content submitted to us, and (c) any key sources which are cited, to the best of the authors’ knowledge.  To ensure transparent declaration of AI, authors should: 1. Include an acknowledgement of AI use in the ‘contributor’ section of written material. If the AI use was in the course of research, a fuller description should be included in the methods section. 2. Transparent declaration includes a description of: What AI technology was used (the name of the technology) Why this AI technology was used (the reason for its use) How the AI technology was used (what the task of the technology was) Consider including a summary of the input, output, and the way in which the AI output was reviewed on the part of the authors as supplementary files or additional information for the editor to review. The editor may ask for more information and/or for information to be added to the content for internal use and/or for publication.  Decision making BMJ will consider whether the way in which AI was used and declared is reasonable and consistent with its publication policies and practice. Content may be rejected or be subject to post-publication changes on the basis of inadequate declaration or on the particular circumstances of its use.     Authorship AI technologies will not be accepted as an author(s) of any content submitted to BMJ for publication. BMJ only recognises humans as being capable of authorship since they must be accountable for the work.   Responsibility for content produced or influenced by AI technology Authors and contributors are responsible for content produced by AI technology in their work. This includes responsibility for accuracy, suitable attribution of sources, and absence of plagiarism.   Detection and screening We may, on a systematic or case by case basis, use screening tools pre-publication to assist with the identification of content generated (in whole or in part) through AI technologies. We may also use such tools post-publication.   Peer review If reviewers use AI technology to improve word processing and language, they should declare this when submitting their reports. However, reviewers should preserve the confidentiality of the peer review process by not putting unpublished manuscripts that they are reviewing for BMJ Journals (or information about them) into publicly available AI tools where ; the security of the confidential information cannot be guaranteed.  Development in the field of AI is continuous. We will review this policy as necessary, or every six months until further notice. Any proposed significant variation will be discussed with relevant stakeholders according to the degree of change proposed and those likely to be affected."
65. Brain supports the World Association of Medical Editors’ recommendations on chatbots and scholarly manuscripts. If an artificial intelligence (AI) such as a chatbot or similar program is used in the development of a paper for Brain, the following is required:  A Large Language Model (LLM), chatbot, or other AI cannot be credited as an author, as authorship requires that the author be accountable for the submitted/published work, and artificial intelligence cannot fulfil this requirement of authorship; Authors listed on the paper must review the content generated by the LLM and take full responsibility for it, as they would for any other content within the submitted/published work; The use of LLM tools must be documented in the Methods, Acknowledgments, or another appropriate section of the paper."
66. For authors The use of generative AI and AI-assisted technologies in scientific writing Please note this policy only refers to the writing process, and not to the use of AI tools to analyze and draw insights from data as part of the research process.   Where authors use generative AI and AI-assisted technologies in the writing process, these technologies should only be used to improve readability and language of the work. Applying the technology should be done with human oversight and control and authors should carefully review and edit the result, because AI can generate authoritative-sounding output that can be incorrect, incomplete or biased. The authors are ultimately responsible and accountable for the contents of the work.  Authors should disclose in their manuscript the use of AI and AI-assisted technologies and a statement will appear in the published work. Declaring the use of these technologies supports transparency and trust between authors, readers, reviewers, editors and contributors and facilitates compliance with the terms of use of the relevant tool or technology.  Authors should not list AI and AI-assisted technologies as an author or co-author, nor cite AI as an author. Authorship implies responsibilities and tasks that can only be attributed to and performed by humans. Each (co-) author is accountable for ensuring that questions related to the accuracy or integrity of any part of the work are appropriately investigated and resolved and authorship requires the ability to approve the final version of the work and agree to its submission. Authors are also responsible for ensuring that the work is original, that the stated authors qualify for authorship, and the work does not infringe third party rights, and should familiarize themselves with our Ethics in Publishing policy opens in new tab/window before they submit.  The use of generative AI and AI-assisted tools in figures, images and artwork We do not permit the use of Generative AI or AI-assisted tools to create or alter images in submitted manuscripts. This may include enhancing, obscuring, moving, removing, or introducing a specific feature within an image or figure. Adjustments of brightness, contrast, or color balance are acceptable if and as long as they do not obscure or eliminate any information present in the original. Image forensics tools or specialized software might be applied to submitted manuscripts to identify suspected image irregularities.  The only exception is if the use of AI or AI-assisted tools is part of the research design or research methods (such as in AI-assisted imaging approaches to generate or interpret the underlying research data, for example in the field of biomedical imaging). If this is done, such use must be described in a reproducible manner in the methods section. This should include an explanation of how the AI or AI-assisted tools were used in the image creation or alteration process, and the name of the model or tool, version and extension numbers, and manufacturer. Authors should adhere to the AI software’s specific usage policies and ensure correct content attribution. Where applicable, authors could be asked to provide pre-AI-adjusted versions of images and/or the composite raw images used to create the final submitted versions, for editorial assessment.  The use of generative AI or AI-assisted tools in the production of artwork such as for graphical abstracts is not permitted. The use of generative AI in the production of cover art may in some cases be allowed, if the author obtains prior permission from the journal editor and publisher, can demonstrate that all necessary rights have been cleared for the use of the relevant material, and ensures that there is correct content attribution.  View Elsevier’s generative AI author policies for books opens in new tab/window.   For reviewers The use of generative AI and AI-assisted technologies in the journal peer review process When a researcher is invited to review another researcher’s paper, the manuscript must be treated as a confidential document. Reviewers should not upload a submitted manuscript or any part of it into a generative AI tool as this may violate the authors’ confidentiality and proprietary rights and, where the paper contains personally identifiable information, may breach data privacy rights.  This confidentiality requirement extends to the peer review report, as it may contain confidential information about the manuscript and/or the authors. For this reason, reviewers should not upload their peer review report into an AI tool, even if it is just for the purpose of improving language and readability.  Peer review is at the heart of the scientific ecosystem and Elsevier abides by the highest standards of integrity in this process. Reviewing a scientific manuscript implies responsibilities that can only be attributed to humans. Generative AI or AI-assisted technologies should not be used by reviewers to assist in the scientific review of a paper as the critical thinking and original assessment needed for peer review is outside of the scope of this technology and there is a risk that the technology will generate incorrect, incomplete or biased conclusions about the manuscript. The reviewer is responsible and accountable for the content of the review report.  Elsevier’s AI author policy states that authors are allowed to use generative AI and AI-assisted technologies in the writing process before submission, but only to improve the language and readability of their paper and with the appropriate disclosure, as per our instructions in Elsevier’s Guide for Authors opens in new tab/window. Reviewers can find such disclosure at the bottom of the paper in a separate section before the list of references.  Please note that Elsevier owns identity protected AI-assisted technologies which conform to the RELX Responsible AI Principles opens in new tab/window, such as those used during the screening process to conduct completeness and plagiarism checks and identify suitable reviewers. These in-house or licensed technologies respect author confidentiality. Our programs are subject to rigorous evaluation of bias and are compliant with data privacy and data security requirements.   Elsevier embraces new AI-driven technologies that support reviewers and editors in the editorial process, and we continue to develop and adopt in-house or licensed technologies that respect authors’, reviewers’ and editors’ confidentiality and data privacy rights.  View Elsevier's generative AI reviewer policies for books opens in new tab/window.   For editors The use of generative AI and AI-assisted technologies in the journal editorial process A submitted manuscript must be treated as a confidential document. Editors should not upload a submitted manuscript or any part of it into a generative AI tool as this may violate the authors’ confidentiality and proprietary rights and, where the paper contains personally identifiable information, may breach data privacy rights.   This confidentiality requirement extends to all communication about the manuscript including any notification or decision letters as they may contain confidential information about the manuscript and/or the authors. For this reason, editors should not upload their letters into an AI tool, even if it is just for the purpose of improving language and readability.   Peer review is at the heart of the scientific ecosystem and Elsevier abides by the highest standards of integrity in this process. Managing the editorial evaluation of a scientific manuscript implies responsibilities that can only be attributed to humans. Generative AI or AI-assisted technologies should not be used by editors to assist in the evaluation or decision-making process of a manuscript as the critical thinking and original assessment needed for this work is outside of the scope of this technology and there is a risk that the technology will generate incorrect, incomplete or biased conclusions about the manuscript. The editor is responsible and accountable for the editorial process, the final decision and the communication thereof to the authors.   Elsevier’s AI author policy opens in new tab/window states that authors are allowed to use generative AI and AI-assisted technologies in the writing process before submission, but only to improve the language and readability of their paper and with the appropriate disclosure, as per our instructions in Elsevier’s Guide for Authors opens in new tab/window. Editors can find such disclosure at the bottom of the paper in a separate section before the list of references. If an editor suspects that an author or a reviewer has violated our AI policies, they should inform the publisher.   Please note that Elsevier owns identity protected AI-assisted technologies which conform to the RELX Responsible AI Principles opens in new tab/window, such as those used during the screening process to conduct completeness and plagiarism checks and identify suitable reviewers. These in-house or licensed technologies respect author confidentiality. Our programs are subject to rigorous evaluation of bias and are compliant with data privacy and data security requirements.   Elsevier embraces new AI-driven technologies that support reviewers and editors in the editorial process, and we continue to develop and adopt in-house or licensed technologies that respect authors’, reviewers’ and editors’ confidentiality and data privacy rights. "
67. Policy for Acceptable Use of Large Language Models The International Society for Computational Biology (ISCB) has created an acceptable use policy for large language models (LLMs), which the journal follows. It is likely that these guidelines will be subject to change in the future as the development of these models continues to change.  Common Acceptable Uses:  As an aid to correct written text (spell checkers, grammar checkers)  As an aid to language translation, however, the researcher is responsible for the accuracy of the final text  As an algorithmic technique for research study  As an evaluation technique (to assist in finding inconsistencies or other anomalies)  It is permissible to include LLM generated text snippets as examples in research papers where appropriate, but these MUST be clearly labelled, and their use explained.  Assist in code writing, however, the researcher is responsible for the correct code  Create documentation for code, however, the researcher is responsible for the correct documentation  Any acceptable use of LLMs or related technologies to produce, or help to produce, part of the text, figures or other contents of the paper should be explicitly declared and documented with sufficient details in the supplementary materials.  Unacceptable Uses:  It is not acceptable to use LLMs or related technologies to draft papers (including but not limited to text, figures, tables, and references) from a prompt text. In essence, papers must be written by researchers.  LLMs cannot be listed as authors as they would not fulfil the requirements of authorship as laid out in the ICMJE guidelines.  Natural language processing tools driven by artificial intelligence (AI) do not qualify as authors, and the Journal will screen for them in author lists. The use of AI (for example, to help generate content, write code, or process data) should be disclosed both in cover letters to editors and in the Methods or Acknowledgements section of manuscripts. Please see the COPE position statement on Authorship and AI for more details.  If your usage of LLMs is not covered by any of these use cases, then please contact the Editor of the journal or Editorial Office."
68. BJD follows COPE’s policy that artificial intelligence (AI) tools, such as ChatGPT, cannot be a named author. These tools can neither meet the requirements for authorship as defined by the ICMJE criteria nor declare conflicts of interest or manage copyright and license agreements.  If AI tools have been used to write the paper, for the production of images or graphical elements of the paper, or in the collection and analysis of data, please disclose it in the Materials and Methods section of the paper including what tool was used and how. Authors are responsible for the content of their manuscript, even those parts produced by an AI tool, and are thus liable for any breach of publication ethics.​"
69. The following statement, issued by the Committee on Publication Ethics in February 2023, has been adapted by the AMS Committee on Publications. The full COPE position statement on Authorship and AI tools can be found on the COPE website.  The use of artificial intelligence (AI) tools such as ChatGPT or Large Language Models (LLMs) in research publications is expanding rapidly. COPE joins organisations, such as WAME and the JAMA Network among others, to state that AI tools cannot be listed as an author of a paper. AI tools cannot meet the requirements for authorship as they cannot take responsibility for the submitted work. As non-legal entities, they cannot assert the presence or absence of conflicts of interest nor manage copyright and license agreements. Authors who use AI tools in the writing of a manuscript, production of images or graphical elements of the paper, or in the collection and analysis of data, must be transparent in disclosing in the Materials and Methods (or similar section) of the paper how the AI tool was used and which tool was used. Authors are fully responsible for the content of their manuscript, even those parts produced by an AI tool, and are thus liable for any breach of publication ethics. Editors and referees are not to upload papers under review to an LLM in any format, for any reason. Many LLMs function by retaining the information fed into them for future use and are not transparent about how information uploaded may be integrated into future use. Among other concerns, this can create potential copyright and confidentiality issues."
70. AMS Publications follows a slightly modified version of the recommendations of the Committee on Publication Ethics (COPE) regarding the use of AI tools in manuscript preparation: Authors are fully responsible for the content of their manuscript, even those parts produced by an AI tool, and are thus liable for any breach of publication ethics. AI tools cannot meet the requirements for authorship as they cannot take responsibility for the submitted work. As non-legal entities, they cannot assert the presence or absence of conflicts of interest nor manage copyright and license agreements. Authors who make substantive use of AI tools in the writing of a manuscript, production of images or graphical elements of the paper, or in the collection and analysis of data, must be transparent in disclosing in the appropriate data/methods/materials sections of the paper how the AI tool was used and which tool was used."
71. IOP Publishing follows the Committee on Publication Ethics (COPE) position statement that AI tools cannot meet the requirements for authorship as they cannot take responsibility for the submitted work. As non-legal entities, they cannot assert the presence or absence of conflicts of interest nor manage copyright and license agreements.  There are many responsible and appropriate uses for generative AI within scholarly research and we support authors using it in this manner. When doing so, authors are encouraged to be transparent about their use of any generative AI tools in either the research or the drafting of the manuscript. Authors are also encouraged to maintain records of previous drafts, as well as any prompts used in the editing or generation of material within their manuscript.  Authors are responsible for ensuring that any written or visual content produced by or edited using a generative AI technology meets all IOP Publishing’s guidelines and policies. All AI-generated content must be checked to ensure it is accurate and free from plagiarism. Generative AI tools cannot be used to create, alter or manipulate original research data and results such as blots or measurements. Any generative AI tools used to create figures from data, such as graphs or charts, should be listed in the figure caption.  In cases where text in a manuscript has been generated, authors must ensure that they have critically revised this work for important intellectual content in order to meet the authorship criteria followed by IOP Publishing and set out by the International Council of Medical Journal Editors (ICMJE)."
72. AI Technologies The use of AI (artificial intelligence) technologies, including large language models and chatbots (e.g., ChatGPT), has grown rapidly in scholarly publishing. An AI tool is incapable of being held accountable, agreeing to take responsibility, and giving final approval for submitted work, all of which are conditions for authorship. Therefore, these inherent limitations preclude an AI tool from being named as an author on a paper. In instances where authors have used an AI technology in the course of their research or the preparation of their paper, transparency is critical. Authors are expected to disclose this information in the paper where appropriate, such as in the methods or acknowledgments, and detail what specific tools were used and how. AI technologies should be used cautiously and with appropriate human oversight. Authors remain wholly responsible for the integrity of any output from or work performed by an AI tool that is included within a paper."
73. Introduction   Generative Artificial Intelligence (AI) tools, such as large language models (LLMs) or multimodal models, continue to develop and evolve, including in their application for businesses and consumers.    Taylor & Francis welcomes the new opportunities offered by Generative AI tools, particularly in: enhancing idea generation and exploration, supporting authors to express content in a non-native language, and accelerating the research and dissemination process.    Taylor & Francis is offering guidance to authors, editors, and reviewers on the use of such tools, which may evolve given the swift development of the AI field.    Generative AI tools can produce diverse forms of content, spanning text generation, image synthesis, audio, and synthetic data. Some examples include ChatGPT, Copilot, Gemini, Claude, NovelAI, Jasper AI, DALL-E, Midjourney, Runway, etc.    While Generative AI has immense capabilities to enhance creativity for authors, there are certain risks associated with the current generation of Generative AI tools.    Some of the risks associated with the way Generative AI tools work today are:   Inaccuracy and bias: Generative AI tools are of a statistical nature (as opposed to factual) and, as such, can introduce inaccuracies, falsities (so-called hallucinations) or bias, which can be hard to detect, verify, and correct.  Lack of attribution: Generative AI is often lacking the standard practice of the global scholarly community of correctly and precisely attributing ideas, quotes, or citations.  Confidentiality and Intellectual Property Risks: At present, Generative AI tools are often used on third-party platforms that may not offer sufficient standards of confidentiality, data security, or copyright protection.   Unintended uses: Generative AI providers may reuse the input or output data from user interactions (e.g. for AI training). This practice could potentially infringe on the rights of authors and publishers, amongst others.   Authors   Authors are accountable for the originality, validity, and integrity of the content of their submissions. In choosing to use Generative AI tools, journal authors are expected to do so responsibly and in accordance with our journal editorial policies on authorship and principles of publishing ethics and book authors in accordance with our book publishing guidelines. This includes reviewing the outputs of any Generative AI tools and confirming content accuracy.    Taylor & Francis supports the responsible use of Generative AI tools that respect high standards of data security, confidentiality, and copyright protection in cases such as:   Idea generation and idea exploration  Language improvement  Interactive online search with LLM-enhanced search engines  Literature classification  Coding assistance  Authors are responsible for ensuring that the content of their submissions meets the required standards of rigorous scientific and scholarly assessment, research and validation, and is created by the author. Note that some journals may not allow use of Generative AI tools beyond language improvement, therefore authors are advised to consult with the editor of the journal prior to submission.   Generative AI tools must not be listed as an author, because such tools are unable to assume responsibility for the submitted content or manage copyright and licensing agreements. Authorship requires taking accountability for content, consenting to publication via a publishing agreement, and giving contractual assurances about the integrity of the work, among other principles. These are uniquely human responsibilities that cannot be undertaken by Generative AI tools.    Authors must clearly acknowledge within the article or book any use of Generative AI tools through a statement which includes: the full name of the tool used (with version number), how it was used, and the reason for use. For article submissions, this statement must be included in the Methods or Acknowledgments section. Book authors must disclose their intent to employ Generative AI tools at the earliest possible stage to their editorial contacts for approval – either at the proposal phase if known, or if necessary, during the manuscript writing phase.  If approved, the book author must then include the statement in the preface or introduction of the book. This level of transparency ensures that editors can assess whether Generative AI tools have been used and whether they have been used responsibly. Taylor & Francis will retain its discretion over publication of the work, to ensure that integrity and guidelines have been upheld.   If an author is intending to use an AI tool, they should ensure that the tool is appropriate and robust for their proposed use, and that the terms applicable to such tool provide sufficient safeguards and protections, for example around intellectual property rights, confidentiality and security.   Authors should not submit manuscripts where Generative AI tools have been used in ways that replace core researcher and author responsibilities, for example:    text or code generation without rigorous revision  synthetic data generation to substitute missing data without robust methodology   generation of any types of content which is inaccurate including abstracts or supplemental materials  These types of cases may be subject to editorial investigation.    Taylor & Francis currently does not permit the use of Generative AI in the creation and manipulation of images and figures, or original research data for use in our publications. The term “images and figures” includes pictures, charts, data tables, medical imagery, snippets of images, computer code, and formulas. The term “manipulation” includes augmenting, concealing, moving, removing, or introducing a specific feature within an image or figure. For additional information on Taylor & Francis’ image policy for journals, please see Images and figures.     Utilising Generative AI and AI-assisted technologies in any part of the research process should always be undertaken with human oversight and transparency. Research ethics guidelines are still being updated regarding current Generative AI technologies. Taylor & Francis will continue to update our editorial guidelines as the technology and research ethics guidelines evolve.   Editors and Peer Reviewers   Taylor & Francis strives for the highest standards of editorial integrity and transparency. Editors’ and peer reviewers’ use of manuscripts in Generative AI systems may pose a risk to confidentiality, proprietary rights and data, including personally identifiable information. Therefore, editors and peer reviewers must not upload files, images or information from unpublished manuscripts into Generative AI tools. Failure to comply with this policy may infringe upon the rightsholder’s intellectual property.    Editors    Editors are the shepherds of quality and responsible research content. Therefore, editors must keep submission and peer review details confidential.   Use of manuscripts in Generative AI systems may give rise to risks around confidentiality, infringement of proprietary rights and data, and other risks. Therefore, editors must not upload unpublished manuscripts, including any associated files, images or information into Generative AI tools.   Editors should check with their Taylor & Francis contact prior to using any Generative AI tools, unless they have already been informed that the tool and proposed use of the tool is authorised. Journal Editors should refer to our Editor Resource page for more information on our code of conduct.    Peer reviewers   Peer reviewers are chosen experts in their fields and should not be using Generative AI for analysis or to summarise submitted articles or portions thereof in the creation of their reviews.  As such, peer reviewers must not upload unpublished manuscripts or project proposals, including any associated files, images or information, into Generative AI tools.   Generative AI may only be utilised to assist with improving review language, but peer reviewers will at all times remain responsible for ensuring the accuracy and integrity of their reviews. "
74. Generative artificial intelligence (AI), as with traditional automated and manual editing services, has the potential to improve the clarity of submitted manuscripts when used to help revise or translate text written by the author. However, it is always the author’s responsibility to ensure that any editing process does not alter the intended meaning of the text and that references are cited as required. Use of any editing services or technologies should be specifically declared in the acknowledgments section of submitted manuscripts.  Unlike in the limited case above of authors revising or translating existing manuscript text generated by the human authors credited in the manuscript author list, any use of AI to produce new text, images, or other material for their manuscript must be described in detail in an accompanying cover letter and in an appropriate section of the manuscript itself. For example, AI-based generation of text or illustrations must be described in the Acknowledgments. Any use of AI in connection with the conduct of the study underlying the manuscript must be described in detail in the methods section of the manuscript.  It is inappropriate for peer reviewers to use generative AI when reviewing a manuscript on behalf of the AACR journals. For information see Peer Review.  AI-assisted technologies—such as those used to screen for manuscript completeness, check for plagiarism, identify image duplication or manipulation, or identify appropriate reviewers—are licensed technologies that respect author confidentiality. The AACR journals program has adopted such technologies and will consider adoption of any future technologies when they respect authors’, reviewers’, and editors’ confidentiality and data privacy rights.  *Generative AI is a type of AI technology that can generate content—including text, images, audio, video, animation, 3D models, etc.—based on a variety of inputs. Examples include ChatGPT, Bard, DALL-E, Jasper AI, NovelAI, Rytr and others."
75. Anyone with access to the internet now has free access to artificial intelligence (AI) applications that can quickly develop text-based responses to specific questions. Large language model applications such as ChatGPT have made it possible to construct research manuscripts, abstracts, and letters to the editor that are extremely difficult to differentiate from human-derived work (see Supplementary Material).  This rapid improvement in AI capabilities may offer some benefits to journals, publishers, readers, and, ultimately, patients. For example, large language models such as ChatGPT might – with suitable human oversight – be able to create plain-language summaries of complex research quickly and at scale, which might make the scientific record more accessible to the public.1 AI-based tools also may facilitate the creation of consistent, clear visual presentations of complex data. And, of course, an exciting feature of transformative technologies is the potential for benefits that we cannot imagine at the outset.  However, misuse of these tools can undermine the integrity of the scholarly record; indeed, there are examples of this happening already. Researchers and authors need to be aware that AI-detection software development is in the refinement stage. When available, these tools will be used by our journals in the same way that plagiarism software is currently deployed. Some have suggested that large language models should be considered authors; in fact, ChatGPT has been listed as a co-author in published research,2 and even is a registered author in the ORCiD and SCOPUS databases. This practice is inappropriate. Under the authorship guidelines of the International Committee of Medical Journal Editors, which all of our journals follow, an author must meet a number of important standards, including being willing to be accountable for all aspects of the work, to ensure that questions related to the accuracy or integrity of the work will be suitably investigated and resolved, to be able to identify which co-authors are responsible for specific parts of the work, and to have confidence in the integrity of the contributions of their co-authors.3 A large language model has no means to comply with such standards, and, for that reason – as well as, we believe, simple common sense – AI-based tools cannot be authors on scientific papers.  Other important concerns have been raised about the use of AI-driven tools in scientific reporting, including the possibilities that they may produce material that is inaccurate or out of date,4 they may conjure up “sources” that do not exist,5 and – this from the team that built ChatGPT – they may generate “plausible-sounding but incorrect or nonsensical answers,” which the coders have said is “challenging” to fix because “during RL [reinforcement learning] training, there’s currently no source of truth”.6 We believe that our readers, and the patients for whom they are responsible, deserve better.  For these reasons and others, our editorial boards have agreed on the following standards concerning AI applications that create text, tables, figures, images, computer code, and/or video:  AI applications cannot be listed as authors.  Whether and how AI applications were used in the research or the reporting of its findings must be described in detail in the Methods section and should be mentioned again in the Acknowledgements section.  Our editorial boards will closely follow the scientific developments in this area and will adjust editorial policy as frequently as required."
76. Copywriting any part of an article using a generative AI tool/LLM would not be permissible, including the generation of the abstract or the literature review, for as per Emerald's authorship criteria, the author(s) must be responsible for the work and accountable for its accuracy, integrity, and validity. In line with standard academic practice, however, Emerald permits the use of examples of generative AI for illustrative purposes as part of scholarly critique and discussion, with the exception of images created by AI tools or large-scale generative models; these examples must be appropriately flagged in the text and be fully cited and referenced in accordance with formatting requirements. The generation or reporting of results using a generative AI tool/LLM is not permissible, for as per Emerald's authorship criteria, the author(s) must be responsible for the creation and interpretation of their work and accountable for its accuracy, integrity, and validity. The in-text reporting of statistics using a generative AI tool/LLM is not permissible due to concerns over the authenticity, integrity, and validity of the data produced, although the use of such a tool to aid in the analysis of the work would be permissible. Copy-editing an article using a generative AI tool/LLM in order to improve its language and readability would be permissible as this mirrors standard tools already employed to improve spelling and grammar, and uses existing author-created material, rather than generating wholly new content, while the author(s) remains responsible for the original work. The submission and publication of images created by AI tools or large-scale generative models is not permitted. Any authors listed should be able to identify which co-author wrote which section of the paper and have full confidence in the integrity of their co-author's work.  If you have any doubts about meeting the above criteria, please discuss these with your co-authors or with your institution's Research Integrity Officer, prior to submission.  When authorship disputes arise, we always try to help the parties involved reach an agreement. However, as it relates to the research stage, it's not possible for us or our editors to comment on the level of contribution by each author. Please refer to the Committee on Publication Ethics (COPE) website for the processes we follow.  If the matter can't be resolved, we may refer it to the authors' institutions, or issue an expression of concern."
77. After manuscript submission, no authorship changes (including the authorship list, author order, and who is designated as the corresponding author) should be made without the approval of the editor. All co-authors must agree on the change(s), and neither the Journal nor the publisher mediates authorship disputes. If individuals cannot agree on the authorship of a submitted manuscript, contact the editorial office. The dispute must be resolved among the individuals and their institution(s) before the manuscript can be accepted for publication. If an authorship dispute or change arises after a paper is accepted, contact OUP’s Author Support team. COPE provides guidance for authors on resolving authorship disputes."
78. CID supports the World Association of Medical Editors’ recommendations on AI, chatbots and scholarly manuscripts. If AI, a Large Language Model (LLM), or a similar tool is used in the development of a paper for CID, the following is required:  The AI/LLM cannot be credited as an author, as authorship requires that the author be accountable for the submitted/published work, and artificial intelligence cannot fulfill this requirement of authorship. Authors listed on the paper must review the content generated by the AI/LLM and take full responsibility for it, as they would for any other content within the submitted/published work. The use of AI/LLM tools must be noted in response to the manuscript submission question, “Did any author utilize any AI writing assistance in the preparation of this manuscript (including text, graphics/image creation, data)?” The use of AI/LLM tools must be documented in the Methods, Acknowledgments, or another appropriate section of the paper. If an editor or reviewer uses AI in their evaluation of a paper, the editor/reviewer must disclose this to each other and to the author of the paper. Editors and reviewers may not upload a manuscript to an AI, LLM, or similar system, as this would violate confidentiality."
79. Use of generative AI and AI-assisted tools • Although in an early stage and likely to quickly evolve, authors shall need to understand and and accept the following general guidelines on the subject and use of Artificial Intelligence (AI) in the creation of the contributions to be published in our journals and shall ensure compliance with them: o The use of AI and AI assisted technologies (hereafter AI) is permitted in the prewriting (research) process; o The use of AI in the writing process is only permitted to enhance readability and language of the work; o The use of AI may not replace the intellectual exercise of the author such as reasoning, recommendations, conclusions, etc.; o The author should be transparent about the use of AI and disclose what type(s) of AI has (have) been used in the Online Contribution\s creative process. o The author is ultimately responsible and accountable for the work delivered. "
80. Current Opinion papers should have a maximum of 3 authors. The journal does not consider Artificial Intelligence authoring tools to meet the requirements for Authorship as recommended by the ICMJE. The use of such tools may be included in the article’s Acknowledgements.
81. Generative AI and AI-assisted technologies (e.g., large language models) are expected to be increasingly used to create content. In the writing process of manuscripts, using AI and AI-assisted technologies to complete key researcher work, such as producing scientific insights, analyzing and interpreting data or drawing scientific conclusions, is not allowed, and they should only be used to improve the readability and language of manuscripts.  AI and AI-assisted technologies should be used under human control and supervision as they may generate incorrect or prejudiced output, and they should not be listed as an author or co-author, nor cited as an author.  The use of AI and AI-assisted technologies should be disclosed by authors in their manuscripts, and a statement will be required in the final publication.  OAE will keep monitoring the development and adjust the policy when necessary."
82. AI Authorship Large Language Models (LLMs), such as ChatGPT, do not currently satisfy our authorship criteria. Notably an attribution of authorship carries with it accountability for the work, which cannot be effectively applied to LLMs. Use of an LLM should be properly documented in the Methods section (and if a Methods section is not available, in a suitable alternative part) of the manuscript. The use of an LLM (or other AI-tool) for “AI assisted copy editing” purposes does not need to be declared. In this context, we define the term ""AI assisted copy editing"" as AI-assisted improvements to human-generated texts for readability and style, and to ensure that the texts are free of errors in grammar, spelling, punctuation and tone. These AI-assisted improvements may include wording and formatting changes to the texts, but do not include generative editorial work and autonomous content creation. In all cases, there must be human accountability for the final version of the text and agreement from the authors that the edits reflect their original work.  Generative AI Images The fast moving area of generative AI image creation has resulted in novel legal copyright and research integrity issues. As publishers, we strictly follow existing copyright law and best practices regarding publication ethics. While legal issues relating to AI-generated images and videos remain broadly unresolved, Springer Nature journals are unable to permit its use for publication.   Exceptions:  Images/art obtained from agencies that we have contractual relationships with that have created images in a legally acceptable manner. Images and videos that are directly referenced in a piece that is specifically about AI and such cases will be reviewed on a case-by-case basis. The use of generative AI tools developed with specific sets of underlying scientific data that can be attributed, checked and verified for accuracy, provided that ethics, copyright and terms of use restrictions are adhered to. *All exceptions must be labelled clearly as generated by AI within the image field.  As we expect things to develop rapidly in this field in the near future, we will review this policy regularly and adapt it if necessary.  Please note: Not all AI tools are generative. The use of non-generative machine learning tools to manipulate, combine or enhance existing images or figures should be disclosed in the relevant caption upon submission to allow a case-by-case review."
83. Author teams who use artificial intelligence (AI) tools, machine learning, language models, or similar technologies when preparing a manuscript for submission to the Cochrane Database of Systematic Reviews must include a statement in the Acknowledgements section, indicating which tool(s) was used, the version (if applicable), and for what purpose. Tools used to improve spelling or grammar are not included in this policy.  In line with the position of COPE and other scientific publications, tools that use artificial intelligence (AI), machine learning, language models, or similar technologies to generate content are unable to fulfil Cochrane's criteria for authorship, and therefore cannot be listed as authors on Cochrane Library publications."
84. Large Language Models (LLMs), such as ChatGPT, do not currently satisfy our authorship criteria. Notably an attribution of authorship carries with it accountability for the work, which cannot be effectively applied to LLMs. Use of an LLM should be properly documented in the Methods section (and if a Methods section is not available, in a suitable alternative part) of the manuscript. In response to emerging information, advice, guidance and policy around artificial intelligence (AI), we have created a dedicated AI section in our Editorial Policy page. Please familiarize yourself with this content and comply with relevant policies."
85. Use of Generative AI and AI-assisted Technologies in the Peer Review Process Since the use of AI technology has increased, it has brought its own challenges regarding the originality of the review of submitted manuscripts. Bentham Science has been striving to improve its policies accordingly. With time, we will continue to update our policies to support our reviewers, authors, and editors.  The quality of the peer review of submitted articles has been our top priority. The reviewers are advised not to use AI technologies or any other related assisting resources to generate review reports that could compromise the integrity and confidentiality of the reports."
86. In accordance with COPE guidance, AI tools should not be listed as an author of a paper. Large Language Models (LLMs), such as ChatGPT, do not meet the requirements for authorship as they cannot take responsibility for the submitted work. Where LLMs have been used in the preparation of the manuscript, this should be clearly disclosed in the Materials and Methods section."
87. 7.1. Use of Artificial Intelligence (AI) Technologies in Manuscript Preparation The Diabetes & Metabolism Journal follows ICMJE guidelines regarding the use of AI manuscript preparation. Traditional and generative AI, including language models, chatbots, machine learning, or similar technologies, may be used to improve the readability and language accuracy of scientific writing. However, AI tools cannot be credited as authors. 7.2. Use of AI-Generated Images Due to unresolved legal and ethical issues, the use of AIgenerated images and videos is restricted. Consequently, AI tools are not permitted to create artwork, including book covers, commissioned content covers, or graphical abstracts. 7.3. Disclosure of AI Technologies Authors must disclose the use of AI technologies during manuscript submission. This includes specifying the tools used, such as the model’s name, version, and manufacturer, and explaining their role in the writing process. Authors must also confirm that there is no plagiarism in the AI-generated text or images. AI-generated content should not be cited as a primary source. 7.4. AI Use by Peer Reviewers AI tools can produce outdated, nonsensical, biased, or incorrect information. Additionally, manuscripts may contain sensitive or proprietary information that should not be shared outside the peer review process. Therefore, peer reviewers are asked not to upload manuscripts into AI tools. The journal is exploring providing access to secure AI tools for peer reviewers. If AI tools are used in any capacity to evaluate a manuscript, reviewers must transparently declare their use in their review reports."
88. Use of Artificial Intelligence, Large Language Models, and Machine Learning ADA has adopted and modified JAMA’s instructions for authors and guidance for authors, peer reviewers, and editors to address the roles of artificial intelligence (AI), large language models (LLMs), and machine learning in the development of content to be presented in ADA publications. See below for more information related to authorship, image integrity, reproduced and re-created material, and peer review.  AI, Authorship, and Content Creation. Nonhuman artificial intelligence, language models, machine learning, or similar technologies do not qualify for authorship.  If these models or tools are used to create content or assist with writing or manuscript preparation, authors must take responsibility for the integrity of the content generated by these tools.  Authors should report the use of artificial intelligence, language models, machine learning, or similar technologies to create content or assist with writing or editing of manuscripts in the Acknowledgments section or the Methods section if this is part of formal research design or methods, as well as in the comments to the editors at the time of submission.  This should include a description of the content that was created or edited and the name of the language model or tool, version and extension numbers, manufacturer, and (where relevant) the query or prompt to create or assist with the development of content. (Note: this does not include basic tools for checking grammar, spelling, references, etc.).  AI and Image Development. The submission and publication of images created by artificial intelligence, machine learning tools, or similar technologies is discouraged, unless part of formal research design or methods, and is not permitted without clear description of the content that was created and the name of the model or tool, version and extension numbers, manufacturer, and (where relevant) the query or prompt to create or assist with the development of content. Authors must take responsibility for the integrity of the content generated by these models and tools.  AI and Reproduced Material. The submission and publication of content created by artificial intelligence, language models, machine learning, or similar technologies is discouraged, unless part of formal research design or methods, and is not permitted without clear description of the content that was created and the name of the model or tool, version and extension numbers, manufacturer, and (where relevant) the query or prompt to create or assist with the development of content. Authors must take responsibility for the integrity of the content generated by these models and tools.  AI and Peer Review. A manuscript reviewer may not enter any part of the manuscript or abstract or the text of the review into an LLM, chatbot, or similar AI tool, as it is a violation of confidentiality. Manuscripts submitted to the journal are confidential and may not be reused or shared in any way. If during the course of the review a reviewer uses an AI tool as a resource in a manner that does not violate the journal’s confidentiality policy, the name of the tool and how it was used must be provided. Peer reviewers are responsible for all content included in a review. "
89. Authors must disclose, both in their manuscript and cover letter, any use of artificial intelligence (AI)-assisted technologies (such as Large Language Models [LLMs], chatbots, or image creators). Chatbots (such as ChatGPT) should not be listed as authors because they cannot be responsible for the accuracy, integrity and originality of the work, and these responsibilities are required for authorship (see Authorship criteria). Therefore, humans are responsible for any submitted material that includes the use of AI-assisted technologies. Authors should carefully review and edit the result because AI can generate authoritative-sounding output that can be incorrect, incomplete or biased. Authors should not list AI and AI-assisted technologies as an author or co-author, nor cite AI as an author. Authors should be able to assert that there is no plagiarism in their paper, including in text and images produced by the AI. Humans must ensure there is appropriate attribution of all quoted material, including full citations."
90. – If artificial intelligence (AI) was used in generating the data or compiling the manuscripts, this must be disclosed on manuscript submission. AI may not be attributed the status of an author. The authors are exclusively responsible for the originality (the use of AI may lead to violation of copyright), accuracy, and integrity of the publication."
91. Instructions for authors Page Path HOME > For contributors > Instructions for authors For contributors For Authors Instructions for authors Article processing charge e-submission For Reviewers Instructions for reviewers How to become a reviewer Best reviewers For Readers Readership Subscription Permission guidelines Instructions for authorsInstructions for authors Copyright transfer agreementCopyright transfer agreement Author's checklistAuthor's checklist WMA-Declaration of HelsinkiWMA-Declaration of Helsinki  Last modified August 3, 2024  Please carefully review the complete instructions for authors before submitting your manuscript to the Diabetes & Metabolism Journal. These instructions can be found at https://e-dmj.org or https://submit.e-dmj.org. Table of Contents 1. ARTICLE PROCESSING CHARGES 2. RESEARCH AND PUBLICATION ETHICS 3. EDITORIAL POLICIES 4. MANUSCRIPT SUBMISSION 5. MANUSCRIPT CATEGORIES AND FORMATS 6. PEER REVIEW 7. USE OF ARTIFICIAL INTELLIGENCE 8. MANUSCRIPT PROCESSING AFTER ACCEPTANCE The Diabetes & Metabolism Journal (International Organization for Standardization abbreviation: Diabetes Metab J; dmj) is the official publication of the Korean Diabetes Association. It is published bimonthly on the first day of January, March, May, July, September, and November. The journal’s mission is to disseminate new knowledge, contribute to the cure for diabetes mellitus, and advance diabetology by sharing the latest scientific information. Manuscripts must be written in English and prepared according to the provided guidelines. For any issues not addressed here, authors should refer to the International Committee of Medical Journal Editors (ICMJE) Recommendations for the Conduct, Reporting, Editing, and Publication of Scholarly Work in Medical Journals (https://www.icmje.org/recommendations). The journal follows an Open-Access Journal policy, making all content freely accessible online for reading, downloading, and printing at no cost. Contact information Diabetes & Metabolism Journal Editorial Office 101-2104, Lotte Castle President, 109 Mapo-daero, Mapo-gu, Seoul 04146, Korea Tel: +82-2-714-9064 / Fax: +82-2-714-9084 Email: diabetes@kams.or.kr 1. ARTICLE PROCESSING CHARGES For articles accepted for publication in the Diabetes & Metabolism Journal, an article processing charge of $600 will apply. Submission can proceed once the payment method has been agreed upon. The applicable fee must be paid before publication. Starting January 1, 2025, the article processing charge will increase to $1,000 for accepted articles. Industry-sponsored articles will incur a charge of $3,000, while invited articles are exempt from any fees. • Waiver Policy The Diabetes & Metabolism Journal offers waivers and discounts for authors from low-income countries, as classified by the World Bank (https://datahelpdesk.worldbank.org/knowledgebase/articles/906519/) as of July in the year prior to submission. Requests for waivers should be made at the time of submission by contacting the editorial office (diabetes@kams.or.kr). To maintain editorial impartiality, editors are not informed when a waiver has been granted. 2. RESEARCH AND PUBLICATION ETHICS The Diabetes & Metabolism Journal adheres to the guidelines and best practices set by professional organizations, including the ICMJE Recommendations, the Committee on Publication Ethics (COPE) Guidelines (https://publicationethics.org/resources/guidelines), and the Good Publication Practice Guideline for Medical Journals (https://www.kamje.or.kr/board/view?b_name=bo_publication&bo_id=13). Additionally, all procedures for addressing research and publication misconduct will follow the applicable COPE flowcharts (https://publicationethics.org/guidance/Flowcharts). 2.1. Authorship and Contribution 1) Author qualifications According to ICMJE Recommendations, authors of a paper must meet the following criteria: (1) make substantial contributions to the conception and design of the study, or to the acquisition, analysis, and interpretation of data; (2) draft the article or critically revise it for significant intellectual content; (3) give final approval of the version to be published; and (4) agree to be accountable for all aspects of the work, ensuring that any questions related to the accuracy or integrity of any part of the work are appropriately investigated and resolved. All authors should meet all four criteria. The author list should include all relevant contributors and no others, providing proper credit and accountability for each researcher’s contributions. 2) Author contributions statements Authors must include a statement at the end of the manuscript, under a section titled “Author Contributions,” specifying each author’s role and responsibilities. This requirement applies to all manuscripts, including review articles. Individuals who do not meet the four criteria mentioned above should be acknowledged in the Acknowledgments section as contributors. 3) Authorship changes Any changes in authorship (adding, removing, or rearranging authors) after the initial manuscript submission must be accompanied by a letter to the editor, signed by all authors. The journal will not correct authorship after publication unless it is due to an editorial error. 4) Role of corresponding author The corresponding author is primarily responsible for communication with the journal during the manuscript submission, peer review, and publication process. This includes ensuring that all administrative requirements, such as authorship details, ethics committee approval, clinical trial registration, and conflict of interest forms, are properly completed. The corresponding author should be available throughout the submission and peer review stages to respond promptly to editorial queries. After publication, they should be prepared to address critiques and cooperate with any journal requests for data or additional information related to the article. 5) Recommendations for collaborating with personal connections Authors planning to involve minors (under 19 years old) or family members (such as spouses, children, or relatives) in their research, whether through co-authoring papers or presentations, must clearly disclose this in the cover letter. For more details, please refer to the Guidelines for Preventing Illegitimate Authorship by the National Research Foundation of Korea (https://cre.nrf.re.kr). 2.2. Disclosure of Conflict of Interest Authors submitting to the Diabetes & Metabolism Journal must declare all competing interests related to their work. Every manuscript should include a “Conflict of Interest” section at the end, listing any financial or non-financial competing interests. Financial conflicts, such as employment, consultancies, stock ownership, honoraria, and paid expert testimony, are often the most obvious. However, conflicts can also arise from personal relationships, academic competition, and intellectual passion (https://www.icmje.org/conflicts-of-interest). If there are no competing interests, the statement should read, “No potential conflict of interest relevant to this article was reported.” For studies sponsored by third parties, authors must describe the sponsor’s role in study design, data collection, analysis, interpretation, report writing, and the decision to submit the manuscript. If the sponsor had no such involvement, this should be clearly stated. Additionally, potential conflicts of interest of editorial board members should also be disclosed in the manuscript. 2.3. Statement of Human and Animal Rights All studies involving humans must adhere to the principles outlined in the World Medical Association Declaration of Helsinki: Ethical Principles for Medical Research Involving Human Subjects (https://www.wma.net/what-we-do/medical-ethics/declaration-of-helsinki). For studies involving animal experiments, care and use of animals must comply with national laws and institutional regulations. The ethical treatment of all experimental animals should align with the guidelines provided by the Institutional Animal Care and Use Committee. Approval from the relevant animal ethics committee must be documented and available for submission if requested by the editors or reviewers. 2.4. Statement of Informed Consent and Institutional Review Board Approval Research involving human subjects, material, or data must have been approved by an appropriate ethics committee. The manuscript should include a statement confirming this approval, with the name of the ethics committee and the reference number. If the study was exempt from requiring ethics approval, this should also be mentioned, including the name of the committee that granted the exemption. During the review process, the Institutional Review Board (IRB) approval document may be requested, if necessary. For all research involving human subjects, informed consent must be obtained from participants, and a statement confirming this should be included in the manuscript. Identifiable information, such as names, initials, hospital numbers, dates of birth, or other protected healthcare information, should not be disclosed. For animal studies, the manuscript should state that the experimental procedures, including breeding and use of laboratory animals, were approved by the Research Ethics Committee (REC) of the institution where the research was conducted or that they comply with the institution’s REC guidelines or the National Institutes of Health (NIH) Guide for the Care and Use of Laboratory Animals. Authors are required to retain the raw experimental data for at least 1 year after publication and should be prepared to present this data if required by the editorial board. 2.5. Registration of Clinical Trial Research Any research involving clinical trials should be registered with a primary national clinical trial registry. This includes registries, such as the Clinical Research Information Service (CRIS; https://cris.nih.go.kr), the World Health Organization Registry Network (https://www.who.int/clinical-trials-registry-platform/network/primary-registries), or ClinicalTrials. gov (https://clinicaltrials.gov), a service of the U.S. NIH. Please ensure that the clinical trial registration number is included on the manuscript’s title page. 2.6. Originality and Duplicate Publication Submitted manuscripts must be original and not under consideration for publication in another magazine or journal. No part of the manuscript may be published elsewhere without the editorial board’s permission. Figures and tables can be reused freely if the original source is properly credited under the Creative Commons Non-Commercial License. Authors are required to resolve any copyright issues when citing figures or tables from non-open access journals. All submissions are screened for plagiarism or duplicate publication using Similarity Check (https://www.crossref.org/services/similarity-check). If such issues are found, the journal will be notified, and appropriate penalties may be imposed on the authors, with their affiliated institutions also being informed. 2.7. Secondary Publication Manuscripts may be republished if they meet the ICMJE’s criteria for secondary publication (https://www.icmje.org/recommendations/browse/publishing-and-editorial-issues/overlapping-publications.html) as follows: • Authors must obtain approval from the editors of both journals (the editor handling the secondary publication must have access to the primary version). • The primary publication retains priority, with a publication interval agreed upon by the editors of both journals and the authors. • The secondary publication is intended for a different audience; an abbreviated version may suffice. • The secondary version must accurately reflect the data and interpretations of the primary version. • The secondary version must inform readers, peers, and documenting agencies that the paper has been published elsewhere, in whole or in part (e.g., “This article is based on a study first reported in the [journal title, with full reference]”), and must cite the primary reference. • The title of the secondary publication should indicate that it is a secondary publication (complete or abridged republication or translation) of a primary publication. Note that the U.S. National Library of Medicine (NLM) does not consider translations as “republications” and does not cite or index them if the original article was published in a Medline-indexed journal. 2.8. Process to Manage the Research and Publication Misconduct The Diabetes & Metabolism Journal is a member of Similarity Check’s plagiarism detection initiative and takes all cases of publication misconduct seriously. If the editorial office identifies suspected research and publication misconduct, such as a redundant (duplicate) publication, plagiarism, data fabrication, changes in authorship, undisclosed conflicts of interest, and other ethical issues, the resolution process will follow the COPE flowcharts. Reviewers are responsible for reporting any suspected issues with a manuscript to the editor. If the investigation confirms scientific misconduct, the article will be retracted. Authors may be invited to prepare the retraction, which must be submitted with a copyright assignment statement signed by all authors. If the paper is unpublished, the editor can reject it outright. Instances of misconduct will be reported to the editorial board, and the editor may impose sanctions, notify editors of other biomedical journals, or, depending on the severity, inform the author’s institution. The journal will not hesitate to publish errata, corrigenda, clarifications, retractions, or apologies when the misconduct is confirmed. 2.9. Editorial Responsibilities The editorial board is committed to upholding high publication ethics standards. This includes providing clear guidelines for retracting articles, preserving the integrity of academic records, prioritizing intellectual and ethical standards over commercial interests, and publishing corrections, clarifications, retractions, or apologies as needed. Editors are responsible for accepting or rejecting articles, avoiding conflicts of interest, promoting corrections or retractions when errors are identified, and preserving reviewer anonymity. 3. EDITORIAL POLICIES 3.1. Copyright Authors must declare that the submitted work is original and does not infringe on any existing copyrights. Upon publication, all papers become the permanent property of the Korean Diabetes Association. Each author is required to sign an authorship responsibility and copyright transfer agreement, confirming their fulfillment of authorship criteria. The agreement will be confirmed via email from each author after acceptance. Additionally, authors are responsible for obtaining written permission to reproduce any material that has been previously published, in any media, including electronic formats. Copies of permission letters for any reproduced copyrighted material must be provided. Submitted materials will only be returned to the author upon specific request. 3.2. Open-Access License The Diabetes & Metabolism Journal is an open-access journal available free of charge. Articles are distributed under the terms of the Creative Commons Attribution Non-Commercial License (https://creativecommons.org/licenses/by-nc/4.0), which permits unrestricted noncommercial use, distribution, and reproduction in any medium, provided the original work is properly cited. Users may freely use, reproduce, disseminate, or display the open-access version of content from this journal for noncommercial purposes. For any commercial use of material from this journal, permission must be obtained from the Korean Diabetes Association (email: diabetes@kams.or.kr). 3.3. Article Sharing (Author Self-Archiving) Policy Authors may share their research in various ways, including on preprint servers, social media, at conferences, and in educational materials, in accordance with our open-access policy. However, submitting the same manuscript to multiple journals is strictly prohibited. 3.4. Data Sharing Policy The Diabetes & Metabolism Journal encourages data sharing wherever possible, unless ethical, privacy, or confidentiality concerns prevent it. Authors are encouraged to deposit their data in a publicly accessible repository and provide a link to the digital object identifier (DOI) within the manuscript. The journal adheres to the ICMJE Recommendations for data sharing statements (https://www.icmje.org/recommendations). Authors may also refer to the editorial, “Data Sharing Statements for Clinical Trials: A Requirement of the International Committee of Medical Journal Editors,” published in the Journal of Korean Medical Science (https://doi.org/10.3346/jkms.2017.32.7.1051). 3.5. Archiving The full text of articles from the Diabetes & Metabolism Journal has been archived in PubMed Central (https://www.ncbi.nlm.nih.gov/pmc/journals/1508) since 2010 (starting from volume 34), the Korea Citation Index (https://www.kci.go.kr), and the National Library of Korea (https://nl.go.kr). The journal ensures the long-term availability of its contents, even if the journal ceases publication, through these archiving platforms. 3.6. Preprint Policy A preprint is a version of a scholarly paper that has not yet undergone formal peer review or been published in a peer reviewed journal. The Diabetes & Metabolism Journal allows authors to submit preprints without it being considered duplicate submission or publication. Authors are encouraged to disclose the preprint DOI in their cover letter during submission. If not disclosed, the preprint may be flagged by plagiarism detection tools such as Similarity Check or Copy Killer. Preprint submissions will undergo the same peer review process as regular submissions. If accepted for publication, authors should update the preprint with a link to the published article in the Diabetes & Metabolism Journal, including its DOI. It is strongly recommended that authors cite the published article in the Diabetes & Metabolism Journal rather than the preprint in future submissions to other journals. 3.7. Peer Review Policy All submissions, including invited papers, undergo peer review. The Diabetes & Metabolism Journal employs a doubleblind peer review process, ensuring that both authors and reviewers remain anonymous to each other, while the editor is aware of their identities throughout the process. Reviewers are chosen by the editorial board based on their expertise, publication history, and prior review performance. During the peer review process, reviewers communicate exclusively with the editor. An initial decision is typically made within 2 weeks of a reviewer agreeing to assess a manuscript. Information about the review process or editorial decision process is not published on the article page. Manuscripts submitted by editors, employees, or members of the editorial board are treated as the same as other unsolicited submissions. The authors of these manuscripts do not participate in the selection of reviewers or the decision-making process. Editors will not handle their submissions, even if commissioned. The conflict of interest statements should be included as follows: Conflicts of Interest: [Author name] has been an editorial board member of the Diabetes & Metabolism Journal since [Year] but has no role in the decision to publish this article. No other potential conflicts of interest relevant to this article were reported. 4. MANUSCRIPT SUBMISSION 4.1. Online Submission All manuscripts must be submitted online through the Korean Diabetes Association’s manuscript submission system (https://submit.e-dmj.org). The entire review and editing process is conducted via this system. Authors can track the status of their manuscript, including any questions or updates related to the review process, directly on the website. Notifications regarding changes in the manuscript’s status will be sent to both the corresponding author and the first author. Detailed submission instructions are available on the website. For any issues, please contact the editorial office. 4.2. Manuscript Preparation Before submitting a new manuscript, please complete the Author Checklist (https://e-dmj.org/file/DMJ-checklist.pdf) and ensure that all points have been addressed. Prior to logging into the online submission system, please prepare the following documents, which will be required during electronic submission. Manuscripts must include a title page containing the following information: • A full disclosure to the editor regarding any submissions or previous reports that might be considered redundant publications of the same or very similar work. • A statement of any financial or other relationships that could lead to a conflict of interest. • A declaration that the manuscript has been read and approved by all the authors, that the authorship criteria outlined in this document have been met, and that each author believes that the manuscript represents honest work. For more information, please refer to the “Title page” section. 5. MANUSCRIPT CATEGORIES AND FORMATS 5.1. General Principles 1) Manuscripts should be prepared using Microsoft Word (.doc or .docx). The entire manuscript, including the title page, abstract, main text, acknowledgments, references, tables, and figure legends, should be double-spaced with a 12-point font and 3 cm margins on all sides of A4 (21×30 cm) or U.S. letter-sized paper (8½×11 in). Page numbers should be centered at the bottom of each page, starting with the title page. 2) Abbreviations should be used only when necessary for clarity. If an abbreviation is needed due to repetition, introduce it in parentheses when the term first appears. 3) Laboratory measurements should be reported in International System of Units (SI). In certain cases, non-SI (conventional) units can also be used, but consistency in unit usage is required. 4) For the specific study design, authors should follow appropriate reporting guidelines, such as CONSORT (https://www.consort-statement.org) for randomized controlled trials, STROBE (https://www.strobe-statement.org) for observational studies, PRISMA (https://www.prisma-statement.org) for systematic reviews and meta-analyses, and CARE (https://www.care-statement.org) for case reports. Additional reporting guidelines can be found at the EQUATOR Network (https://www.equator-network.org) and U.S. NLM (https://www.nlm.nih.gov/services/research_report_guide.html). 5.2. Original Articles Manuscripts should be organized as follows: title page, abstract with keywords, main text (introduction, methods, results, and discussion), conflicts of interest, funding information, acknowledgments, references, tables, and figure legends. Original articles should not exceed 4,000 words (excluding abstract, references, and tables or figure legends), include no more than 50 references, and contain up to six tables or figures. 1) Title page Manuscripts must include a title page with following information: • Title: The title should be no longer than 20 English words. Capitalize the first letter of each word. Avoid acronyms unless absolutely necessary. • Running title: Provide a short running title of fewer than 50 characters, including spaces. • Author list and affiliations: Include the full names and institutional affiliations of all authors. For multicenter studies, indicate each author’s affiliation using superscript Arabic numbers (e.g., 1, 2, 3). • Corresponding author: Include the name, postal code, address, and email of the corresponding author. • Conflicts of interest: Disclose any potential conflicts of interest. If none exist, state, “No potential conflict of interest relevant to this article was reported.” • Author contributions: Specify each author’s contribution to the manuscript using the Contributor Roles Taxonomy (CRediT) format (https://credit.niso.org/). • Open Researcher and Contributor ID (ORCID): Provide the ORCID IDs of the corresponding and first authors. Authors can obtain an ORCID ID by registering at https://orcid.org. This information should be included during submission but should not appear in the main text. After acceptance, this section will be published following the Discussion section. • Funding: Detail the sources of funding that supported the work and describe the role of any sponsors or funders. If they had no role, include, “The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.” • Acknowledgments: Mention any individuals who contributed to the study or manuscript but do not meet the criteria for authorship. If there are none, write “None.” 2) Abstract and Keyword • The abstract should be self-contained and comprehensible without needing to refer to the main text. • It should be concise (fewer than 250 words) and structured to clearly describe concisely the Background, Methods, Results, and Conclusion. • Include three to ten keywords at the end of the abstract, reflecting the manuscript’s content, using MeSH terms in Medline (http://www.nlm.nih.gov/mesh/MBrowser.html). • Provide the clinical trial registration number at the end of the abstract. 3) Main text The main text should be organized into the following sections: Introduction, Methods, Results, and Discussion. Use appropriate headings and subheadings in the Methods and Results sections. References, figures, and tables must be cited numerically in the order mentioned in the text. • Introduction: Provide context or background for the study. Clearly state the specific purpose, research objective, or hypothesis of the study. Only cite directly relevant references and avoid including data or conclusions from the current work. • Methods: Present materials, methods, and study design in detail. Clearly describe the selection of participants (including controls), eligibility and exclusion criteria, and the source population. Use sex for biological factors and gender psychosocial, or cultural factors. Experimental methods should be detailed enough to allow replication by readers. Specify sources for any special chemicals or preparations (including the company name). Describe the statistical analysis and the criteria for determining significance. Include a statement regarding approval by an ethics committee, IRB, or similar review body, as well as the consent procedures, at the beginning of the Methods section. • Results: Present a detailed description of the study results, organized logically. When using tables, avoid redundantly describing their contents in the main text. Instead, highlight the important trends and key points. • Discussion: Emphasize new and significant findings. Discuss the significance and limitations of your findings, ensuring that the conclusions are directly linked to the study’s objectives. Avoid drawing conclusions that are not fully supported by the data. 4) References Authors should provide direct references to original research sources whenever possible. • References should be listed in the order they are cited in the paper. Reference numbers should be placed in the middle or at the end of the corresponding sentences within the text. The reference list should appear at the end of the document, following the main text and acknowledgments (if applicable) and before any tables. Original articles are limited to 50 references. Reference numbers in the text should be in chronological order, in normal type, and in square brackets (e.g., “In the study by Won et al. [23] ...”). • Authors’ names must be listed by last name followed by the initials of their first and middle names. If there are more than six authors, list the first six followed by “et al.” Include inclusive page numbers. Journal titles should be abbreviated according to the style used for Medline (https://www.ncbi.nlm.nih.gov/nlmcatalog/journals). • Journals 1. Bae EJ, Park BH. Multiple roles of sirtuin 6 in adipose tisvi sue inflammation. Diabetes Metab J 2023;47:164-72. 2. Inzucchi SE, Maggs DG, Spollett GR, Page SL, Rife FS, Walton V, et al. Efficacy and metabolic effects of metformin and troglitazone in type II diabetes mellitus. N Engl J Med 1998;338:867-72. • Book and Book chapter 3. Eyre HJ, Lange DP, Morris LB. Informed decisions: the complete book of cancer diagnosis, treatment, and recovery. 2nd ed. American Cancer Society; 2002. p768. 4. Leon S, Fritz MA. Clinical gynecologic endocrinology and infertility. 7th ed. Lippincott Williams & Wilkins; 2005. Chapter 29, Endometriosis; p1103-33. • Online 5. Ministry for Health, Welfare and Family Affairs. The Third Korea National Health and Nutrition Examination Survey (KNHANES III). Available from: https://knhanes.cdc.go.kr (updated of July 8, 2006). • Preprint 6. Arruda AL, Hartley A, Katsoula G, Smith GD, Morris AP, Zeggini E. Insights into the comorbidity between type 2 diabetes and osteoarthritis [Preprint]. Posted 2023 Mar 29. medRxiv 2023.03.28.23287861. https://doi.org/10.1101/2023.03.28.23287861 5) Tables • Tables should be double-spaced and placed on a separate page at the end of the document, with the table number, title, and legend positioned above the table. • Table titles should be concise, consisting of a phrase and a clause, with the first character capitalized. • Tables should be numbered in the order they are referenced in the main text. • Footnotes should be listed below the table, with descriptions following the order of acronyms and symbols. Symbols should be marked with lowercase letters (e.g.,   a, b, c, d, e) in the order they appear. • Avoid using unnecessary vertical lines. Horizontal lines should be minimized. • Tables should be easy to understand. • If a table has been previously published, acknowledge the original source and obtain written permission from the copyright holder for reproduction. Permission is required irrespective of authorship or publisher, except for documents in the public domain. 6) Figures • Figures should be submitted separately from the manuscript text. All images, including photographs, must be of high quality, with a resolution of at least 300 dpi, and provided in JPEG, EPS, TIFF, or PICT format with RTF manuscripts, or embedded within a PDF file. • Figures should be numbered in the order they are mentioned in the text. • When using multiple images under the same number, label them with letters (e.g., Fig. 1A, Fig. 1B). • Use color images when appropriate. • Photomicrographs should include internal scale markers. Provide an explanation for the scale and indicate the staining method used in photomicrographs. • If a figure has been previously published, acknowledge the original source and provide written permission from the copyright holder for reproduction. Permission is required irrespective of authorship or publisher, except for public domain materials. 7) Figure legends • Use Arabic numerals to number figures in the order they mentioned in the main text. • Describe all images and photographs in the legend using complete sentences rather than fragments or phrases. • Footnotes below the figure should follow the order of symbols first, then acronyms. Symbols should be denoted with lowercase letters in the order of their appearance, such as     a, b, c, d, e. 8) Supplemental data Nonessential tables and figures can be included as onlineonly supplemental files. Whenever possible, these files should be combined in a single document and uploaded separately during the submission process. Each file must be referenced in the main text at least once (e.g., “Supplementary Table 1”). 9) Graphical abstract A graphical abstract visually summarizes the key findings of a paper, presenting the topic in an engaging, easy-to-understand format to attract a wide audience. Highlights, presented as concise bullet points (up to five), convey the paper’s essential discoveries. Each bullet point should not exceed 85 characters, including spaces. Although submitting a graphical abstract and highlights is optional during the initial submission, they are required upon acceptance of the manuscript. Both the graphical abstract and highlights will appear in the online content and the article PDF file. 5.3. Reviews Review articles may be written by invitation or submitted for consideration by the editorial board. Submitted review manuscripts will undergo the same review process as original research articles. Review articles should follow the instructions for original articles, including an abstract of no more than 200 words and keywords. References should not exceed 150. 5.4. Brief Reports Brief reports aim to publish novel and significant findings from clinical and experimental studies that can be presented concisely. These manuscripts should include a short, unstructured abstract (up to 180 words), as well as sections for the Introduction, Methods, Results, and Discussion. The total manuscript length should not exceed 1,500 words, excluding references and the abstract. Brief reports may include up to 20 references and a maximum of two figures or tables. 5.5. Editorials Editorials in the Diabetes & Metabolism Journal are written by invitation from the journal’s editorial board, extended to vii a senior investigators in the relevant field. The purpose of these editorials is to provide additional insights into original data presented in an article published in the journal. The number of references should not exceed 20. 5.6. Letters to the Editor This includes critiques or opinions on manuscripts published in this journal in the past 6 months. Submissions should be no longer than 1,000 words, with up to 10 references and typically no more than one table or one figure. Letters will be published at the discretion of the editor-in-chief. 6. PEER REVIEW 6.1. Initial Screening Submitted manuscripts are first reviewed by manuscript editors. If they do not meet the submission criteria, they will be returned to the authors for correction and resubmission. The priority of the manuscript will then be initially assessed by the associate editors. Before undergoing peer review, all submissions are checked for plagiarism using Similarity Check, a plagiarism-screening tool. If the similarity score is too high, the editorial board will conduct a more thorough content review. 6.2. Peer Review Process Manuscripts deemed suitable will be reviewed by two or more experts in the relevant field to assess their scientific quality. This journal employs a double-blind review process throughout. If revisions are required, the editorial board will request that the authors amend the manuscript. Authors must provide a detailed, line-by-line response to the reviewers’ comments when submitting the revised manuscript. Revisions must be received within 2 months of the editorial board’s notification. If the revised manuscript is not submitted within this period, it will be assumed that the author has decided not to pursue publication. Based on the review and revisions, the associate editor will make the final decision on the manuscript’s acceptance. If necessary, a professional statistician will conduct a statistical review. 6.3. Complains and Appeals 1) Who can file a complaint or appeal? Submitters, authors, reviewers, and readers may file complaints and appeals in cases such as: falsification, fabrication, plagiarism, duplicate publication, authorship disputes, conflicts of interest, ethical treatment of animals, informed consent issues, bias, unfair competitive practices, copyright infringement, data theft, defamation, and legal issues. Complaints or appeals should be submitted via email (diabetes@kams.or.kr), including detailed information addressing all relevant questions. 2) Who handles complaints and appeals? The editor, editorial board, or editorial office is responsible for resolving complaints and appeals. A legal consultant or ethics editor may assist in the decision-making process. 3) Possible resolution outcomes: The consequences depend on the nature and severity of the misconduct. Resolutions will follow COPE guidelines. If not described above, the process of handling complaints and appeals follows the guidelines of the COPE (https://publicationethics.org/appeals). 7. USE OF ARTIFICIAL INTELLIGENCE 7.1. Use of Artificial Intelligence (AI) Technologies in Manuscript Preparation The Diabetes & Metabolism Journal follows ICMJE guidelines regarding the use of AI manuscript preparation. Traditional and generative AI, including language models, chatbots, machine learning, or similar technologies, may be used to improve the readability and language accuracy of scientific writing. However, AI tools cannot be credited as authors. 7.2. Use of AI-Generated Images Due to unresolved legal and ethical issues, the use of AIgenerated images and videos is restricted. Consequently, AI tools are not permitted to create artwork, including book covers, commissioned content covers, or graphical abstracts. 7.3. Disclosure of AI Technologies Authors must disclose the use of AI technologies during manuscript submission. This includes specifying the tools used, such as the model’s name, version, and manufacturer, and explaining their role in the writing process. Authors must also confirm that there is no plagiarism in the AI-generated text or images. AI-generated content should not be cited as a primary source. 7.4. AI Use by Peer Reviewers AI tools can produce outdated, nonsensical, biased, or incorrect information. Additionally, manuscripts may contain sensitive or proprietary information that should not be shared outside the peer review process. Therefore, peer reviewers are asked not to upload manuscripts into AI tools. The journal is exploring providing access to secure AI tools for peer reviewers. If AI tools are used in any capacity to evaluate a manuscript, reviewers must transparently declare their use in their review reports."
92. Authors who use artificial intelligence (AI) tools in the writing of a manuscript, production of images or graphical elements of the article, or in the collection or analysis of data, must be transparent in disclosing in the Methods section of the manuscript how the AI tool was used and which tool was used. Authors remain fully responsible for the content of their manuscript, even those parts produced by an AI tool, and are thus liable for any breach of publication ethics."
93. A clinical trial protocol is an essential document produced by study investigators detailing a priori the rationale, proposed methods and plans for how a clinical trial will be conducted.1,2 This key document is used by external reviewers (funding agencies, regulatory bodies, research ethics committees, journal editors, peer reviewers, institutional review boards and, increasingly, the wider public) to understand and interpret the rationale, methodological rigour, and ethical considerations of the trial. Additionally, trial protocols provide a shared reference point to support the research team in conducting a high-quality study. Despite their importance, the quality and completeness of published trial protocols are variable.1,2 The SPIRIT statement was published in 2013 to provide guidance for the minimum reporting content of a clinical trial protocol and has been widely endorsed as an international standard.3–5 The SPIRIT statement published in 2013 provides minimum guidance applicable for all clinical trial interventions but recognises that certain interventions may require extension or elaboration of these items.1,2 Artificial intelligence (AI) is an area of enormous interest, with strong drivers to accelerate new interventions through to publication, implementation, and market.6 While AI systems have been researched for some time, recent advances in deep learning and neural networks have gained considerable interest for their potential in health applications. Examples of such applications of these are wide ranging and include AI systems for screening and triage,7,8 diagnosis,9–12 prognostication,13,14 decision support,15 and treatment recommendation.16 However, in most recent cases, the majority of published evidence has consisted of in-silico, early-phase validation. It has been recognised that most recent AI studies are inadequately reported and existing reporting guidelines do not fully cover potential sources of bias specific to AI systems.17 The welcome emergence of randomised controlled trials seeking to evaluate the clinical efficacy of newer interventions based on, or including, an AI component (called “AI interventions” here)15,18–23 has similarly been met with concerns about design and reporting,17,24–26 This has highlighted the need to provide reporting guidance that is fit for purpose in this domain. SPIRIT-AI (as part of the SPIRIT-AI and CONSORT-AI initiative) is an international initiative supported by SPIRIT and the EQUATOR (Enhancing the Quality and Transparency of Health Research) Network to extend or elaborate on the existing SPIRIT 2013 statement where necessary, to develop consensus-based AI-specific protocol guidance.27,28 It is complementary to the CONSORT-AI statement, which aims to promote high-quality reporting of AI trials. This Consensus Statement describes the methods used to identify and evaluate candidate items and gain consensus. In addition, it also provides the full SPIRIT-AI checklist, including new items and their accompanying explanations."
94. Artificial Intelligence (AI) and AI-assisted technologies should not be listed as an author or co-author as authorship implies responsibilities and tasks that can only be attributed to and performed by humans.  Authors should only use AI and AI-assisted technologies to improve readability and language, and the listing of references of the manuscript. Human oversight and control is required for the usage of the technology, authors should carefully review and edit the result as the journal will conduct an AI similarity index check.  Authors are allowed to use AI as a research tool where the use of AI or AI-assisted tools is part of the research design or research methods. As such, the usage of AI or AI-assisted tools must be described in a reproducible manner in the methods section of the manuscript.  AI disclosure statements are encouraged to be provided if the technology is used."
95. In accordance with our Auhorship policy, Large Language Models (LLMs) and other AI technologies cannot be listed as authors on any submitted works. Authorship implies responsibilities and tasks that can only be attributed to and performed by humans. Each (co-) author is accountable for ensuring that questions related to the accuracy or integrity of any part of the work are appropriately investigated and resolved and authorship requires the ability to approve the final version of the work and agree to its submission. Authors are also responsible for ensuring that the work is original, that the stated authors qualify for authorship, and the work does not infringe third party rights. Any use of an LLM or AI technology should be described in detail within the Materials and Methods section of the article.  Currently, there are unique legal challenges to AI-generated images related to copyright and research integrity. AI-generative tools should also not be used to create images in submitted manuscripts, except when it is an integral part of the research design or methodology. In such cases a detailed description of the altered or generated content, an explanation of the AI or AI-assisted tool's role in the process, and information about the model, tool, version, and manufacturer must be provided in the Materials and Methods section.  Any failure to disclose the use of these tools will be considered research misconduct and will result in immediate retraction of the article.  This policy pertains solely to AI and AI-assisted tools, like Large Language Models, capable of generating content for scientific purposes. Disclosure is not required for reference management software, such as Mendeley, EndNote, Zotero and similar tools, which authors are free to employ for collecting, organizing, annotating, and utilizing references to scholarly articles."
96. an Artificial Intelligence (AI) or Large Language Models (LLM) program cannot be listed as an author of an article. Use of AI programs should be primarily restricted to improve the style, accessibility or quality of human generated text and images, including schemata and data figures. Any part of an article assembled with the use of an AI based program must be thoroughly checked and verified by the authors, including deriving an understanding of the provenance of new information and ideas. The authors bear full responsibility for all text and images published in a paper, including factual accuracy, completeness as well as accurate, comprehensive literature citation (including preprints and dataset, where appropriate). Authors must take care to ensure that application of AI-based tools does not lead them to plagiarize, misrepresent or falsify content, or infringe third party rights.  Authors must disclose their use in the published article, including details on which parts of the article were assembled with the assistance of AI programs and details on the tools employed. Data figures and schemata presented in papers must be original, or, if presented for illustrative purposes, accurately cite the source. For data based on original experimentation or meta-analysis of the literature, AI programs can be used in the collection and analysis of data if this is documented in the Methods section of the paper. If AI is used to generate synthetic data, this must be clearly labeled in the main text and figure, and it must also be documented in the Methods section. AI must not be used to synthesize or edit experimental data in a manner that misrepresents the findings. AI programs may be used to display data or for illustrative purposes, as long as that is declared and attribution is provided, where appropriate."
97. Use of Chtatbots/Artificial Intelligence Text or ideas generated by chatbots (or any other artificial intelligence programs or assistance) have begun to appear in scholarly literature, spurred by the release of ChatGPT in early 2023. For the use of chatbots or other artificial intelligence tools, EID follows the recommendations of WAME, which state, in brief, the following:  1. Chatbots cannot be authors.  2. Authors should be transparent when chatbots are used and provide information about how they were used.  3. Authors are responsible for the work performed by a chatbot in their paper (including the accuracy of what is presented, and the absence of plagiarism) and for appropriate attribution of all sources (including for material produced by the chatbot).  4. Editors need appropriate tools to help them detect content generated or altered by AI. Such tools should be made available to editors regardless of ability to pay for them, for the good of science and the public, and to help ensure the integrity of healthcare information and reducing the risk of adverse health outcomes.  If you use a chatbot's help to write your manuscript, including text or graphics, you should consult and follow current WAME Recommendations on Chatbots and Generative Artificial Intelligence in Relation to Scholarly Publications. Note that EID prefers not to publish figures, graphs, or images created by using artificial intelligence.  For EID, this information should be placed in the Acknowledgements section of the manuscript. In addition, you must indicate on the EID Author Checklist whether you have used a chatbot to help write your manuscript"
98. The journal does not consider Artificial Intelligence (AI) authoring tools to meet the requirements for Authorship as recommended by the ICMJE. Authors who use AI tools in the writing of a manuscript, production of images or graphical elements of the paper, or in the collection and analysis of data, must be transparent in disclosing in the Materials and Methods (or similar section) of the paper how the AI tool was used and which tool was used. Authors are fully responsible for the content of their manuscript, even those parts produced by an AI tool, and are thus liable for any breach of publication ethics.  In addition, authors, reviewers and editors should not upload an accepted or published manuscript or any part of it into a generative AI tool as this may violate the copyright agreement or licensing terms in effect at the time of acceptance.  Generative AI should not be used by editors or reviewers as the sole mechanism in the evaluation or decision-making process of a manuscript. The editor is responsible and accountable for the editorial process, the final decision, and the communication thereof to the authors."
99. AI or AI-assisted tools do not qualify as authors, only humans do. Authors are fully responsible for the entire content of their work. Authors are fully responsible for correctly labelling and disclosing which parts of their work has been created by or in assistance of AI: AI-tools used to generate results must be described in detail in the methods section. AI-tools used for writing and content editing must be disclosed in the acknowledgements. Reviewers and editors are obliged to confidentiality and should not upload manuscripts to software or AI-assisted tools where confidentiality cannot be assured."
100. Use of generative artificial intelligence This guidance refers only to the use of generative artificial intelligence (AI) in preparing your paper for submission and revision, not to the use of AI as an experimental tool.  If a generative AI model is involved in the planning, conduct or analysis of your study, this should be detailed in the introduction or methods section, as would use of any other research tool.  AI and publication ethics Generative AI is a powerful tool with potential to drive great advances. However, it can also be used for misconduct. The use of generative AI to fabricate data or references, to conceal plagiarism or duplication of an author’s own work, or to contaminate the scientific record in any way, is contrary to everything ERS stands for.  AI, privacy and confidentiality Always be aware that depending on their usage agreements, publicly available generative AI models may use anything you upload as training data. You should not upload any material containing confidential or personally identifiable information, or anything to which someone else holds the rights, to an AI model.  AI as an author A generative AI model or its interface cannot be credited as an author of a scientific paper as it cannot take responsibility for the content of that paper. Unless otherwise stated in these instructions, contributions from an AI should be listed in the Acknowledgements section, including the name and version of the AI and the date(s) used.  AI as a basic writing assistant Subject to the privacy and confidentiality requirements above, authors are free to use a large language model (LLM) or other AI assistant as a writing assistant, supporting the authors in refining, correcting, formatting and editing text and tables. Contributions of this sort should be detailed in the Acknowledgements section, including the name and version of the AI. Authors retain full responsibility for the text.  AI as an advanced writing assistant Authors who wish to use generative AI for more advanced writing tasks than those detailed in the previous section should do so with great care, as generative AI models are known to output false information. Authors should be aware that they are fully responsible for the content of their article, and that by submitting it they declare that they meet all four of the International Committee of Medical Journal Editors’ criteria for authorship: https://www.icmje.org/recommendations/browse/roles-and-responsibilities/defining-the-role-of-authors-and-contributors.html#two  Contributions of this sort should be detailed in the Acknowledgements section, including the name and version of the AI, the date(s) used and the tasks carried out or input provided by the AI.  AI for images ERS does not accept figures or images created by, or with assistance from, generative AI models, unless these are specifically part of the research output and are clearly indicated as such.  Manipulation or enhancement of image data is strictly limited to those detailed in the guidelines produced by Rockefeller University Press and discussed by the Council of Science Editors at https://www.councilscienceeditors.org/3-4-digital-images-and-misconduct#GuidelinesforHandling  No specific feature within an image may be enhanced, obscured, moved, removed, or introduced. Adjustments of brightness, contrast, or colour balance are acceptable if they are applied to the whole image and as long as they do not obscure, eliminate, or misrepresent any information present in the original. The grouping of images from different parts of the same gel, or from different gels, fields, or exposures must be made explicit by the arrangement of the figure (e.g. dividing lines) and in the text of the figure legend. If the original data cannot be produced by an author when asked to provide it, acceptance of the manuscript may be rescinded. As generative AI models work in opaque ways, ERS’s position is that they should not be used for this kind of image enhancement, as the authors cannot guarantee adherence to the rules."
101. A determination of plagiarism or fabrication by the journal will require contacting the corresponding author’s institution and possibly funding agencies. If plagiarism or fabrication is determined post-publication, the journal will investigate potential courses of action, up to and including formal retraction of the article. "
102. Generative AI and Figures, images and artwork Please read our policy on the use of generative AI and AI-assisted tools in figures, images and artwork, which can be found in Elsevier’s GenAI Policies for Journals. This policy states:  We do not permit the use of Generative AI or AI-assisted tools to create or alter images in submitted manuscripts.  The only exception is if the use of AI or AI-assisted tools is part of the research design or methods (for example, in the field of biomedical imaging). If this is the case, such use must be described in a reproducible manner in the methods section, including the name of the model or tool, version and extension numbers, and manufacturer.  The use of generative AI or AI-assisted tools in the production of artwork such as for graphical abstracts is not permitted. The use of generative AI in the production of cover art may in some cases be allowed, if the author obtains prior permission from the journal editor and publisher, can demonstrate that all necessary rights have been cleared for the use of the relevant material, and ensures that there is correct content attribution."
103. If you have used an AI tool in the development of the paper it must be declared within the paper, after the Ethics statement if applicable and before the references. You should indicate how the tool was used and how you used the material the tool produced in the paper you have submitted."
104. Regarding the use of generative AI tools (e.g., ChatGPT), EM adheres to the general guidelines of its publisher Springer. These tools may be used for certain purposes, but two areas need to be distinguished:  1. Use of generative AI by authors: This implies that authors must declare when generative AI tools have been used in the process of researching data and/or preparing the manuscript. The authors need to describe the purpose (e.g., improving language) as well as the extent to which generative AI has been used and assure that they take full responsibility of the content of the manuscript.  2. Use of generative AI by reviewers and editors: First, reviewers should be aware that neither papers or sections thereof must be uploaded to generative AI tools to produce reviews or parts thereof. Second, when checking manuscripts, reviewers are encouraged to look more closely on how the different parts of the manuscript are related to each other (“the sound and convincing story”), i.e. how motivation, literature analysis, research gap, own contribution and findings fit to each other.  In case any questions arise, please contact the Editorial Office"
105. 3.1 English editing by AI language tools Enhancing manuscript quality with Assistive-Artificial Intelligence (AI) language tools At AIMS, we are committed to maintaining high language quality standards in all submitted manuscripts. To support our authors, we recommend the use of Assistive-AI language tools. These tools can significantly enhance the clarity, coherence, and overall quality of your writing. Below are three Assistive-AI tools that you may find particularly useful:  Grammarly Grammarly is an advanced writing assistant that helps improve your writing by providing suggestions on grammar, spelling, punctuation, style, and tone. It also includes a plagiarism detection feature and vocabulary enhancement suggestions. Grammarly integrates seamlessly with various platforms, including Microsoft Word and Google Docs, making it a convenient tool for refining your manuscripts.    • Key features:         o Grammar and spelling check         o Style and tone suggestions         o Plagiarism detection         o Integration with multiple platforms LanguageTool LanguageTool is an open-source grammar and spell checker that supports over 20 languages. It identifies grammatical errors, spelling mistakes, and punctuation issues, offering suggestions for corrections. LanguageTool is especially beneficial for non-native English speakers and integrates with word processors like Microsoft Word and Google Docs.    • Key features:          o Grammar and spelling check          o Style suggestions          o Multilingual support          o Integration with multiple platforms Curie Curie is an AI writing assistant designed to enhance your writing by providing contextual grammar and style suggestions. It helps improve sentence structure, coherence, and readability. Curie also offers personalized feedback based on your writing style and integrates with various writing platforms.     • Key features:         o Contextual grammar and style suggestions         o Sentence structure and readability improvement         o Personalized feedback         o Integration with multiple writing platforms We follow COPE's guidelines and policies regarding the use of AI tools: COPE Policy on AI tools. Please disclose any Generative-AI use in your manuscript's “Use of Generative-AI tools declaration” portion at the end of your manuscript before the Acknowledgments section. (The tools listed above are not considered Generative-AI tools) We encourage our authors to utilize these Assistive-AI tools to enhance the language quality of their manuscripts. Doing so will help ensure clarity, coherence, and a professional standard in your writing. This ultimately facilitates a smoother review and publication process and may increase the possibility of acceptance."
106. Artificial intelligence (AI) AI-assisted technologies [such as large language models (LLMs), chatbots, and image creators] do not meet Energy Material Advances' criteria for authorship and therefore may not be listed as authors or coauthors, nor may sources cited in Energy Material Advances journal content be authored or coauthored by AI tools. Authors who use AI-assisted technologies as components of their research study or as aids in the writing or presentation of the manuscript should note this in the cover letter and in the acknowledgments section of the manuscript. For more details of the journal's AI policies, see Publication Ethics."
107. Generative AI usage key principles Copywriting any part of an article using a generative AI tool/LLM would not be permissible, including the generation of the abstract or the literature review, for as per Emerald’s authorship criteria, the author(s) must be responsible for the work and accountable for its accuracy, integrity, and validity. In line with standard academic practice, however, Emerald permits the use of examples of generative AI for illustrative purposes as part of scholarly critique and discussion, with the exception of images created by AI tools or large-scale generative models; these examples must be appropriately flagged in the text and be fully cited and referenced in accordance with formatting requirements. The generation or reporting of results using a generative AI tool/LLM is not permissible, for as per Emerald’s authorship criteria, the author(s) must be responsible for the creation and interpretation of their work and accountable for its accuracy, integrity, and validity. The in-text reporting of statistics using a generative AI tool/LLM is not permissible due to concerns over the authenticity, integrity, and validity of the data produced, although the use of such a tool to aid in the analysis of the work would be permissible. Copy-editing an article using a generative AI tool/LLM in order to improve its language and readability would be permissible as this mirrors standard tools already employed to improve spelling and grammar, and uses existing author-created material, rather than generating wholly new content, while the author(s) remains responsible for the original work. The submission and publication of images created by AI tools or large-scale generative models is not permitted."
108. Declaration of Interest and Financial Disclosures  A conflict of interest may exist when an author (or the author's institution or employer) has financial or personal relationships or affiliations that could influence (or bias) the author's decisions, work, or manuscript.  Authors are expected to provide detailed information about all relevant financial interests and relationships or financial conflicts (e.g., employment/affiliation, grants or funding, consultancies, honoraria, stock ownership or options, expert testimony, royalties, or patents filed, received, or pending), particularly those present at the time the research was conducted and through publication, as well as other financial interests (such as patent applications in preparation), that represent potential future financial gain.  For example, authors of a manuscript about prostate cancer should report all financial relationships they have with all manufacturers of products used in the management of prostate cancer, not only those relationships with companies whose specific products are mentioned in the manuscript.  Although many universities and other institutions have established policies and thresholds for reporting financial interests and other conflicts of interest, European Urology Oncology requires complete disclosure of all relevant financial relationships and potential financial conflicts of interest, regardless of amount or value. Please find the authorship available to download here.    Declaration of generative AI in scientific writing The below guidance only refers to the writing process, and not to the use of AI tools to analyse and draw insights from data as part of the research process.  Where authors use generative artificial intelligence (AI) and AI-assisted technologies in the writing process, authors should only use these technologies to improve readability and language. Applying the technology should be done with human oversight and control, and authors should carefully review and edit the result, as AI can generate authoritative-sounding output that can be incorrect, incomplete or biased. AI and AI-assisted technologies should not be listed as an author or co-author, or be cited as an author. Authorship implies responsibilities and tasks that can only be attributed to and performed by humans, as outlined in Elsevier's AI policy for authors.  Authors should disclose in their manuscript the use of AI and AI-assisted technologies in the writing process by following the instructions below. A statement will appear in the published work. Please note that authors are ultimately responsible and accountable for the contents of the work."
109. Authors who employ generative AI (artificial intelligence) and AI-assisted technologies (such as large language models, chatbots, or image creators) in developing papers should transparently disclose their use to editors, reviewers and readers. The submitted work should include a description which AI technology or tool was used, how the AI was used and identify what was produced or co-produced by AI-assisted technologies. Because the authors of a manuscript are responsible for the accuracy, validity, reliability, trustworthiness, integrity, and originality of the scientific outputs, chatbots or other AI-assisted technologies cannot be listed as authors. Authors should carefully review, verify and edit all materials produced through the use of AI, to prevent the submission of authoritative-sounding output that is incorrect, incomplete, or biased. Citation of AI-generated material as a primary source is not acceptable."
110. AIMS monitors ongoing developments in this  area closely, and may review, adjust, or refine these policies as needed.   AIMS recognizes the transformative  potential of AI-powered writing assistants and tools such as ChatGPT. These  technologies can enhance writing and research by providing authors with fresh  ideas, overcoming writer's block, and optimizing editing tasks. While these  tools improve efficiency, it is crucial to understand their limitations and use  them in ways that uphold academic and scientific integrity principles. As a  publisher, AIMS values human creativity and authorship. Large Language Models  (LLMs) cannot be credited as authors or take responsibility for the text they  generate. Therefore, human oversight, intervention, and accountability are  vital to ensure the accuracy and integrity of our published content. We  acknowledge that many academics and scholars already use assistive and  generative tools to enhance their productivity and assist in their academic  writing. We have developed these guidelines to support authors submitting materials  (including, but not limited to, journal articles and books) to AIMS.   The Distinction Between Assistive AI Tools and Generative AI Tools   Assistive AI Tools  Assistive AI tools provide suggestions, corrections, and enhancements to  content you have authored. For example, tools like Google's Gmail and  Microsoft's Outlook and Word have long flagged spelling or grammatical errors.  More recently, these assistive tools have introduced features that proactively  suggest the next word or phrase or recommend better, more concise phrasing to  improve clarity. Content that you have created independently but refined or  improved with the help of these Assistive AI tools is considered “AI-assisted.”  We currently recommend the assistive AI programs Grammarly, Curie, and  LanguageTool.   Generative AI Tools  This term refers to tools such as ChatGPT or Dall-e that produce content,  whether in text, images, or translations. Even if you've made significant  changes to the content afterward, if an AI tool was the primary creator of the  content, the content would be considered ""AI-generated.”   Disclosure Requirements  AI-assisted writing will become more common  as AI tools are increasingly embedded within tools such as Microsoft Word and  Google Docs. You are not required to disclose the use of assistive AI tools in  your submission, but all content, including AI-assisted content, must undergo  rigorous human review before submission. This is to ensure the content aligns  with our standards for quality and authenticity.   You are required to inform us of any  AI-generated content appearing in your work (including text, images, or translations) when you submit any form of content  to AIMS, including,  but not limited to, journal articles and book proposals. This will allow the editorial team to make an informed publishing  decision regarding your submission.   Things to Consider Before Using  Generative AI Tools   If you use AI to generate content or images  for your submission, follow these guidelines before submitting your work to  AIMS.  1. Disclosure: As outlined above, you must reveal any AI-generated content in your submission. There is a specified “Use of AI tools declaration” section present for this purpose. Declare the tool used and the purpose of the usage.  2. Carefully Verify the Accuracy, Validity, and Appropriateness of AI-generated Content or AI-produced Citations:: Large Language Models (LLMs) can sometimes ""hallucinate"" – producing incorrect or misleading information, especially when used outside of the domain of their training data or when dealing with complex or ambiguous topics. While their outputs may appear linguistically sound, they might not be scientifically accurate or correct, and LLMs may produce nonexistent citations. Remember, some LLMs might only have been trained on data up to a specific year, potentially resulting in incorrect or incomplete knowledge of a topic.  3. Carefully Check Sources & Citations: Offer a comprehensive list of resources utilized for content and citations, including those produced by AI. Meticulously cross-check citations for their accuracy to ensure proper referencing.  4. Appropriately Cite AI-Generated Content: Where you include content generated by AI, the appropriate citations should be included following the appropriate referencing convention.  5. Avoid Plagiarism and Copyright Infringement: LLMs could inadvertently reproduce significant text chunks from existing sources without due citation, infringing others' intellectual property. As the work's author, you bear responsibility for confirming that there is no plagiarized content in your submission.  6. Be Aware of Bias: Because LLMs have been trained on text that includes biases, and because there is an inherent bias in AI tools because of human programming, AI-generated text may reproduce these biases, such as racism or sexism, or may overlook perspectives of populations that have been historically marginalized. Relying on LLMs to generate text or images can inadvertently propagate these biases so you should carefully review all AI-generated content to ensure it’s inclusive, impartial, and appeals to a broad readership.  7. Acknowledge Limitations: In your submission, if you have included AI-generated content, you should appropriately acknowledge the constraints of LLMs, including the potential for bias, inaccuracies, and knowledge gaps.  8. Take Responsibility: AI tools like ChatGPT cannot be recognized as a co-author in your submission. As the author, you (and any co-authors) are entirely responsible for the work you submit.  9. Stay Updated: Follow the latest developments in the debates around AI-generated content to ensure you understand the possible ramifications and ethical challenges of using AI-generated content in your submission.  Prohibited Use  ● Do not use generative AI to create or modify core research data artificially.  ● Never share sensitive personal or proprietary information on an AI platform like ChatGPT, as this may expose sensitive information or intellectual property. Any information you share with AI tools like ChatGPT is collected for business purposes.  ● Editors and reviewers must uphold the confidentiality of the peer review process. Editors must not share information about submitted manuscripts or peer review reports in generative AI tools such as ChatGPT. Reviewers must not use AI tools, including but not limited to ChatGPT, to generate review reports.  These guidelines aim to ensure the  responsible and ethical use of AI tools in writing and research, preserving the  integrity and quality of academic and scientific publications.  Further Information  ● World Association of Medical Editors (WAME) recommendations on chat bots, ChatGPT  and scholarly manuscripts.   ● Committee on Publication Ethics (COPE)’s position  statement on Authorship and AI tools.  ● STM Whitepaper on Generative  AI in Scholarly Communication.  Disclosure Instructions for the Use of Generative-AI Tools  We follow COPE's guidelines and policies regarding the use of Artificial Intelligence (AI) tools: COPE Policy on AI tools  The use of artificial intelligence (AI) tools such as ChatGPT or Large Language Models in research publications is expanding rapidly. COPE joins organizations, such as  WAME and the JAMA Network among others, to state that AI tools cannot be listed as an author of a paper. - COPE  AI tools cannot meet the requirements for authorship as they cannot take responsibility for the submitted work. As non-legal entities, they cannot assert the presence or absence of conflicts of interest nor manage copyright and license agreements. - COPE  Please disclose the use of any generative-AI tools in the writing of a manuscript, the production of images or graphical elements, or the collection and analysis of data. In the “Use of AI tools declaration” we ask that you disclose which tool was used as well as a description of how the tool was used.  Authors are fully responsible for the content of their manuscript, including any portion produced by an AI tool, and are thus liable for any breach of publication ethics.  If there is nothing to disclose, there is no need to add a declaration (Remember, there is no need to disclose the use of Assistive-AI). If there is generative-AI use to disclose, here is a guide for an acceptable disclosure.  Use of Generative-AI Tools Declaration  The author(s) declare(s) they have used Artificial Intelligence (AI) tools in the creation of this article.  AI tools used:  How were the AI tools used?  Where in the article is the information located?"
111. These guidelines cover acceptable uses of generative AI technologies such as Large Language Models (ChatGPT, Jasper) and text-to-image generators (DALL-E 2, Midjourney, Stable Diffusion) in the writing or editing of manuscripts submitted to Frontiers.  AI use by authors Authors should not list a generative AI technology as a co-author or author of any submitted manuscript. Generative AI technologies cannot be held accountable for all aspects of a manuscript and consequently do not meet the criteria required for authorship.  If the author of a submitted manuscript has used written or visual content produced by or edited using a generative AI technology, this use must follow all Frontiers guidelines and policies. Specifically, the author is responsible for checking the factual accuracy of any content created by the generative AI technology. This includes, but is not limited to, any quotes, citations or references. Figures produced by or edited using a generative AI technology must be checked to ensure they accurately reflect the data presented in the manuscript. Authors must also check that any written or visual content produced by or edited using a generative AI technology is free from plagiarism.  If the author of a submitted manuscript has used written or visual content produced by or edited using a generative AI technology, such use must be acknowledged in the acknowledgements section of the manuscript and the methods section if applicable. This explanation must list the name, version, model, and source of the generative AI technology. We encourage authors to upload all input prompts provided to a generative AI technology and outputs received from a generative AI technology in the supplementary files for the manuscript."
112. Where authors use generative artificial intelligence (AI) and AI-assisted technologies in the writing process, authors should:  Only use these technologies to improve readability and language, not to replace key researcher tasks such as interpreting data or drawing scientific conclusions.  Apply the technology with human oversight and control, and carefully review and edit the result, as AI can generate authoritative-sounding output that can be incorrect, incomplete or biased.  Not list AI and AI-assisted technologies as an author or co-author, or cite AI as an author. Authorship implies responsibilities and tasks that can only be attributed to and performed by humans, as outlined in Elsevier's AI policy for authors.  Disclose in their manuscript the use of AI and AI-assisted technologies in the writing process by following the instructions below. A statement will appear in the published work. Please note that authors are ultimately responsible and accountable for the contents of the work.  Disclosure instructions Authors must disclose the use of generative AI and AI-assisted technologies in the writing process by adding a statement at the end of their manuscript in the core manuscript file, before the References list. The statement should be placed in a new section entitled 'Declaration of AI and AI-assisted technologies in the writing process'. Statement: During the preparation of this work the author(s) used [NAME TOOL / SERVICE] in order to [REASON]. After using this tool/service, the author(s) reviewed and edited the content as needed and take(s) full responsibility for the content of the publication. This declaration does not apply to the use of basic tools for checking grammar, spelling, references etc. If there is nothing to disclose, there is no need to add a statement."
113. Disclosure of use of AI-assisted tools including generative AI Any use of AI and AI-assisted technologies such as generative AI in writing papers should be declared and transparently cited and referenced. Disclosures should be made where used in the writing of and/or illustrations in the paper and among the references, as appropriate. A summary of use needs to be included at the end of the manuscript (e.g. in a “Disclosure of use of AI-assisted tools including generative AI“ section), and any text or and other AI generated output such as images generated should also be included as a supplementary file hosted in GigaDB or other open repositories."
114. In accordance with MIT Press Policies, GEP does not allow artificial intelligence (AI) tools such as ChatGPT or large language models (LLMs) to be listed as authors of our publications. Authors who use AI tools to produce text or images/graphics, or to collect data, must inform the editors of this use and be transparent about it in their manuscripts so that readers understand the role of these tools in the development of the work. Authors are fully responsible for the content of their manuscripts, including any portions produced by AI tools,  and are liable for any ethical breaches that may result from the use of such content. Please read the full MIT Press AI policy before submitting a paper to GEP (https://direct.mit.edu/journals/pages/publication-ethics) . When you submit, you will also be asked if you used artificial intelligence in any portion of the research or writing process and, if so, to describe how it was used. "
115. The below guidance only refers to the writing process, and not to the use of AI tools to analyse and draw insights from data as part of the research process.  Where authors use generative artificial intelligence (AI) and AI-assisted technologies in the writing process, authors should only use these technologies to improve readability and language. Applying the technology should be done with human oversight and control, and authors should carefully review and edit the result, as AI can generate authoritative-sounding output that can be incorrect, incomplete or biased. AI and AI-assisted technologies should not be listed as an author or co-author, or be cited as an author. Authorship implies responsibilities and tasks that can only be attributed to and performed by humans, as outlined in Elsevier's AI policy for authors.  Authors should disclose in their manuscript the use of AI and AI-assisted technologies in the writing process by following the instructions below. A statement will appear in the published work. Please note that authors are ultimately responsible and accountable for the contents of the work.  Disclosure instructions  Authors must disclose the use of generative AI and AI-assisted technologies in the writing process by adding a statement at the end of their manuscript in the core manuscript file, before the References list. The statement should be placed in a new section entitled 'Declaration of Generative AI and AI-assisted technologies in the writing process'  Statement: During the preparation of this work the author(s) used [NAME TOOL / SERVICE] in order to [REASON]. After using this tool/service, the author(s) reviewed and edited the content as needed and take(s) full responsibility for the content of the publication  This declaration does not apply to the use of basic tools for checking grammar, spelling, references etc. If there is nothing to disclose, there is no need to add a statement.  Submission declaration and verification Submission of an article implies that the work described has not been published previously (except in the form of an abstract, a published lecture or academic thesis, see 'Multiple, redundant or concurrent publication' for more information), that it is not under consideration for publication elsewhere, that its publication is approved by all authors and tacitly or explicitly by the responsible authorities where the work was carried out, and that, if accepted, it will not be published elsewhere in the same form, in English or in any other language, including electronically without the written consent of the copyright-holder. To verify compliance, your article may be checked by Crossref Similarity Check and other originality or duplicate checking software.  Preprints Please note that preprints can be shared anywhere at any time, in line with Elsevier's sharing policy. Sharing your preprints e.g. on a preprint server will not count as prior publication (see 'Multiple, redundant or concurrent publication' for more information)."
116. At submission of the manuscript, authors must disclose whether they used Artificial Intelligence (AI)-assisted technologies. If so, both the cover letter and the submitted paper should include a description of the technologies used and for what purposes they were employed."
117. Where authors use generative artificial intelligence (AI) and AI-assisted technologies in the writing process, authors should:  Only use these technologies to improve readability and language, not to replace key researcher tasks such as interpreting data or drawing scientific conclusions.  Apply the technology with human oversight and control, and carefully review and edit the result, as AI can generate authoritative-sounding output that can be incorrect, incomplete or biased.  Not list AI and AI-assisted technologies as an author or co-author, or cite AI as an author. Authorship implies responsibilities and tasks that can only be attributed to and performed by humans, as outlined in Elsevier's AI policy for authors  Disclose in their manuscript the use of AI and AI-assisted technologies in the writing process by following the instructions below. A statement will appear in the published work. Please note that authors are ultimately responsible and accountable for the contents of the work.  Disclosure instructions  Authors must disclose the use of generative AI and AI-assisted technologies in the writing process by adding a statement at the end of their manuscript in the core manuscript file, before the References list. The statement should be placed in a new section entitled 'Declaration of AI and AI-assisted technologies in the writing process'. Statement: During the preparation of this work the author(s) used [NAME TOOL / SERVICE] in order to [REASON]. After using this tool/service, the author(s) reviewed and edited the content as needed and take(s) full responsibility for the content of the publication. This declaration does not apply to the use of basic tools for checking grammar, spelling, references etc. If there is nothing to disclose, there is no need to add a statement.  Drug declaration A drug declaration statement/disclosure form will be sent to the corresponding author after acceptance. Authors must select the statement that is most appropriate for their manuscript. This form as well as the copyright forms must be returned to the Editorial office via e-mail.  Submission declaration Submission of an article implies that the work described has not been published previously (except in the form of an abstract or as part of a published lecture or academic thesis or as an electronic preprint), that it is not under consideration for publication elsewhere, that its publication is approved by all authors and tacitly or explicitly by the responsible authorities where the work was carried out, and that, if accepted, it will not be published elsewhere including electronically in the same form, in English or in any other language, without the written consent of the copyright-holder.  Financial disclosure Authors are requested to identify who provided financial support for the conduct of the research and/or preparation of the article and to briefly describe the role of the sponsor(s), if any, in study design; in the collection, analysis and interpretation of data; in the writing of the report; and in the decision to submit the article for publication. If the funding source(s) had no such involvement then this should be stated."
118. It is the responsibility of every person listed as an author of an article published in Hypertension Research to have contributed in a meaningful and identifiable way to the design, performance, analysis, and reporting of the work. A manuscript will be considered for publication on the understanding that all named authors have agreed to its submission and that if accepted it will not be later published in the same or similar form in any language without the consent of the publishers. Guide to Authors September 2024 2 All contributors who do not meet the criteria for authorship as defined above should be listed in an acknowledgements section. Examples of those who might be acknowledged include a person who provided purely technical help, writing assistance, or a department chair who provided only general support. Authors should disclose whether they had any writing assistance and identify the entity that paid for this assistance. Large Language Models (LLMs), such as ChatGPT, do not currently satisfy our authorship criteria. Notably an attribution of authorship carries with it accountability for the work, which cannot be effectively applied to LLMs. Use of an LLM should be properly documented in the Methods section (and if a Methods section is not available, in a suitable alternative part) of the manuscript. (e.g. For the language proofreading of the manuscript, we employed ChatGPT by GPT-3.5.) The corresponding (submitting) author is responsible for having ensured that this agreement has been reached, and for managing all communication between the journal and all co-authors, before and after publication. Any changes to the author list after submission, such as a change in the order of the authors, or the deletion or addition of authors, needs to be approved by a letter signed by every author. "
119. Authors must declare the use of generative AI in scientific writing upon submission of the paper. The following guidance refers only to the writing process, and not to the use of AI tools to analyse and draw insights from data as part of the research process:      Generative AI and AI-assisted technologies should only be used in the writing process to improve the readability and language of the manuscript.  The technology must be applied with human oversight and control and authors should carefully review and edit the result, as AI can generate authoritative-sounding output that can be incorrect, incomplete or biased.  Authors are ultimately responsible and accountable for the contents of the work.  Authors must not list or cite AI and AI-assisted technologies as an author or co-author on the manuscript since authorship implies responsibilities and tasks that can only be attributed to and performed by humans. The use of generative AI and AI-assisted technologies in scientific writing must be declared by adding a statement at the end of the manuscript when the paper is first submitted. The statement will appear in the published work and should be placed in a new section before the references list. An example:      Title of new section: Declaration of generative AI and AI-assisted technologies in the writing process.  Statement: During the preparation of this work the author(s) used [NAME TOOL / SERVICE] in order to [REASON]. After using this tool/service, the author(s) reviewed and edited the content as needed and take(s) full responsibility for the content of the published article.  The declaration does not apply to the use of basic tools, such as tools used to check grammar, spelling and references. If you have nothing to disclose, you do not need to add a statement.     We advise you to read our policy for authors on the use of generative AI and AI-assisted technologies for Elsevier.   Please note: to protect authors’ rights and the confidentiality of their research, this journal does not currently allow the use of Generative AI or AI-assisted technologies such as ChatGPT or similar services by reviewers or editors in the peer review and manuscript evaluation process. We are actively evaluating compliant AI tools and may revise this policy in the future.  Preprints Authors may share preprints, anywhere and at any time, in line with Elsevier's article sharing policy. Sharing preprints, such as on a preprint server, will not count as prior publication.    We advise you to read our policy on multiple, redundant or concurrent publication.   For manuscript submissions following a double anonymized peer review process, submissions should not be published as a preprint until a final decision has been made."
120. Authors who use AI tools such as Large Language Models (LLMs), chatbots or image creators in the writing of a manuscript, production of images or graphical elements of the paper, or in the collection and analysis of data, must be transparent in disclosing in the Materials and Methods (or similar section) of the paper how the AI tool was used and which tool was used. Authors who use such technology should describe, in both the cover letter and the submitted work, how they used it. These technologies should only be used to improve readability and language of the work and should not be used to replace researcher responsibilities such as producing scientific insights, analyzing and interpreting data, or drawing conclusions. These technologies should be applied with human oversight and control, and authors should carefully review and edit the result as AI can generate authoritative-sounding output that may be incorrect, incomplete, or biased. Authors are fully responsible for the content of their manuscript, even those parts produced by an AI tool, and are thus liable for any breach of publication ethics.   Authors should not list AI and AI-assisted technologies as an author or co-author, nor cite AI as an author. Any attribution of authorship carries with it accountability for the work, and AI tools cannot take such responsibility."
121. The use of artificial intelligence (AI)–generated text in an article shall be disclosed in the acknowledgements section of any paper submitted to an IEEE Conference or Periodical. The sections of the paper that use AI-generated text shall have a citation to the AI system used to generate the text. For more information, visit the IEEE Author Center. You can also find the policy for the use of artificial intelligence (AI) by authors and reviewers can be found in section 8.2.1 of the IEEE Publication Services and Products Board Operation Manual, subsections B article 10 and subsection C article 6, respectively."
122. The use of artificial intelligence (AI)-generated text (e.g., by ChatGPT) in an article shall be disclosed in the acknowledgements section of any paper submitted IEEE Conference or Periodical. The section of the paper that use AI-generated text shall have a citation to the AI system used to generate the text."
123. The use of content generated by artificial intelligence (AI) in an article (including but not limited to text, figures, images, and code) shall be disclosed in the acknowledgments section of any article submitted to an IEEE publication. The AI system used shall be identified, and specific sections of the article that use AI-generated content shall be identified and accompanied by a brief explanation regarding the level at which the AI system was used to generate the content.  The use of AI systems for editing and grammar enhancement is common practice and, as such, is generally outside the intent of the above policy. In this case, disclosure as noted above is recommended."
124. Natural language processing tools driven by artificial intelligence (AI) such as ChatGPT do not qualify as authors, and OUP will screen for them in author lists. The use of AI (for example, to help generate content or images, write code, process data, or for translation) must be disclosed both in cover letters to editors and in the Methods or Acknowledgements section of manuscripts."
125. The Indian Journal of Medical Research adheres to the World Association of Medical Editors (WAME) recommendations on artificial intelligence (AI) used in scientific publications.  Artificial intelligence tools such as ChatGPT or Large Language Model (LLM) based bots cannot be listed as a credited author of a paper published, only humans can perform tasks and take responsibility for the authorship of a scientific paper. If AI is used in any element of the research process including data collection, writing or editing of the text, preparation of tables or production of images or graphical elements, authors should disclose the use of AI in authoring the manuscript. Please note that authors are ultimately responsible and accountable for the contents of the work (including the accuracy of what is presented, and the absence of plagiarism), regardless of AI use."
126. AI, and in particular Generative AI represented by Large Language Models such as ChatGPT, Claude, and others, is advancing quickly and having a significant impact on academic publishing. We believe that it is essential for authors, reviewers and editors to be fully transparent in terms of the uses of AI and we request that authors disclose the use of AI in their cover letters to the Editors and provide an opening footnote in each article stating whether GenAI has been used for this paper, and, if so how. Submissions must clearly articulate what GenAI has been used for, which products and versions of GenAI have been used, and why GenAI was used. The Editors will be making an assessment about the appropriateness of each submission and will consider this as part of their decision."
127. Sage recognises the value of artificial intelligence (AI) and its potential to help authors in the research and writing process. Sage welcomes developments in this area to enhance opportunities for generating ideas, accelerating research discovery, synthesising, or analysing findings, polishing language, or structuring a submission.  Large language models (LLMs) or Generative AI offer opportunities for acceleration in research and its dissemination. While these opportunities can be transformative, they are unable to replicate human creative and critical thinking. Sage’s policy on the use of AI technology has been developed to assist authors, reviewers and editors to make good judgements about the ethical use of such technology.  For authors AI  assistance We recognise that AI assisted writing has become more common as the technology becomes more accessible. AI tools that make suggestions to improve or enhance your own work, such as tools to improve language, grammar or structure, are considered assistive AI tools and do not require disclosure by authors or reviewers. However, authors are responsible for ensuring their submission is accurate and meets the standards for rigorous scholarship.  Generative AI The use of AI tools that can produce content such as generating references, text, images or any other form of content must be disclosed when used by authors or reviewers. Authors should cite original sources, rather than Generative AI tools as primary sources within the references. If your submission was primarily or partially generated using AI, this must be disclosed upon submission so the Editorial team can evaluate the content generated.   Authors are required to follow Sage guidelines, and in particular to:  Clearly indicate the use of language models in the manuscript, including which model was used and for what purpose. Please use the methods or acknowledgements section, as appropriate. Verify the accuracy, validity, and appropriateness of the content and any citations generated by language models and correct any errors, biases or inconsistencies. Be conscious of the potential for plagiarism where the LLM may have reproduced substantial text from other sources. Check the original sources to be sure you are not plagiarising someone else’s work. Be conscious of the potential for fabrication where the LLM may have generated false content, including getting facts wrong, or generating citations that don’t exist. Ensure you have verified all claims in your article prior to submission. Please note that AI bots such as ChatGPT should not be listed as an author on your submission.    While submissions will not be rejected because of the disclosed use of generative AI, if the Editor becomes aware that Generative AI was inappropriately used in the preparation of a submission without disclosure, the Editor reserves the right to reject the submission at any time during the publishing process. Inappropriate use of Generative AI includes the generation of incorrect text or content, plagiarism or inappropriate attribution to prior sources.   For Reviewers and Editors The use of AI or LLMs for Editorial work presents confidentiality and copyright issues. The tool or model will learn from what it receives over time and may use it to provide outputs to others.  AI assistance Reviewers may wish to use Generative AI to improve the quality of the language in their review.  If they do so, they maintain responsibility for the content, accuracy and constructive feedback within the review.  Journal Editors maintain overall responsibility for the content published in their journal and act as gatekeepers of the scholarly record. Editors may use Generative AI tools for assistance in looking for suitable peer-reviewers.  Generative AI Reviewers using ChatGPT or other Generative AI tools to generate review reports inappropriately will not be invited to review for the journal and their review will not be included in the final decision.  Editors must not use ChatGPT or other Generative AI to generate decision letters, or summaries of unpublished research.  Undisclosed or Inappropriate use of Generative AI Reviewers suspecting the inappropriate or undisclosed use of generative AI in a submission should flag their concerns with the Journal Editor. If Editors suspect the use of ChatGPT or any other generative AI in a submitted manuscript or a submitted review, they should consider this policy in undertaking an editorial assessment of the matter or contact their Sage representative for advice.  Sage and the Journal Editor will lead a joint investigation into concerns raised about the inappropriate or undisclosed use of Generative AI in a published article. The investigation will be undertaken in accordance with guidance issued by COPE and our internal policies.   Further information  Using AI in peer review and publishing | SAGE Publications Inc  Assistive and Generative AI Guidelines for Authors — Sage (sagepub.com)  New white paper launch: Generative AI in Scholarly Communications - STM (stm-assoc.org)  Committee on Publication Ethics (COPE)’s position statement on Authorship and AI tools.  World Association of Medical Editors (WAME) recommendations on chat bots, ChatGPT and scholarly manuscripts "
128. Authors who use artificial intelligence tools for enhancing the mathematical contents of their work are required to state this fact clearly and with precise details upon submission of their works for publication. Such statements will appear in the published versions of works.
129. In line with the COPE position on the use of AI tools such as ChatGPT in research publications, it is the policy of International Affairs that:  AI tools cannot meet the requirements of authorship because they are a non-legal entity, and as such they cannot claim responsibility for the submitted work nor assert the presence or absence of conflict of interest. Authors who use AI tools in any stage of the writing of the manuscript must disclose on the ScholarOne system what AI tools were used, in what capacity, and in what portions of the manuscript. Authors are fully responsible for the content of their manuscript, even those produced by AI tools, and as such are liable to any breach of COPE guidelines. Authors are encouraged to familiarize themselves with the COPE Position Statement on Authorship and AI Tools."
130. The International Journal of Epidemiology follows the COPE position statement on the use of artificial intelligence (AI) tools.  An AI tool such as ChatGPT or Large Language Models cannot be listed as an author of a paper. AI tools cannot meet the requirements for authorship as they cannot take responsibility for the submitted work. As non-legal entities, they cannot assert the presence or absence of conflicts of interest nor manage copyright and license agreements.  Authors who use AI tools in collecting and/or analysing data, or in producing images or graphical elements of the paper must be transparent in disclosing in the Methods section of the paper which AI tools were used and how they were used. Further, authors should declare their use of AI in the declarations section at the end of the paper.  Authors must maintain control of the results of AI use, as AI tools can produce content that is inaccurate or biased. Authors remain fully responsible and liable for the accuracy and integrity of their manuscript, even those parts produced by an AI tool, and are thus liable for any breach of publication ethics."
131. The following sections must be added at the end of the manuscript, prior to the Reference list:  Acknowledgements Funding Availability of data and materials Authors' contributions Ethics approval and consent to participate Patient consent for publication Competing interests Authors' information (optional) Use of artificial intelligence tools (to be included only when AI tools are used)"
132. Publishing Policies The publication of each peer-reviewed article published in a CSIRO Publishing journal is considered a component in the development of a coherent and respected network of knowledge that directly reflects the quality of work of the author and the institutions that support them.    As a publisher with a global reputation for scientific excellence, and in line with our Charter, CSIRO Publishing recognises the importance of high standards of ethical behaviour throughout the publication process. Our policies support this, and demonstrate our commitment to openness, transparency, and reproducibility in publishing. The following policies apply to all journals published by CSIRO Publishing.    These policies are regularly reviewed and updated to align with changes to industry standards.   In addition to the general procedures listed here, authors should refer to the Author Instructions for the individual journals for specific policies relevant to their research communities.   CSIRO Publishing is a member of the Committee on Publication Ethics (COPE) and supports the recommendations of the COPE Core Practices in our policies and procedures. Our journal editors are expected to work within the framework of the Core Practices, and according to the CSIRO Publishing Editorial Board Conduct Policy.  COPE logo    Use of inclusive language Sensitivities statements Use of artificial intelligence tools and technologies Authorship Contributorship Conflicts of interest Peer review Ethics approval Data Scientific misconduct, expressions of concern, and retractions Non-peer reviewed material Metrics  Use of inclusive language These guidelines should be used to assist in identifying appropriate language, but are by no means exhaustive or definitive. Inclusive language comprises carefully chosen words and phrases that are respectful and promote the acceptance and value of all people. It is language which is free from words, phrases or tones that demean, insult, exclude, stereotype, or trivialise people on the basis of their membership of a certain group or because of a particular attribute. As such, inclusive language should make no assumptions about the beliefs or commitments of any reader, and contain nothing which might imply that one individual is superior to another on any grounds including but not limited to: age, gender, race, ethnicity, culture, sexual orientation, disability or health condition. We encourage the use of plural nouns (e.g., 'they' as default wherever possible instead of 'he/she'), and recommend avoiding the use of descriptors that refer to personal attributes, unless there is scientific or clinical relevance. For further guidance on inclusive language see Inclusive language | Style Manual. If there are questions about language use and/or publishing with regards to Aboriginal and/or Torres Strait Islander peoples, please contact the Journal. We encourage authors to consider and acknowledge where research has been conducted on traditional lands and pay respects to traditional owners.   Return to Index   Sensitivities statements CSIRO Publishing supports the integration of diverse histories, knowledge and perspectives in our publications as well as representing traditional practices and voices of First Peoples. We encourage authors to consider working with co-authors from diverse backgrounds or experiences to provide different perspectives and authentic experience that will enrich their work.   To provide context or assist understanding, authors may occasionally use photographs or quotes to represent historical context. This content might include language that is now considered offensive to some readers or photographs and names of deceased First Peoples that require sensitivity warnings.   In addition to our authors’ due diligence in ensuring use of language or images is appropriate and cited in historical context, we ask for the inclusion cultural warnings and sensitivity statements at the abstract level, where appropriate. This will ensure we are giving adequate notice of sensitive content before it is seen by our readers. These warning will also be added to the table of contents during the editing and typesetting process.   We have provided some options below that can be used or adapted for the specific context of the article:   Warning: This article contains terms, descriptions and opinions that may be culturally sensitive and/or offensive to Aboriginal and Torres Strait Islander peoples. Warning: This article contains the names and/or images of deceased Aboriginal and Torres Strait Islander peoples. Warning: This article contains terms, descriptions and opinions used for historical context that may be culturally sensitive for some readers. It also includes the names and/or images of deceased Aboriginal and Torres Strait Islander peoples. Warning: This article contains terms, descriptions and opinions used for context that may be offensive to some readers.  Return to Index   Use of artificial intelligence tools and technologies   Authors Materials generated using Artificial Intelligence (AI) tools such as ChatGPT or Large Language Models (LLMs) may not be protected by copyright. Further, AI tools do not meet the criteria for authorship under our authorship policy, and cannot be listed as an author on a manuscript in accordance with the guidance of COPE. Use of generative AI tools in any aspect of the collection and analysis of data, generation of ideas or in preparation of a manuscript must be transparently disclosed in the manuscript (usually in the Materials and Methods section if available, otherwise in the Acknowledgements). The author(s) should describe how the AI tool was used, how the tool’s outputs were validated, and which tool was used (name, version, model, source).   Authors are responsible for the full content of their manuscript and are requested to check any part generated by an AI tool for accuracy and integrity, and to ensure all relevant sources are cited.   Reviewers An unpublished manuscript is a confidential document and should not be entered into LLMs or Chatbots. Entering any part of a manuscript or abstract, or the text of your review, into a chatbot, LLM, or similar tool is a violation of confidentiality. If such AI tools are used in a way that ensures confidentiality in the peer review process, reviewers must disclose and describe their use to the editor. Reviewers assume full responsibility for the review report they submit.
133. Policy on the use of AI tools by MIT Press authors and peer reviewers The MIT Press does not allow artificial intelligence (AI) tools such as ChatGPT or large language models (LLMs) to be listed as authors of our publications. The emerging consensus of scholarly organizations, including the Committee on Publication Ethics, is that AI tools do not meet the requirements for authorship since they cannot assume ethical and legal responsibility for their work.   MIT Press authors must represent to the press and to readers that their work is original as well as responsible and scholarly in its use of material created by others. Authors who use AI tools to produce text or images/graphics, or to collect data, must inform their editors of this use and be transparent about it in their manuscripts so that readers understand the role of these tools in the development of the work. Authors are fully responsible for the content of their manuscripts, including any portions produced by AI tools, and are liable for any ethical breaches that may result from the use of such content.  Usage of large language models or other artificial intelligence tools to assist in the peer review process is strictly prohibited. "
134. Use of AI by Authors A generative AI technology cannot be listed as a co-author or author of any submitted manuscript.  If the author of a submitted manuscript has used any content (text or imagery) produced and/or edited with a generative AI technology, this must be disclosed (i.e., acknowledged in the acknowledgments section and/or the methods section as appropriate). The disclosure should include the name, version, model, and source of the generative AI technology as well as the date the content was created and/or edited. Additionally, the author is responsible for checking the accuracy of any content created by the generative AI technology (including references and any code). Authors are also responsible to check that any content produced and/or edited with a generative AI technology is free from plagiarism. Submission of work containing plagiarized content resulting from use of a generative AI technology is considered ethical misconduct and would subject the authors to the consequences outlined in the ARVO Publications Ethics Statement.  Use of AI by Reviewers and Editors Consistent with NIH policy NOT-OD-23-149, reviewers and editors are prohibited from using AI tools when conducting peer review of unpublished work."
135. Authorship: All authors/coauthors must have an appropriate degree and institutional affiliation to have contributed to the manuscript. Adding coauthors in the revision stage of the peer review process will be allowed only in special instances approved by the editor-in-chief, and adding authors/coauthors after acceptance is not allowed. The author order cannot be changed after manuscript acceptance. Each author is required to have individually and significantly contributed to the manuscript and to have participated in the study to a significant extent.  Single first authorship is considered to be the standard of reference, and the vast majority of accepted papers fall into this category. Co-first authorship is permitted (2 first authors only), with a statement of justification required from the authors and approval by the editor-in-chief. There can be only one corresponding author, and there can be only one senior author.  Authorship credit should be based on 1) substantial contributions to conception and design, acquisition of data, or analysis and interpretation of data; 2) drafting the article or revising it critically for important intellectual content; 3) final approval of the version to be published; 4) Agreement to be accountable for all aspects of the work in ensuring that questions related to the accuracy or integrity of any part of the work are appropriately investigated and resolved. Authors should meet all four conditions.  The journal does not consider Artificial Intelligence authoring tools to meet the requirements for Authorship as recommended by the ICMJE. Any use of such tools—which is discouraged—must be explained in detail in the cover letter accompanying the submission and must also be included in the article's Acknowledgments. For additional information, please refer to RSNA’s policy on Artificial Intelligence: https://pubs.rsna.org/page/policies#llm  Although the editors and reviewers make every effort to ensure the validity of published manuscripts, the final responsibility rests with the authors, not with the Journal, its editors, or the publisher.
136. A note on the use of Artificial Intelligence (Addition 10 April 2024)  It is not permitted to use generative AI — such as ChatGPT etc. — to generate a review report. The manuscript is provided to reviewers under confidentiality and by uploading someone else’s materials into the training set and/or knowledge base of a generative AI product, the reviewer is breaking that confidentiality. This also extends to the review report, which contains information from the manuscript."
137. Authors must declare the use of generative AI in scientific writing upon submission of the paper. The below guidance only refers to the writing process, and not to the use of AI tools to analyze and draw insights from data as part of the research process.  Generative AI and AI-assisted technologies should only be used in the writing process to improve the readability and language of the manuscript. The technology must be applied with human oversight and control and authors should carefully review and edit the result, as AI can generate authoritative-sounding output that can be incorrect, incomplete or biased. Authors are ultimately responsible and accountable for the contents of the work. Authors must not list or cite AI and AI-assisted technologies as an author or co-author on the manuscript since authorship implies responsibilities and tasks that can only be attributed to and performed by humans. The use of generative AI and AI-assisted technologies in scientific writing must be declared by adding a statement at the end of the manuscript when the paper is first submitted. The statement will appear in the published work and should be placed in a new section after the ""declaration of interests"" section. An example:  Title of new section: Declaration of generative AI and AI-assisted technologies in the writing process. Statement: During the preparation of this work the author(s) used [NAME TOOL / SERVICE] in order to [REASON]. After using this tool/service, the author(s) reviewed and edited the content as needed and take(s) full responsibility for the content of the published article. The declaration does not apply to the use of basic tools, such as tools used to check grammar, spelling and references. If you have nothing to disclose, you do not need to add a statement.  We advise you to read Elsevier's policy Opens in new window  for authors on the use of generative AI and AI-assisted technologies.  Please note that to protect authors’ rights and the confidentiality of their research, this journal does not currently allow the use of Generative AI or AI-assisted technologies such as ChatGPT or similar services by reviewers Opens in new window  or editors Opens in new window   in the peer review and manuscript evaluation process. We are actively evaluating compliant AI tools and may revise this policy in the future.  Generative AI and figures, images, and artwork Please read our policy Opens in new window   on the use of generative AI and AI-assisted tools in figures, images and artwork, which states:  We do not permit the use of Generative AI or AI-assisted tools to create or alter images in submitted manuscripts. The only exception is if the use of AI or AI-assisted tools is part of the research design or methods (for example, in the field of biomedical imaging). If this is the case, such use must be described in a reproducible manner in the methods section, including the name of the model or tool, version and extension numbers, and manufacturer. The use of generative AI or AI-assisted tools in the production of artwork such as for graphical abstracts is not permitted. The use of generative AI in the production of cover art may in some cases be allowed, if the author obtains prior permission from the journal editor and publisher, can demonstrate that all necessary rights have been cleared for the use of the relevant material, and ensures that there is correct content attribution."
138. JID supports the World Association of Medical Editors’ recommendations on AI, chatbots and scholarly manuscripts. If AI, a Large Language Model (LLM), or a similar tool is used in the development of a paper for JID, the following is required:  The AI/LLM cannot be credited as an author, as authorship requires that the author be accountable for the submitted/published work, and artificial intelligence cannot fulfill this requirement of authorship. Authors listed on the paper must review the content generated by the AI/LLM and take full responsibility for it, as they would for any other content within the submitted/published work. The use of AI/LLM tools must be noted in response to the manuscript submission question, “Did any author utilize any AI writing assistance in the preparation of this manuscript (including text, graphics/image creation, data)?” The use of AI/LLM tools must be documented in the Methods, Acknowledgments, or another appropriate section of the paper. If an editor or reviewer uses AI in their evaluation of a paper, the editor/reviewer must disclose this to each other and to the author of the paper. Editors and reviewers may not upload a manuscript to an AI, LLM, or similar system, as this would violate confidentiality.  Originality  By submitting your manuscript to JID, it is understood that this it is an original manuscript and is unpublished work and is not under consideration elsewhere. Plagiarism, including duplicate publication of the author’s own work, in whole or in part, without proper citation is not tolerated by JID. Manuscripts submitted to JID may be checked for originality using anti-plagiarism software.
139. Oxford Journals, publisher of Innovation in Aging, is a member of the Committee on Publication Ethics (COPE), and the journal strives to adhere to the COPE code of conduct and guidelines. For further information, see Authorship and AI tools. Following COPE and the International Committee of Medical Journal Editors (ICMJE) guidelines for Artificial Intelligence (AI) Assisted Technology, the following should be observed.  The use of artificial intelligence (AI) tools cannot meet the requirements for authorship as they cannot take responsibility for the submitted work. As non-legal entities, they cannot assert the presence or absence of conflicts of interest nor manage copyright and license agreements. Authors who use AI tools in the writing of a manuscript, production of images or graphical elements of the paper, or in the collection and analysis of data, must be transparent in disclosing in the Materials and Methods (or similar section) of the paper how the AI tool was used and which tool was used. Authors are fully responsible for the content of their manuscript, even those parts produced by an AI tool, and are thus liable for any breach of publication ethics.  All authors should follow COPE and the International Committee of Medical Journal Editors (ICMJE) guidelines for Artificial Intelligence (AI) Assisted Technology. Thereby, authors are required to disclose whether they used artificial intelligence (AI)-assisted technologies (such as Large Language Models [LLMs], chatbots, or image creators) in the production of submitted work in the Methods (or similar section) of the paper, which AI tool was used, and how the AI tool was used. Authors should not list AI and AI-assisted technologies as an author or co-author, nor cite AI as an author. Authors should be able to assert that there is no plagiarism in their paper, including in text and images produced by the AI. Humans must ensure there is appropriate attribution of all quoted material, including full citations."
140. The author affiliation(s) listed should be the institution(s) where the majority of the research was conducted. If an author has multiple affiliations all the relevant institutions should be listed. If the present address of an author is different from that at which the work was conducted, that address should be stated in a footnote and not as an affiliation.  Artificial intelligence (AI) tools, such as ChatGPT or other Large Language Models, cannot be listed as an author on a submitted work. AI tools do not meet the criteria to qualify for authorship, as they are unable to take responsibility for the work, cannot consent to publication nor manage copyright, licence or other legal obligations, and are unable to understand issues around conflicts of interest. Any use of AI tools in producing any part of the manuscript must be clearly described in the Experimental or Acknowledgement section. The authors are fully responsible and accountable for the content of their article, including any parts produced by an AI tool.
141. Authors should observe high standards with respect to publication best practices. Falsification or fabrication of data, plagiarism (including duplicate publication of the authors' own work without proper citation), and misappropriation of the work are all unacceptable practices. Any cases of ethical misconduct are treated very seriously and will be managed in accordance with the Commission on Publication Ethics (COPE) guidelines. Integrative Organismal Biology is published in partnership with Oxford University Press and as such follows both SICB and OUP ethical policies. Further information about Oxford University Press's (OUP) ethical policies."
142. Artificial intelligence (AI) is software used by computers to mimic aspects of human intelligence.  AI-assisted technologies are software applications that use artificial intelligence algorithms to perform specific tasks and solve problems.   Machine learning is an application of AI that enables systems to learn and improve from experience without being explicitly programmed.  Authors must disclose in the manuscript their use and a statement will be required in the published work. The statement should provide detail of which elements of the work were generated by AI and AI-assisted technologies. Editors and reviewers will judge if its use is appropriate. Published articles in which the use of such technologies is subsequently discovered may be retracted. Research articles on the topic of AI (but which do not contain AI-generated content) are not within the scope of this policy.  Where used in the writing process, these technologies should only be used to improve readability and language of the work. Use of AI in language editing must be declared. They may be used as a ‘search engine’ e.g., to aid identification of suitable code or statistical techniques. Use of AI to predict 3D protein structures is another example of legitimate use.  They must not replace key researcher tasks such as producing scientific insights, analysing and interpreting data or drawing scientific conclusions.  In addition:  Such systems must not plagiarize, misrepresent, or falsify content.   The resulting work in its totality must be an accurate representation of the authors’ underlying work and novel intellectual contributions and is not primarily the result of the tool’s generative capabilities. It is recognised that these technologies can produce unpredicted outcomes (e.g., references which do not exist), the authors accept responsibility for the veracity and correctness of all material in their work, including any computer-generated material. Authors must not list AI and AI-assisted technologies as an author or co-author, nor cite AI as an author. Authorship implies responsibilities and tasks that can only be attributed to and performed by humans. Authors are also responsible for ensuring that the work is original, that the stated authors qualify for authorship, and the work does not infringe third party rights, and should familiarize themselves with our publishing policies.
143. Following the COPE guidelines, if any AI tool (such as ChatGPT) is used in any part of the manuscript, including: the writing of the manuscript, full or partial generation of images used in the manuscript, collecting data, or analysing data, the authors must fully disclose this in the Acknowledgements section, and also state in the Materials and Methods section how the AI tool was used, which tool was used, and what parts of the text or images were affected. Note that an AI tool cannot be listed as an author of a manuscript."
144. IGI Global allows limited use of AI tools to support authors' writing processes. However, as AI can produce incorrect, repetitive, or biased output, authors must provide a level of oversight and control in its usage and must carefully review and edit the content generated. Authors are ultimately accountable for the contents of the work. Authors may use AI tools to:  Support the analysis of data during the research process. Improve the readability of the paper. Authors choosing to use AI tools in the research and writing process must also disclose the tool and its usage by providing a written statement in the manuscript.  No AI tool will be credited with authorship and authors should not list or cite any AI as an author. This is because only humans have the ability to accept the responsibilities and accountability for the work, such as confirming its accuracy and integrity, of which AI cannot take responsibility."
145. In line with COPE guidelines, artificial intelligence tools (e.g. ChatGPT) cannot be listed as named authors on submitted articles. Authors are fully responsible for the content of their article, even those parts produced by any AI tool, and are thus liable for any inaccuracies or breach of publication ethics.  Authors who have used AI tools to develop their article and/or to write, generate or edit text must include a note in the article's Acknowledgements section describing the technologies used and their purpose.  Please note that this policy does not apply to software such as spelling or grammar checkers or reference managers. Authors using such tools do not need to include a note about them in the Acknowledgements section."
146. Please note that we do not accept papers that are generated by Artificial Intelligence (AI) or Machine Learning Tools primarily because such tools cannot take responsibility for the submitted work and therefore cannot be considered as authors. Where such tools or technologies are used as part of the design or methodology of a research study, their use should be clearly described in an acknowledgements section.  Please contact the journal editor or contact us with any authorship disputes that arise.
147. When traditional and generative AI technologies are used to create, review, revise, or edit any of the content in a manuscript, authors should report in the Acknowledgment section the following:  Name of the AI software platform, program, or tool Version and extension numbers Manufacturer Date(s) of use A brief description of how the AI was used and on what portions of the manuscript or content Confirmation that the author(s) take responsibility for the integrity of the content generated Note this guidance does not apply to basic tools for checking grammar, spelling, references, and similar.  AI Used in Research When AI (eg, large language model [LLM] or natural language processing [NLP], supervised or unsupervised machine learning [ML] for predictive/prescriptive or clustering tasks, chatbots, or similar other technologies) is used as part of a scientific study, authors should:  Follow relevant reporting guidelines for specific study designs when they exist and report each recommended guideline element with sufficient detail to enable reproducibility. Avoid inclusion of identifiable patient information in text, tables, and figures. Be aware of copyright and intellectual property concerns. If content protected by copyright was entered into the AI model by authors, include a copy of the permission or license from the copyright owner and describe this permission/license in the Methods section. If content (text, images, multimedia) generated by AI is included in a submitted manuscript or supplemental material, indicate rights or permissions to publish that content as determined by the AI service or owner in the Methods section or in the legend(s) of any AI-generated figures or multimedia. Also address the following:  Methods Section  Include the study design and, if a relevant reporting guideline exists, indicate how it was followed, with sufficient detail to enable reproducibility. Describe how AI was used for specific aspects of the study (eg, to generate or refine study hypotheses, assist in the generation of a list of adjustment variables, create graphs to show visual relationships). For studies using LLMs, provide the name of the platform or program, tool, version, and manufacturer; specify dates and prompt(s) used and their sequence and any revisions to prompts in response to initial outputs. For studies reporting ML and algorithm development, include details about data sets used for development, training, and validation. Clearly state if algorithms were trained and tested only on previously collected or existing data sets or if the study includes prospective deployment. Include the ML model and describe the variables and outcome(s) and selection of the fine-tuning parameters. Describe any assumptions involved (eg, log linearity, proportionality) and how these assumptions were tested. Indicate the metric used to evaluate the performance of the algorithms, including bias, discrimination, calibration, reclassification, and others as appropriate. Indicate the methods used to address missing data. Indicate institutional review board/ethics review, approval, waiver, or exemption. Describe methods or analyses included to address and manage AI-related methodologic bias and inaccuracy of AI-generated content. Indicate, when appropriate, if sensitivity analyses were performed to explore the performance of the AI model in vulnerable or underrepresented subgroups. Provide a data sharing statement, including if code will be shared. Results Section  When reporting comparisons, provide performance assessments (eg, against standard of care), include effect sizes and measures of uncertainty (eg, 95% CIs) and other measurements such as likelihood ratios, and include information about performance errors, inaccurate or missing data, and sufficient detail for others to reproduce the findings. Report the results of analyses to address methodologic bias and population representation. If examples of generated text or content are included in tables or figures, be sure to indicate the source and licensing information, as noted above. Discussion Section  Discuss the potential for AI-related bias and what was done to identify and mitigate such bias. Discuss the potential for inaccuracy of AI-generated content and what was done to identify and manage this. Discuss generalizability of findings across populations and results of analyses performed to explore the performance of the AI model in vulnerable or underrepresented subgroups.
148. The use of artificial intelligence (AI) authoring tools is acceptable; however, this must be acknowledged in the Declarations section. Moreover, authors who use AI tools in the writing of a manuscript, production of images or graphical elements, or in the collection and analysis of data must be transparent in disclosing in the Materials and Methods (or similar section) which AI tool was used and how it was used. Authors are fully responsible for the content of their manuscript, even those parts produced by an AI tool, and are thus liable for any breach of publication ethics. 3 JBI Evidence Implementation: Policy: Manuscript Authorship_Version_001 Authors should not upload an accepted or published manuscript or any part of it into a generative AI tool, as this may violate the copyright agreement or licensing terms in effect at the time of acceptance. If you have questions about this policy or any other authorship-related matters, please contact the journal’s editorial office. Alex Mignone Journal Manager JBI Evidence Implementation JBI, University of Adelaide
149. Use of generative AI technology to generate or modify data images is strictly prohibited. Peer reviewers are not permitted to use AI technologies to write reviews. Generative AI technologies may not be listed as authors on submitted manuscripts.  Generative AI technologies used for written or visual content must be explicitly described within the Methods section of the submission. This description must specify what content is AI generated, as well as the AI platform, version used, and date of use. The Editors encourage authors to provide full details regarding the prompts provided, either in Methods or Supplemental Methods. Authors are responsible for verifying the accuracy of AI-generated content.
150. JCO Journals recognize that authors may find utility in using artificial intelligence (AI)/large language models (LLMs) in their scientific writing.  Accordingly, we offer specific guidance on the appropriate use of these tools for manuscripts submitted to JCO Journals.  Authors must be aware of the rapidly evolving capabilities and deficiencies of these tools. Authors remain responsible for the accuracy of all content submitted and are liable for any breach of publication ethics. JCO Journals do not accept manuscripts with nonhuman authors. LLMs and AI tools cannot be listed as an author under any circumstances. The use of LLMs and AI tools to generate written content in submissions is generally discouraged. LLMs and AI tools used to assist in writing Original Reports or Clinical Trial Updates must be noted in the Acknowledgments. If LLMs or AI tools are used in the research itself (eg, data analysis), it must be disclosed in the Methods section. In either place, the authors must note: the LLM or AI tool used, the version number, the date accessed, the manufacturer/creator name, and a description of how and for which parts of the submission the tools were used. AI tools used to assist with grammar, spelling, formatting, and reference clean up do not need to be disclosed. JCO Journals forbid the use of LLMs or AI tools in the preparation of submissions primarily advancing the author’s opinion and perspective. We invite authors to craft opinion pieces and targeted Reviews precisely because we value their opinion and insight. The use of LLMs and AI to draft content for those submissions is not allowed. Reviewers may not use LLMs or AI tools when reviewing work submitted to JCO Journals for peer review. See “Use of Large Language Models and Artificial Intelligence Tools in Works Submitted to Journal of Clinical Oncology.”
151. University of Illinois Press Generative AI Use Policy Overview From the COPE (Committee on Publication Ethics) guidelines: “Authors are fully responsible for the content of their manuscript, even those parts produced by an AI tool, and are thus liable for any breach of publication ethics.” Additionally, any use of AI tools should be documented and cited properly. Background The use of artificial intelligence tools (AI) is becoming an increasingly customary tool for writing, but the rules for the use of this software in research articles have not yet been standardized. The process of scraping websites for their content, including copyrighted content, and aggregating the output into text, can violate copyright and produce text that plagiarizes ideas. Misrepresenting the output from generative software as an author’s own runs the risk of plagiarism, as the AI output does not acknowledge the primary, possibly copyrighted, sources. Text generated by AI tools cannot be copyrighted at present, because copyright requires a human author. The University of Illinois Press requires that all authors submitting to journals are responsible for the text submitted. If AI generated text is used or cited in the text, this must be acknowledged. Policy The Journals Department at the Press is following the policy of COPE (Committee on Publication Ethics) for disclosure guidelines: “Authors who use AI tools in the writing of a manuscript, production of images or graphical elements of the paper, or in the collection and analysis of data, must be transparent in disclosing in the Materials and Methods (or similar section) of the paper how the AI tool was used and which tool was used. Authors are fully responsible for the content of their manuscript, even those parts produced by an AI tool, and are thus liable for any breach of publication ethics.” University of Illinois Press Generative AI Use Policy Citation Examples Documenting how the software was used in the production of the text can happen in different ways. The Chicago Manual of Style suggests that “for most types of writing, you can simply acknowledge the AI tool in your text (e.g., “The following recipe for pizza dough was generated by ChatGPT”). For a research article a footnote might looks like this: 1. Text generated by ChatGPT, OpenAI, March 7, 2023, https://chat.openai.com/chat. If the prompt used to generate the output has not been included in the text, like this: 1. ChatGPT, response to “Explain how to make pizza dough from common household ingredients,” OpenAI, March 7, 2023 Examples of how to cite in a couple of other styles are shown below. Please view submission guidelines for each journal to determine the appropriate style required. APA OpenAI. (2023). ChatGPT (Mar 14 version) [Large language model]. https://chat.openai.com/chat MLA Full citation in works cited page: “Summarize the book Thus Spoke Zarathustra” prompt. ChatGPT, GPT-4, OpenAI, 30 Jun. 2023, chat.openai.com/chat. Parenthetical citation in text: (“Summarize the book”)
152. For this policy, AI refers to generative LLM AI tools and does not include grammar-checking software, citation software, or plagiarism detectors.  When a generative artificial intelligence (AI) model is used in the drafting of a manuscript for an APA publication, the use of AI must be disclosed in the methods section and cited. AI cannot be named as an author on an APA scholarly publication. When AI is cited in an APA scholarly publication, the author must employ the software citation template, which includes specifying in the methods section how, when, and to what extent AI was used. Authors in APA publications are required to upload the full output of the AI as supplemental material. The authors are responsible for the accuracy of any information in their article. Authors must verify any information and citations provided to them by an AI tool. Authors may use but must disclose AI tools for specific purposes such as editing. No submitted content may be entered into generative AI tools as this violates the confidentiality of the process. Additional reading material:  APA Style Blog: How to cite ChatGPT (apa.org) COPE Position Statement: Authorship and AI tools | COPE: Committee on Publication Ethics US Copyright Office Guidance: Federal Register :: Copyright Registration Guidance: Works Containing Material Generated by Artificial Intelligence
153. Artificial Intelligence (AI) chatbots and Large Language Models (LLMs), including but not limited to, ChatGPT by Open AI, Google Gemini, and Microsoft Bing do not meet the requirements for authorship and, therefore, may not be listed as an author.  Use of AI or LLM programs for the writing of a manuscript (including using them to polish, condense, or otherwise lightly edit the writing), generation of graphical or image elements, or in the collection or analysis of data, should be documented and explained in the “Materials and methods” section of the manuscript. Authors should clearly illustrate which tool was used and its precise usage within the manuscript.
154. The use of artificial intelligence (AI) tools must be disclosed during the submission process and also described in the Methods or Acknowledgments sections of the text.
155. Use of AI Tools: The MIT Press does not allow artificial intelligence (AI) tools such as ChatGPT or large language models (LLMs) to be listed as authors of our publications. The emerging consensus of scholarly organizations, including the Committee on Publication Ethics, is that AI tools do not meet the requirements for authorship since they cannot assume ethical and legal responsibility for their work.  MIT Press authors must represent to the press and to readers that their work is original as well as responsible and scholarly in its use of material created by others. Authors who use AI tools to produce text or images/graphics, or to collect data, must inform their editors of this use and be transparent about it in their manuscripts so that readers understand the role of these tools in the development of the work. Authors are fully responsible for the content of their manuscripts including any portions produced by AI tools, and are liable for any ethical breaches that may result from the use of such content.  Individual MIT Press journals may have rules around AI and LLM usage that are more restrictive and specific to that title. Please check the submission guidelines for more information.  Additionally, we encourage our authors to adhere to the following publishing standards:
156. Artificial Intelligence and Authorship  ASCE is a member of COPE, the Committee on Publication Ethics. As such, ASCE follows COPE Guidelines on artificial intelligence and authorship. Our policy is that AI software cannot be listed as an author on a paper.  ChatGPT and similar software is not human, and for this reason cannot independently design studies, create and critique methodologies, interpret data, or be held responsible for the outcomes and implications of the study in question. For this reason, ChatGPT and similar software should be treated as a tool, not an author. For more information on COPE’s guidance on AI and authorship, please visit the COPE website.  Artificial Intelligence and Automated Tools  ASCE policies on the use of AI and automated tools are the following:  ASCE will not review or accept manuscripts written by nonhuman authors. Large Language Models (LLMs) and Artificial Intelligence (AI) tools should not be listed in a byline for any reason. Authors are required to disclose whether artificial intelligence (AI) tools were used in the creation and preparation of their manuscripts. ASCE reserves the right to ask for and receive detailed information on how LLMs and AI were used in the creation of a manuscript. Reviewers shall not use LLMs or AI tools when reviewing manuscripts or preparing comments to authors. Future developments: ASCE will continue to monitor the ethical implications of using AI tools and automation as they evolve and change. More information about COPE’s guidelines and recommendations regarding AI tools and automation can be found here.
157. If authors use generative artificial intelligence and artificial intelligence–assisted technologies in the writing process, they must include a statement in the Notes section: During the preparation of this work, the author(s) used [tool or service] in order to [reason for use]. After using [tool or service], the author(s) reviewed and edited the content as needed and take(s) full responsibility for the content of the publication. A statement is not necessary for the use of basic tools (for example, those that check grammar, spelling, references, and so on). A statement is not needed if there is nothing to disclose
158. The use of AI in publishing is rapidly evolving and JXB will continue to adjust guidance for authors as developments occur. JXB decision making with regards to the use of AI follows current recommendations made by the Committee on Publication Ethics (COPE). In accordance with the COPE position statement on Authorship and AI tools, generative artificial intelligence (AI) tools, such as the large language model ChatGPT, cannot be listed as an author of a paper. Authors are required to take responsibility and accountability for the submitted work, state any conflicts of interest, and consent to copyright and license agreements. As non-legal entities, AI tools do not meet these authorship requirements.  The use of such tools, for example, to generate content, process data, or improve English, must be disclosed in the cover letter and described in detail in the Material and Methods section or the Acknowledgements. The description should include the name of the AI tool, date and time accessed, and the prompts used to generate content. Authors are fully responsible for the content of their manuscript including AI generated content and are thus liable for any breach of publication ethics. Exempt from this policy are tools used for general text editing or to improve spelling and grammar, such as the in-built spelling and grammar checkers in Microsoft Word and similar word-processing tools. Please contact the editorial office (j.exp.bot@lancaster.ac.uk) if you have any questions about declaring a specific tool.  More information about AI in publishing is available from Oxford University Press.
159. Artificial Intelligence and Automated Tools  ASCE policies on the use of AI and automated tools are the following:  ASCE will not review or accept manuscripts written by nonhuman authors. Large Language Models (LLMs) and Artificial Intelligence (AI) tools should not be listed in a byline for any reason. Authors are required to disclose whether artificial intelligence (AI) tools were used in the creation and preparation of their manuscripts. ASCE reserves the right to ask for and receive detailed information on how LLMs and AI were used in the creation of a manuscript. Reviewers shall not use LLMs or AI tools when reviewing manuscripts or preparing comments to authors. Future developments: ASCE will continue to monitor the ethical implications of using AI tools and automation as they evolve and change. More information about COPE’s guidelines and recommendations regarding AI tools and automation can be found here.
160. Additionally, authors may use artificial intelligence (AI) tools or technology for language editing. Both language-editing services and AI used in the preparation of a manuscript must be disclosed in the Acknowledgments at the time of submission.
161. It is the collective responsibility of all those who have conducted the work to define who should be listed as a co-authors, the order of the listing and who should be acknowledged in another way.  Other contributors, who participated in certain aspects of the research project, should be named in an acknowledgement section.  Please note that we do not accept papers that are generated by Artificial Intelligence (AI) or Machine Learning Tools primarily because such tools cannot take responsibility for the submitted work and therefore cannot be considered as authors. Where such tools or technologies are used as part of the design or methodology of a research study, their use should be clearly described in an acknowledgements section.  Please contact the journal editor or contact us with any authorship disputes that arise.
162. Artificial Intelligence (AI) and Machine Learning (ML) JOSPT Journals’ Editorial Policy on Using Machine Learning, Artificial Intelligence and Generative AI When Creating and Publishing Scientific Works Definitions Artificial Intelligence (AI): AI describes various attempts to develop machines, computers and software that are able to perform tasks which typically require human cognitive functions.  Machine Learning (ML): An application of AI where algorithms are used to analyze data and ‘learn’ from statistical associations within the data. ML models are the output of the ML algorithms. Separating ML from ‘statistics’ is difficult, and many methods can be successfully used for different types of analyses.1 2  A simple rule of thumb is that ML methods are used to develop out-of-sample generalizable predictive patterns and are trained and optimized viarepetitive data analysis, whileinferential statistics are mathematical models used to draw inferences about a population from the analysis of sample data.1 2 9 For more information on ML approaches in medicine and biomedical research, see:3 9  Generative AI: Acategory of AI approaches that use advanced ML techniques to generate novel content (text, images, speech), which is intended to mimic human-produced content. Well-known examples include Open AI’s GPT and DALL-E and Google’s BARD, and Microsoft’s GitHub CoPilot. Reporting the Use of Machine Learning and AI Models in Different Types of Research JOSPTJournals requires authors to fully and transparently report any use and specifications of any and all ML or AI models used in their work. We encourage authors to consult existing guidelines for reporting ML and AI models in research. Authors should choose the most appropriate guideline, depending on the aims of their work and the type and use of the ML/AI model(see 4).  Authors who wish to submit a manuscript that includes data generated by ML/AI models, but would not be classified as one of the study types listed below, should ensure that the paper includes all information required in the “Minimum information about clinical artificial intelligence modeling” guidelines.7 A completed MI-CLAIM checklist should be included in the paper. Specific guidelines are given when authors have used or intend to use generative AI. Authors choosing to submit their work to any Movement Science Media journals (JOSPT, JOSPT Open, JOSPT Cases) are encouraged to share any code and data for their work. Clinical trials and intervention studies (including protocolsfor these studies) Relevant for randomized controlled trials (RCTs) that evaluate the clinical efficacy of interventionsthat include an AI/ML component. Authors should adhere to the ‘Consolidated Standards of Reporting Trials–Artificial Intelligence’ (CONSORT-AI)5 and the ‘Standard Protocol Items: Recommendations for Interventional Trials–Artificial Intelligence’ (SPIRIT-AI)8 guidelines when submitting trial reports and protocols in which AI/ML models were used. Authors should supply a completed version of the relevant checklist when submitting their paper. Medical imaging studies Relevant for studies that use AI/ML in the analysis and generation of images. Authors should adhere to the guidelines for the use of AI/ML in medical imaging studies.6 Authors must include the completed ‘Checklist for Artificial Intelligence in Medical Imaging’ (CLAIM) with the submission. Diagnostic and predictive studies Relevant for studies reporting on the use of AI/ML models to assess diagnostic test accuracy and performance or to estimate the diagnostic or prognostic presence of an outcome. At the time of writing, the AI/ML extensions for the ‘Standards for Reporting of Diagnostic Accuracy’ (STARD-AI), Transparent Reporting of a multivariable prediction model for Individual Prognosis Or Diagnosis tool’ and ‘Prediction model Risk Of Bias ASsessment Tool’ (PROBAST-AI) are still being developed. Until the guidelines become available, authors should ensure that their manuscript includes all information detailed in the ‘Minimum information about clinical artificial intelligence modeling’ guidelines.7 Include acompleted MI-CLAIM checklist with the submission. Studies evaluating Generative AI Relevant for studies evaluating generative AI performance in health care or research. Details of the generative AI model, vendor or origin, version and date of use must be provided in the Method section of the submitted manuscript. Authors must quote the exact system and user prompts used alongside the Application Programming Interface (API) specifications (where relevant). Include all prompts as a supplementary file. Text, images, code or other content produced by generative AI can only be included in the supplementary material and must be appropriately labelled with the source.  Where appropriate, model accuracy, error rates, the number of ‘hallucinations’or other falsifications, and other statistics that would allow readers to determine the quality of the model output should be provided in the Results sections of the manuscript. For studies evaluating generative AI in clinical decision-making, authors should consult the reporting guidelines for the early-stage clinical evaluation of decision support systems driven by artificial intelligence (DECIDE-AI).10 Using Generative AI when preparing manuscripts and interpreting data These guidelines are relevant for authors who have used, or wish to use, generative AI systems to write parts of a scientific paper or assist with interpreting scientific data.  Generative AI models, including Large Language Models (e.g. ChatGPT, BARD), arenot accepted as authors of manuscripts submitted to JOSPT, JOSPT Open and JOSPT Cases. Generative AI models do not meet the International Committee of Medical Journal Editors (ICMJE) criteria for authorship: produced by generative AI cannot be included in the submitted manuscript. Movement Science Media journals will not accept manuscripts where generative AI wasused to generate text, images, graphics or speech or code, or where generative AI was used to interpret data.  Authors may use tools with embedded generative AI systems that assist with preparing manuscriptsand/or analysis (e.g. grammar correction, language translation or title and abstract screening for systematic reviews).Authors are required to acknowledge the use of these systems and provide information about how they were used, the version and vendor of the tool. Using Generative AI in the Editorial Process Using a commercially available generative AI system (e.g. ChatGPT, BARD etc.) to assist peer reviewers and editors with reviewing and/or editinga manuscriptis not permitted by any of the JOSPT journals (i.e. JOSPT, JOSPT Open, JOSPT Cases). Additional reading Committee On Publication Ethics (COPE): https://publicationethics.org/news/artificial-intelligence-and-authorship World Association of Medical Editors (WAME): https://wame.org/page3.php?id=106Chatbots, Generative AI, and Scholarly Manuscripts || WAME  International Committee of Medical Journal Editors: https://www.icmje.org/recommendations/
163. Authorship is limited to those who have made a significant contribution to the design and execution of the work described. Any contributors whose participation does not meet the criteria for authorship should be acknowledged but not listed as an author. The Journal will contact all listed authors at the point of submission to confirm their role.  The Journal does not allow ghost authorship, where an unnamed author prepares the article with no credit, or guest/gift authorship, where an author who made little or no contribution is listed as an author. The Journal follows Committee on Publication Ethics (COPE) guidance on investigating and resolving these cases. For more information, please see the OUP Publication Ethics page.  Natural language processing tools driven by artificial intelligence (AI) do not qualify as authors, and the Journal will screen for them in author lists. The use of AI (for example, to help generate content or images, write code, process data, or for translation) should be disclosed both in cover letters to editors and in the Methods or Acknowledgements section of manuscripts. Please see the COPE position statement on Authorship and AI for more details.  After manuscript submission, no authorship changes (including the authorship list, author order, and who is designated as the corresponding author) should be made unless there is a substantive reason to do so. The editor and all co-authors must agree on the change(s), and neither the Journal nor the publisher mediates authorship disputes. If individuals cannot agree on the authorship of a submitted manuscript, contact the editorial office at jph.editorialoffice@oup.com. The dispute must be resolved among the individuals and their institution(s) before the manuscript can be accepted for publication. If an authorship dispute or change arises after a paper is accepted, contact OUP’s Author Support team. COPE provides guidance for authors on resolving authorship disputes.  After submission, changing who is designated as the corresponding author will be permitted only where there is a substantive reason to do so. For the avoidance of doubt, changing the corresponding author in order to access Read and Publish funding is not permissible. For more information on Read and Publish funding, see the Open access charges section.
164. The use and declaration of AI and AI-assisted technologies in scientific writing  Where authors use artificial intelligence (AI) and AI-assisted technologies in any aspect of the work being reported in the submission and/or the development of submission materials, authors should:  Only use these technologies to improve readability and language, not to replace key researcher tasks such as interpreting data or drawing scientific conclusions.  Apply the technology with human oversight and control, and carefully review and edit the result, as AI can generate authoritative-sounding output that can be incorrect, incomplete, or biased.  Not list AI and AI-assisted technologies as an author or co-author or cite AI as an author. Authorship implies responsibilities and tasks that can only be attributed to and performed by humans, as outlined in Elsevier's AI policy for authors.  Disclose in their manuscript the use of AI and AI-assisted technologies by following the instructions below. A customized statement will appear in the published work. Please note that authors are ultimately responsible and accountable for the contents of the work.  Note: Peer reviewers should not use AI or AI-assisted technologies to review a paper. Reviewers should not upload the submitted manuscript or their peer review report into any AI tool as it may violate the authors' confidentiality and proprietary rights, and where the paper contains personally identifiable information, may breach data privacy rights. Read more in the Guide for Reviewers.  Disclosure instructions  Authors must disclose the use of AI and AI-assisted technologies in any aspect of the work being reported in the submission and/or the development of submission materials. A question during the submission process will prompt authors to disclose. If disclosed, authors will be prompted to customize the statement below, and include it on the title page in a new section entitled 'Declaration of AI and AI-assisted technologies in the writing process'. Statement: During the preparation of this work the author(s) used [NAME TOOL / SERVICE] in order to [REASON]. After using this tool/service, the author(s) reviewed and edited the content as needed and take(s) full responsibility for the content of the publication. This declaration does not apply to the use of basic tools for checking grammar, spelling, references etc. If there is nothing to disclose, there is no need to add a statement.  Neuroscience-based Nomenclature Child & Adolescent (NbN C&A)  JAACAP encourages authors submitting manuscripts reporting on the psychopharmacological treatment of child and adolescent mental health conditions (including experimental studies, randomized trials, observational studies, and reviews) to utilize the Neuroscience-based Nomenclature Child & Adolescent (NbN C&A).
165. Authorship is limited to those who have made a significant contribution to the design and execution of the work described. Any contributors whose participation does not meet the criteria for authorship should be acknowledged but not listed as an author. The Journal will contact all listed authors at the point of submission to confirm their role. For a detailed definition of authorship, please see the International Committee of Medical Journal Editors (ICMJE) definitions of authors and contributors.  The Journal does not allow ghost authorship, where an unnamed author prepares the article with no credit, or guest/gift authorship, where an author who made little or no contribution is listed as an author. The Journal follows Committee on Publication Ethics (COPE) guidance on investigating and resolving these cases. For more information, please see the OUP Publication Ethics page.  Natural language processing tools driven by artificial intelligence (AI) do not qualify as authors, and the Journal will screen for them in author lists. The use of AI (for example, to help generate content or images, write code, process data, or for translation) should be disclosed both in cover letters to editors and in the Methods or Acknowledgements section of manuscripts. Please see the COPE position statement on Authorship and AI for more details.
166. The submission of content created by generative AI is discouraged, unless it is part of formal research design or methods. Examples of content creation include writing the manuscript text, generating other content in the manuscript, as well as using the AI to generate ideas that are presented in the submitted manuscript. Software that checks for spelling, offers synonyms, makes grammar suggestions or is used to translate your own words into English does not generate new content, and we do not consider it generative AI.   If you choose to submit a manuscript with content created by generative AI systems, you must disclose and describe any use of these systems to do the following:   Write the manuscript text  Generate data, images, figures, citations  Generate ideas used in the text  Translate text other than your own words.  In doing so, you will be accepting full responsibility for the text’s factual and citation accuracy; mathematical, logical, and common-sense reasoning; and originality.   Disclosures can be made in the methods section AND among the references, as appropriate. Authors should specify:  1) who used the system 2) the time and date of the use 3) the prompt(s) used to generate the text 4) the sections(s) containing the text and/or the ideas in the paper resulting from generative AI use.  Additionally, the text generated by generative AI systems should be submitted as supplementary material.  While it is not possible to anticipate all possible iterations, an example of such a disclosure in the methods section could be: “In writing this manuscript, J.D. used OpenAI Chatbot on 23 February 2023 at 2:33 pm EST. The following prompt was used to write the introduction section: ‘Write a 300 word piece about health sciences libraries and the use of AI.’ The generated text was copied verbatim and is submitted as supplementary material.”   Generative AI systems cannot be listed as an author because they do not meet the criteria for authorship and cannot share responsibility for the paper or be held accountable for the integrity of the information reported.   This policy will be updated as things evolve. 
167. Natural language processing tools driven by artificial intelligence (AI) do not qualify as authors, and the Journal will screen for them in author lists. The use of AI (for example, to help generate content or images, write code, process data, or for translation) should be disclosed both in cover letters to editors and in the Methods or Acknowledgements section of manuscripts. Please see the COPE position statement on Authorship and AI for more details.  After manuscript submission, no authorship changes (including the authorship list, author order, and who is designated as the corresponding author) should be made unless there is a substantive reason to do so. The editor and all co-authors must agree on the change(s), and neither the Journal nor the publisher mediates authorship disputes. If individuals cannot agree on the authorship of a submitted manuscript, contact the editorial office at jtmedi.editorialoffice@oup.com.  The dispute must be resolved among the individuals and their institution(s) before the manuscript can be accepted for publication. If an authorship dispute or change arises after a paper is accepted, contact OUP’s Author Support team. COPE provides guidance for authors on resolving authorship disputes.  After submission, changing who is designated as the corresponding author will be permitted only where there is a substantive reason to do so. For the avoidance of doubt, changing the corresponding author in order to access Read and Publish funding is not permissible. For more information on Read and Publish funding, see the Open access charges section.
168. The below guidance only refers to the writing process, and not to the use of AI tools to analyze and draw insights from data as part of the research process.  Where authors use generative artificial intelligence (AI) and AI-assisted technologies in the writing process, authors should only use these technologies to improve readability and language. Applying the technology should be done with human oversight and control, and authors should carefully review and edit the result, as AI can generate authoritative-sounding output that can be incorrect, incomplete, or biased. AI and AI-assisted technologies should not be listed as an author or co-author or be cited as an author. Authorship implies responsibilities and tasks that can only be attributed to and performed by humans, as outlined in Elsevier's AI policy for authors.  Authors must disclose the use of generative AI and AI-assisted technologies in the writing process by adding a statement at the end of their manuscript before the References list. The statement should be placed in a new section entitled 'Declaration of Generative AI and AI-assisted technologies in the writing process'.  Statement: During the preparation of this work the author(s) used [NAME TOOL / SERVICE] in order to [REASON]. After using this tool/service, the author(s) reviewed and edited the content as needed and take(s) full responsibility for the content of the publication.  This declaration does not apply to the use of basic tools for checking grammar, spelling, references, etc. If there is nothing to disclose, there is no need to add a statement.
169. Artificial Intelligence (AI)–Assisted Technology: At submission, the Journal of Athletic Training requires authors to disclose whether they used artificial intelligence (AI)assisted technologies (such as Large Language Models [LLMs], chatbots, or image creators) in the production of submitted work. Authors who use such technology should describe, in both the cover letter and the submitted work, how they used it. Chatbots (such as ChatGPT) should not be listed as authors because they cannot be responsible for the accuracy, integrity, and originality of the work, and these responsibilities are required for authorship (see Section II.A.1). Therefore, humans are responsible for any submitted material that included the use of AI-assisted technologies. Authors should carefully review and edit the result because AI can generate authoritative-sounding output that can be incorrect, incomplete, or biased. Authors should not list AI and AI-assisted technologies as an author or co-author, nor cite AI as an author. Authors should be able to assert that there is no plagiarism in their paper, including in text and images produced by the AI. Humans must ensure there is appropriate attribution of all quoted material, including full citations. (International Committee of Medical Journal Editors. Recommendations for the Conduct, Reporting, Editing, and Publication of Scholarly Work in Medical Journals. Updated May 2023. https:// www.icmje.org/icmje-recommendations.pdf. Reprinted with permission.) 
170. All authors listed on the manuscript should have participated sufficiently in the work and analysis of data, as well as the writing of the manuscript to be listed as a co-author. All authors should have read and approved the final version. All authors will be required to attest to their involvement and approval of the final version prior to publication of the manuscript. The title page should state that all authors have seen and approved the manuscript. More than one corresponding author is permitted for each manuscript, and both authors will appear on the correspondence line on the final article. However, only one can be considered the corresponding author in the manuscript submission system; thus, only the author entered in the system as the corresponding author will receive automated messages, such as editors’ decisions and page proofs.  For guidelines on authorship, please refer to the Uniform Requirements for Manuscripts Submitted to Biomedical Journals, formulated by the International Committee of Medical Journal Editors. Artificial intelligence, large language models (such as ChatGPT), or similar technologies do not qualify for authorship. These technologies cannot satisfy all criteria of authorship, namely the ability to be held accountable for the work. The listed authors will be held accountable for all content created or edited by these technologies. Further, if one or more of these technologies were used in the composition of a manuscript, the authors must provide a statement that describes the content that was created or edited by this technology and the name of the language model or tool, version and extension numbers, and manufacturer on the title page of the manuscript. The use of basic tools for checking grammar, spelling, and organizing or checking references does not need to be disclosed.
171. After ChatGPT’s release on November 30, 2022, generative artificial intelligence (AI) fever was a hot topic in 2023. Many kinds of generative AI platforms appeared, including GPT-4, Bing, Gemini (former Bard), Claude.ai, Clova X, and Wrtn. The issues related to ChatGPT adoption discussed in research articles mainly dealt with passing tests, applicability in medical practice, and writing support [1]. Many manuscripts on generative AI have also been submitted to this journal. Most of them were accepted if the methods and interpretations were sound. Out of them, my brief report on ChatGPT’s performance on a parasitology exam, with a 60.8% correct answer rate [2], was the first article to be published in the journal on the performance of ChatGPT. Another remarkable article was written by a team of 1st year medical students. As a class assignment, they wrote an article comparing the performance of 6 generative AI platforms by information amount, accuracy, and relevance [3]. Their writing was quite impressive, with a core message focusing on the usefulness of generative AI platforms. The conclusion was also very informative—“A Korea-based company’s generative AI, Clova X, showed 100% relevance to the queries in Korea, which is the best performance out of the 6 generative AI platforms. The experience of using generative AI in the classroom enhanced the authors’ self-efficacy, which led to a heightened interest in the subject matter.” Dr. Ju Yoen Lee, a copyright law professor, wrote an article on AI authorship [4], which has also been a hot topic regarding the use of generative AI. She concluded, “Current AI chatbots such as ChatGPT are much more advanced than search engines in that they produce original text, but they still remain at the level of a search engine in that they cannot take responsibility for their writing. For this reason, they also cannot be authors from the perspective of research ethics.” The journal’s editorial policies on the use of generative AI in article writing and peer review have been announced [5]. The main difference from other journal publishers is that the Journal of Educational Evaluation for Health Professions (JEEHP) does not ask authors to disclose the use of AI tools. The reason for this is that the editorial office is not able to screen the use of AI tools consistently, although multiple similarity check tools are used. The fever of using generative AI in medical or health professions education will continue in 2024. The effects of using generative AI platforms will be a new topic in educational evaluation for health professions. In Taiwan, coronavirus disease 2019 (COVID-19) negatively impacted medical students’ clinical performance, regardless of their specialty [6]. This paper provides evidence regarding the challenges met during the COVID-19 pandemic, even though the pandemic led to the more active use of online tools and virtual reality environments in education.
172. The journal does not consider Artificial Intelligence (AI) authoring tools to meet the requirements for Authorship as recommended by the International Committee of Medical Journal Editors (ICMJE). The use of such tools may be included in the article’s Acknowledgements.  Authors who use AI tools in the writing of a manuscript, production of images or graphical elements of the paper, or in the collection and analysis of data, must be transparent in disclosing in the Methods section of the paper how the AI tool was used, and which tool was used. Authors are fully responsible for the content of their manuscript, even those parts produced by an AI tool, and are thus liable for any breach of publication ethics.
173. Publishing Ethics Statement (Last updated 27 November 2024)    John Benjamins Publishing Company is committed to meeting high standards of ethical behavior in all its publications. This statement outlines the publishing ethics responsibilities of the publisher, authors, peer reviewers and editors. We follow the guidance of the Committee on Publication Ethics (COPE), which provides advice and resources on publication ethics and research and publication misconduct.  We expect our publishing partners, editors, authors and peer reviewers to uphold any relevant confidentiality arrangements for each book or journal, to raise concerns in the case of any suspected breach of ethics, and to disclose any conflicts of interest.  Concerns in these respects about research published by John Benjamins Publishing Company should be raised with the relevant (journal) editor(s) and/or the publisher (ethics at benjamins.nl).  AUTHOR’S RESPONSIBILITIES The authors’ central obligation is to present a concise, accurate account of the research performed as well as an objective discussion of its significance. A paper should contain sufficient detail and references to public sources of information to permit others to repeat the work.  The submitted manuscript must contain unpublished original work and not be under consideration for publication by any other journal or in another book. Duplicate publications are never acceptable. For the rights of authors to re-use their own work, and deposit pre-publication versions, see also our Author Rights Policy  Fragmentation of research papers is not acceptable. Publications should be organized so that each paper gives a complete account of a particular aspect of the research.  Authorship should be limited to those who have made a significant contribution to the concept, design, execution, or interpretation of the research study. All those who have made significant contributions should be offered the opportunity to be listed as authors. Other individuals who have contributed to the study should be acknowledged, but not identified as authors.  (Addition 22 March 2023) All authors are accountable for the originality, validity, and integrity of the paper; for this reason, no Artificial Intelligence qualifies as author. See also the section on ‘Artificial Intelligence’.  The corresponding author, who submits the paper for publication, should ensure that all appropriate co-authors and no inappropriate co-authors are included on the paper, and that all co-authors have seen the final version of the paper and have agreed to its submission for publication.  All (co-)authors have an obligation to provide prompt retractions or correction of errors in published works. Any individual unwilling or unable to accept appropriate responsibility for a paper should not be a co-author.  Authors should list their affiliation(s), limited to those institutions with which the author has or had a formal relationship at the time of the research and/or the preparation of the publication.  Artificial Intelligence (Addition 22 March 2023) Artificial Intelligence (AI) does not qualify for the role of author (see above) and should not be listed as such. If AI was used in the research or preparation of the paper, this should be declared and explained in the description of the tools or methods used. Any requirements concerning copyright and plagiarism continue to apply.
174. Authorship is limited to those who have made a significant contribution to the design and execution of the work described. Any contributors whose participation does not meet the criteria for authorship should be acknowledged but not listed as an author.  The Journal does not allow ghost authorship, where an unnamed author prepares the article with no credit, or guest/gift authorship, where an author who made little or no contribution is listed as an author. The Journal follows Committee on Publication Ethics (COPE) guidance on investigating and resolving these cases. For more information, please see the OUP Publication Ethics page.  Natural language processing tools driven by artificial intelligence (AI) do not qualify as authors, and the Journal will screen for them in author lists. The use of AI (for example, to help generate content or images, write code, process data, or for translation) should be disclosed both in cover letters to editors and in the Methods or Acknowledgements section of manuscripts. Please see the COPE position statement on Authorship and AI for more details.
175. AI-assisted technologies [such as large language models (LLMs), chatbots, and image creators] do not meet Journal of Remote Sensing's criteria for authorship and therefore may not be listed as authors or coauthors, nor may sources cited in Journal of Remote Sensing journal content be authored or coauthored by AI tools. Authors who use AI-assisted technologies as components of their research study or as aids in the writing or presentation of the manuscript should note this in the cover letter and in the acknowledgments section of the manuscript. Detailed information should be provided in the methods section: The full prompt used in the production of the work, as well as the AI tool and its version, should be disclosed. Authors are accountable for the accuracy of the work and for ensuring that there is no plagiarism. They must also ensure that all sources are appropriately cited and should carefully review the work to guard against bias that may be introduced by AI. Editors may decline to move forward with manuscripts if AI is used inappropriately. Reviewers may not use AI technology in generating or writing their reviews because this could breach the confidentiality of the manuscript.  AI-generated images and other multimedia are not permitted without explicit permission from the editors. Exceptions may be granted in certain situations—e.g., for images and/or videos in manuscripts specifically about AI and/or machine learning. Such exceptions will be evaluated on a case-by-case basis and should be disclosed at the time of submission. Journal of Remote Sensing recognizes that this area is rapidly developing, and the position on AI-generated multimedia may change with the evolution of copyright law and industry standards on ethical use.
176. When submissions make use of previously reported data, such as public use data files from a federal survey, the source of the data should be clearly documented, and the paper should state how the complete data set can be obtained. Manuscripts based on well-documented surveys done earlier (such as public use data sets) should include a citation to documentation covering (1) a definition of the population; (2) the response rate and details of its calculation; (3) dates the survey was conducted; and (4) the exact wording of all questions used in the analysis.  Unless there are conditions of security or confidentiality, the data on which the paper must be available to reviewers as a requirement for publication. Artificial data sets created for simulations and relatively small data sets would generally be included as online-only supplementary material.  Papers reporting results based on computation should provide enough information so that readers can evaluate the quality of the results, especially their estimated accuracy.
177. Artificial Intelligence Authoring Tools and Authorship Policy  The Journal of Trauma and Acute Care Surgery does not accept using generative artificial intelligence (AI) and AI-assisted technologies to collect, analyze, or interpret data reported in a manuscript. Such tools may be used for editing purposes, to improve readability only, and the authors must explicitly declare their use (see below).  The journal follows guidelines from COPE and ICMJE regarding AI authoring tools and requirements and responsibilities of authorship. AI tools should not be listed as an author. Authors are ultimately responsible and accountable for the contents of the work, and AI tools cannot take responsibility and do not bear accountability for submitted works.   Authors who use AI tools must be fully transparent in their use in the writing of a manuscript. Authors must disclose the use of AI tools in the Materials and Methods (or similar section) of the paper as to 1) how the AI tool was used and 2) which AI tool was used.  Authors are responsible for all content in their manuscript, including content generated by AI tools, and are therefore liable for any breach of publication ethics.
178. Generative AI should only be used to improve language and readability; it cannot be listed as an author or cited as a source. If generative AI is used, you must include the following statement before the references:  Declaration of generative AI and AI-assisted technologies in the writing process  During the preparation of this work the author(s) used [NAME TOOL / SERVICE] in order to [REASON]. After using this tool/service, the author(s) reviewed and edited the content as needed and take(s) full responsibility for the content of the publication.
179. This policy is being introduced in response to the increasing prevalence and use of generative artificial intelligence in primary and secondary research and academic writing. We expect to update this policy as generative AI technologies advance and our community norms around use of such technologies shape up.  JAERE views generative AI as a tool, when used effectively and appropriately, that is available to researchers to improve productivity and streamline the research process. JAERE does not restrict the use of such tools to any aspect of the research process including drafting survey protocols, generating code for data analysis or streamlining writing. Authors of papers are responsible for all content in their papers. That means the authors are solely responsible for coding errors, incorrect facts or plagiarized text arising from the use of generative AI.  While it is not appropriate to cite generative AI or include such bots as co-authors, authors may include an optional disclosure statement if they want to.
180. ETHICS AND AUTHORSHIP IN THE USE OF GENERATIVE ARTIFICIAL INTELLIGENCE (AI) • Authorship assignment to AI is prohibited. • Authors who employ generative AI tools are solely responsible for all content produced and submitted. • Korean Journal of Radiology discourages the use of generative AI tools for the purpose of creating any types of content for scientific manuscripts. If such tools are used, the authors must report their use transparently. • The use of AI tools to enhance the linguistic quality of a submission is considered acceptable and does not require specific disclosure. • When generative AI itself is the focus of a study, the use of AI should be explicitly detailed in the Materials and Methods section. • Reviewers are forbidden from using AI for the purpose of generating review comments. Please refer to https://doi.org/10.3348/kjr.2023.0643 for further details.
181. AUTHORS Authorship ASN journals have adopted the criteria recommended by the International Committee of Medical Journal Editors (ICMJE) in the current update of the Uniform Requirements for Manuscripts Submitted to Biomedical Journals. Authorship credit should be based on (1) substantial contributions to conception and design, or acquisition of data, or analysis and interpretation of data; (2) drafting the article or revising it critically for important intellectual content; (3) final approval of the version to be published; and (4) agreement to be accountable for all aspects of the work pre- and post-publication. The full text of the Uniform Requirements for Manuscripts Submitted to Biomedical Journals is available at https://www.icmje.org/. Based on the ICMJE criteria for authorship, artificial intelligence (AI) tools, such as ChatGPT, do not qualify for authorship. ASN journals have adopted the JAMA Network policy on AI tools, which states, “Nonhuman artificial intelligence, language models, machine learning, or similar technologies do not qualify for authorship.” Additionally, and in accordance with the JAMA Network policy, if AI tools, such as ChatGPT “are used to create content or assist with writing or manuscript preparation, authors must take responsibility for the integrity of the content generated by these tools. Authors should report the use of artificial intelligence, language models, machine learning, or similar technologies to create content or assist with writing or editing of manuscripts in the Acknowledgement section or the Methods section if this is part of formal research design or methods. This should include a description of the content that was created or edited and the name of the language model or tool, version and extension numbers, and manufacturer.” If authors upload an accepted or published manuscript or any part of it into an AI tool, it may violate the copyright agreement or licensing terms in effect at the time of acceptance. Figures ASN journals follow the JAMA Network guidance that “The submission and publication of images created by artificial intelligence, machine learning tools, or similar technologies is discouraged, unless part of formal research design or methods, and is not permitted without clear description of the content that was created and the name of the model or tool, version and extension numbers, and manufacturer. Authors must take responsibility for the integrity of the content generated by these models and tools.” Authors are required to answer questions during the submission process about the use of AI. EDITORS AND REVIEWERS Editors and reviewers should not upload a submitted manuscript or any part of it into large language models (LLM)/artificial intelligence (AI) tools, such as ChatGPT. This action by an editor or reviewer may violate the authors’ confidentiality and proprietary rights and, where the paper contains personally identifiable information, may breach data privacy rights. This confidentiality requirement extends to all communication about the manuscript, including any notification or decision letters, as they may contain confidential information about the manuscript and/or the authors. With the exception of basic grammar, spelling, and reference checking tools, submission of a manuscript into an LLM and submission of reviewer comments by reviewers is prohibited by ASN. Ethics Editors should not use AI to evaluate potential author misconduct and research integrity concerns.
182. Authorship should be limited to those who have made significant contributions to the concept, design, execution or interpretation of the work reported in a manuscript; others who have contributed should be acknowledged. Nonhuman artificial intelligence, language models, machine learning, or similar technologies do not qualify for authorship because they cannot take responsibility for the submitted work. AI tools cannot be listed as an author of a paper. Authors who use AI tools in the writing of a manuscript, production of images or graphical elements of the paper, or in the collection and analysis of data, must disclose in the Methods or Acknowledgements how the AI tool was used and which tool was used. Author order should be agreed on by all authors as should any changes in authors and order that occur while the manuscript is under review or revision. Changes in authorship must be submitted to the editorial office and must be approved by all authors involved. Changes to authorship are not permitted after acceptance of a manuscript. Authors and co-authors should review and ensure the accuracy and validity of results prior to submission; co-authors should have the opportunity to review the manuscript before submission.
183. Artificial Intelligence Authoring Tools and Authorship Policy  The advent of Artificial Intelligence (AI) authoring tools (eg, ChatGPT, GPT-3) presents academic scholarship with unique challenges. In recent weeks, several stories concerning the attribution of authorship to AI- authoring tools have circulated (1).  In concordance with the recommendations of other publishers, it is our position that an AI authoring tool does not meet the standards required for authorship as defined by the ICMJE (2). Specifically, the ICMJE recommendations require that every author be “…accountable for all aspects of the work in ensuring that questions related to the accuracy or integrity of any part of the work are appropriately investigated and resolved.” We do not believe that AI Authoring tools meet this standard.  In agreement with the position of the Committee on Publication Ethics (3), we endorse the following recommendation, and suggest that Instructions for Authors be updated accordingly:  Authors who use AI tools in the writing of a manuscript, production of images or graphical elements of the paper, or in the collection and analysis of data, must be transparent in disclosing in the Materials and Methods (or similar section) of the paper how the AI tool was used and which tool was used. Authors are fully responsible for the content of their manuscript, even those parts produced by an AI tool, and are thus liable for any breach of publication ethics.  References
184. CDC sometimes uses GenAI (generative artificial intelligence) to help create content for the public. This may include content for the web, social media, fact sheets, and graphics. In every case, our experts review our communication materials in an effort to ensure accuracy and quality before use. CDC public health research, data, and recommendations are based on the best science currently available and go through a separate agency review process prior to release.
185. Transparency in Using LLMs Cogitatio Press recognizes the potential of LLMs like ChatGPT to assist authors in writing their manuscripts. However, to ensure responsible use and maintain the integrity of our publications, any use of LLMs during the research or writing process must be clearly disclosed.  Disclosure Options Methods Section: Briefly describe the specific LLM used and how it contributed to your work (e.g., for grammar and style improvement, literature review assistance, or brainstorming initial ideas for the structure). Acknowledgments Section: Acknowledge the specific LLM tool used and its contribution (if applicable). Important Considerations LLM outputs require human verification and critical analysis. You, the author, remain responsible for the accuracy, originality, and validity of your work. Be mindful of potential bias and factual inaccuracies in LLM-generated content. AI co-authorship is not currently accepted. Following these guidelines ensures transparency and ethical use of LLMs in your research and writing.  Additional Resources Committee on Publication Ethics (COPE): https://publicationethics.org/cope-position-statements/ai-author  Please note: This policy may evolve as the use of LLMs continues to develop.
186. Artificial intelligence (AI) policy The policy applies to generative AI tools such as Large Language Models. Please note that not all AI tools are generative. The use of non-generative machine learning tools to manipulate, combine or enhance existing images or figures should be disclosed in the relevant caption upon submission to allow a case-by-case review. This policy does not apply to AI and AI-assisted tools used to check for spelling, improve readability and language of the work, or as reference managers.  As we expect rapid development in this field, we will regularly review this policy and update it if necessary.  Use of generative AI by authors Authors cannot list generative AI tools such as Large Language Models as co-authors or cite them as such as these tools do not satisfy authorship criteria, do not meet accountability and consent requirements and are unable to manage legal obligation and issues relating to conflict of interest. Use of these tools must be disclosed in the manuscript or in the acknowledgement section of the article, as relevant. Authors should provide details on which elements of the work were generated by AI and AI-assisted technologies. Editors and reviewers will consider whether such use is appropriate.  Use of AI-generated images and videos is not permitted with the exception of those that are directly referenced in an article that is specifically about AI. Such images and videos will be reviewed and considered on a case-by-case basis.  Authors are responsible and accountable for all the content within their article, including any parts produced by an AI tool, and they must not replace key researcher tasks such as producing scientific insights, interpreting data or drawing scientific conclusions.  Use of generative AI by reviewers Peer reviewers are carefully selected and invited by our editors based on their expertise and must be accountable for accuracy of their comments and recommendations. AI large language models, and more generally generative AI tools, have substantial limitations and may produce biased and false information.  Peer reviewers must not upload any element of a manuscript into generative AI tools. AI large language models must not be used to generate peer review reports or to assist with any part of the peer review process.  Back to top
187. At Mindful.org, we recognize the transformative power of Artificial Intelligence (AI) in enhancing various facets of our operations. As we integrate AI technologies into our workflows, we remain steadfast in our commitment to ethical standards, integrity, and the well-being of our audience.   In a landscape increasingly dominated by organizations relying heavily on AI, often causing genuine voices to be overshadowed, we are dedicated to ensuring that our content stands out by helping people find the stories and information they’re seeking. This policy outlines our approach to utilizing AI responsibly, emphasizing transparency, human oversight, and ethical considerations, particularly in how it relates to our journalism and content creation.  1. Scope of AI Utilization While we embrace AI to develop administrative and marketing content, enhancing efficiency and engagement, we uphold a distinct boundary concerning our journalistic integrity. Specifically, we do not use AI in writing articles or scripts for our magazine, podcast, or social media platforms. This decision reflects our commitment to authenticity, creativity, and the human touch that defines our content.   All instances of AI-assisted content creation present on Mindful.org are derived from a database exclusively consisting of existing Mindful articles and media and will always include a link to the original content on the page.  2. Transparency and Disclosure We are committed to transparency about our use of AI. A clear disclosure will appear on any Mindful.org page that includes AI-generated content, ensuring our audience can distinguish between human and AI contributions. These disclosures will be straightforward, accessible, and prominently placed.  3. Human Oversight Human oversight is a cornerstone of our AI strategy. All AI-generated content will be reviewed and approved by our team to ensure they align with our ethical, journalistic, and quality standards. This ensures that AI assists with, rather than replaces, the work of writers and editors.  4. Accuracy, Reliability, and Ethical Use We pledge to ensure the accuracy and reliability of all content, with AI-generated materials undergoing rigorous fact-checking, anti-plagiarism, and proofreading processes. We will avoid irresponsible applications of AI that could mislead, harm, or discriminate. This extends to a cautious approach to sensitive topics, emphasizing inclusivity, respect, and understanding.  5. Privacy and Data Protection Adhering to our privacy policy, we will manage all data used in AI systems with the utmost care, following relevant data protection laws. This includes a strict stance on the misuse or compromise of personal data through our AI applications.  6. Continuous Learning and Improvement Mindful.org commits to continuous learning and adaptation of our AI policies and practices, staying abreast of technological, ethical, and regulatory developments in the AI landscape.  7. Stakeholder Engagement We value stakeholder input in shaping our approach to AI. Engaging in open dialogue with readers, journalists, and partners, we aim to reflect diverse perspectives in our AI applications.  Mindful.org is dedicated to leveraging AI’s potential responsibly, enhancing our administrative and marketing efforts while preserving the human-driven creativity and authenticity in our journalism and content creation. This policy will be periodically reviewed and updated to remain aligned with our values and the evolving AI landscape.
188. NEW  Policy on the use of generative AI  Firstly, upon their submission, authors are requested (1) to declare that they did not utilize generative artifical intelligence (AI) tools in the composition of their manuscript, or, if any part of this work did involve the use of such tools, the authors are required (2) to clearly specify the nature of the AI's involvement. The latter includes detailing the purpose(s) of using generative AI and naming the specific AI tool(s) used as well as highlighting directly in the manuscript any content that was AI-generated.  Secondly, to facilitate the process of evaluating manuscripts upon resubmission, authors are requested to refrain from replacing entire paragraphs using "change-tracking" mode of the text-processing program. Instead, all modifications should be made as in-line changes using "change-tracking". This approach ensures that each alteration is clearly visible and directly comparable with the original text.
189. Neurology® adheres to the position of the Committee on Publication Ethics regarding authorship and AI tools. The policy states: “Authors who use AI tools in the writing of a manuscript, production of images or graphical elements of the paper, or in the collection and analysis of data, must be transparent in disclosing in the Materials and Methods (or similar section) of the paper how the AI tool was used and which tool was used. Authors are fully responsible for the content of their manuscript, even those parts produced by an AI tool, and are thus liable for any breach of publication ethics. In addition, authors should not upload an accepted or published manuscript or any part of it into a generative AI tool as this may violate the copyright agreement or licensing terms in effect at the time of acceptance.”
190. The Journal has adopted the following policies, as specified by the International Committee of Medical Journal Editors (ICMJE), on the use of artificial intelligence (AI) in preparation of material to be submitted for publication in the Journal.  Authors must disclose at submission of the manuscript whether AI-assisted technologies (such as large language models, chatbots, or image creators) were used to produce the submitted work. If so, both the cover letter and the submitted work should include a description of the technologies used and what was produced. Because the authors of a manuscript are responsible for the accuracy, integrity, and originality of the work, chatbots or other AI-assisted technologies cannot be listed as authors. Authors should carefully review and edit all materials produced through the use of AI, to prevent the submission of authoritative-sounding output that is incorrect, incomplete, or biased. Authors should be able to assert that there is no plagiarism of text or images in materials produced by AI. Authors must ensure that all quoted material is properly attributed, including full citations. Citation of AI-generated material as a primary source is not acceptable.
191. Authors using a Large Language Models (LLM) (e.g., ChatGPT) in the capacity of an editing tool may need to acknowledge the use in this capacity. When/if an LLM is used to incorporate text, data, or any other content in the manuscript, these sections need to be acknowledged in an appropriate section of the manuscript. Authors are responsible for checking all content incorporated into their manuscript from LLM to ensure that the use of such content does not require citation back to another original source. 
192. Authors must be transparent about the use of Artificial Intelligence tools such as ChatGPT and other large language models in the manuscript preparation, and disclose details of how the AI tool was used within the "Materials and Methods" section
193.  Artificial intelligence guideline The emergence of artificial intelligence (AI), exemplified by Chat GPT’s announcement in 2022, has brought about significant transformations in the academic landscape. AI has proven its capacity to perform tasks at an exceptionally high level in scholarly paper writing, challenging the traditional belief that academic writing is solely within the realm of human intellectual abilities. This shift is positive as it brings us closer to uncovering truths that may have been overlooked. It is also helpful to enhance the overall readability of academic papers and overcome the language barrier. However, it is crucial to acknowledge that AI still grapples with unresolved issues, with hallucination being a prominent concern. The reliability of AI is not yet definitive. Copyright-related concerns arising from creative processes facilitated by AI necessitate societal consensus. It is imperative to evaluate this technology not solely for its convenience but also considering its broader implications. We highly respect the creative process of researchers and acknowledge its intrinsic value. Therefore, the editorial board of Neurospine earnestly requests authors to adhere to the following guidelines when submitting papers to the journal: 1) Artificial intelligence tools cannot be listed or cited as one of the authors due to its inability to take responsibility for errors. 2) Authors should exert every effort to ensure the reliability of their papers when utilizing artificial intelligence, holding responsibility for any plagiarism or false information generated using AI. 3) Authors must provide detailed information, including prompts, AI tools used, and their versions, in the Materials and Methods or Acknowledgment section when employing AI tools. 4) Images or videos created using AI, without societal consensus on copyright, cannot be included in papers at the moment. 5) Reviewers are cautioned against sharing the manuscript outside during the peer-review process. Even simple uploading papers to external AI tools can break confidentiality. 6) The editor may refuse to proceed with review of the paper if inappropriate use of AI is detected. We recognize that technology’s rapid evolution continually shapes the academic writing process, and the points mentioned above may evolve based on future societal agreements. All correspondences, business communications and manuscripts should be mailed to:
194. Use of Generative AI and AI-assisted Technologies Text: The JNSPG does not accept any AI tool as a credited author on a research paper. AI tools to analyze and draw insights from data as part of the research process are acceptable and must be declared in the Methods or Acknowledgments section of the paper, as appropriate. In the writing process, generative AI and AI-assisted technologies should only be used to improve readability and language of the work. Authors should carefully review and edit the result to ensure accuracy and validity of language, references, and data. The authors are ultimately responsible and accountable for the content of the work.  Authors must disclose in their manuscript the use of AI and AI-assisted technologies, and a statement will appear in the published work. Declaring the use of these technologies supports transparency and trust while facilitating compliance with the terms of use of the relevant tool or technology.  Figures: The JNSPG does not permit the use of AI tools to create or manipulate an image or figure included as part of a submitted manuscript; that is, we do not accept the use of such AI technology to enhance, obscure, move, remove, or introduce any specific features in an image, although adjusting color, contrast, or brightness is acceptable if it does not mask or subtract any details in the original figure or image. The JNSPG may use available forensic tools or software to investigate any suspected creation or alteration of an original image.  We acknowledge that AI or AI-assisted tools may be used as part of a research design or methods (e.g., biomedical imaging studies), and this is acceptable if the authors provide explicit details on such use in the Methods section of the paper, including the name of the program or tool, the version and extension numbers, the manufacturer, and a description of how the technology was used in the image creation or alteration. It is the authors’ responsibility to follow the AI software’s usage policies and attribution requirements. The JNSPG may require authors to submit the composite raw images used to generate the final submitted versions (i.e., pre–AI-adjusted versions of images).
195. Artificial Intelligence (AI) Authoring Tools The journal does not consider Artificial Intelligence authoring tools to meet the requirements for Authorship as recommended by the ICMJE. Authors who use AI tools in the writing of a manuscript, production of images or graphical elements of the paper, or in the collection and analysis of data, must be transparent in disclosing in the Acknowledgements section of the paper how the AI tool was used, and which tool was used. Authors are fully responsible for the content of their manuscript, even those parts produced by an AI tool, and are thus liable for any breach of publication ethics. Additionally, Figures and Tables that are generated with AI should be clearly identified in their respective legends.
196. AUTHORSHIP AND AI TOOLS. As a result of the increased popularity of using artificial intelligence (AI) tools such as ChatGPT or Large Language Models (LLMs) in research publications, the Oceanography Editorial Board, and the TOS Council, endorse the Committee on Publication Ethics (COPE) position statement on authorship and AI tools, which states that “AI tools cannot be listed as an author of a paper.”  The position further states:  AI tools cannot meet the requirements for authorship as they cannot take responsibility for the submitted work. As non-legal entities, they cannot assert the presence or absence of conflicts of interest nor manage copyright and license agreements.  Authors who use AI tools in the writing of a manuscript, production of images or graphical elements of the paper, or in the collection and analysis of data must be transparent in disclosing in the Materials and Methods (or similar section) of the paper how the AI tool was used, and which tool was used. Authors are fully responsible for the content of their manuscript, even those parts produced by an AI tool, and are thus liable for any breach of publication ethics.
197. The use of artificial intelligence (AI) and machine learning is rapidly changing society in fast-moving and unpredictable ways. The practice of ophthalmology, and ophthalmic research, are as affected by these changes as any other segment of society.   The Academy understands and supports efforts to conduct cutting-edge research in the field of ophthalmology, including novel applications of AI such as generative AI and large language models.   As a leading source of ophthalmic knowledge, the Academy creates publications such as the Basic and Clinical Science Course (BCSC®), the Ophthalmology family of journals, EyeNet, the Preferred Practice Pattern® guidelines, Ophthalmic Technology Assessments and other online and print resources that provide an unparalleled source of information for training AI systems such as large language models.    These and other publications are protected by both U.S. and international copyright laws, as well as contractual provisions such as the Academy’s Terms of Service. Without first seeking permission to use these copyrighted materials, individuals and organizations may infringe the Academy’s rights.    In addition to intellectual property issues, AI can present concerns regarding data privacy, the accuracy of content online (including liability for erroneous information), patient safety, and discrimination. The Academy believes it is imperative to proceed carefully in this area to both protect its valuable intellectual property as well as the interests of its membership.   To balance these concerns and obligations with the research opportunities presented by AI, the Academy has, pursuant to express written agreements, permitted researchers applying AI technologies to use Academy materials. While the Academy reviews every request on its own terms, the Academy reserves its rights to decide in its sole discretion whether or not to permit use of Academy materials.    Generally speaking, researchers must be able to clearly delimit the intended scope of use of Academy materials, acknowledge the permission granted by the Academy, and provide reasonable assurances that the inputs for the research will not be retained by the AI system at issue, because the material is copyrighted and protected by law.     If you are interested in pursuing ophthalmic research using AI and Academy-owned materials, direct your request for permission to permissions@aao.org.   Separately, the Academy describes expectations regarding use of AI in articles submitted for consideration in the Ophthalmology family of journals and in EyeNet Magazine. 
198. Wiley’s guidance on artificial intelligence generated content (such as ChatGPT) is available here. If an author has used Artificial intelligence generated content (AIGC) tools — such as ChatGPT and others based on large language models (LLMs) — to develop any portion of their manuscript, its use must be described, transparently and in detail, in the Methods or Acknowledgements section.  
199. Content Generated by Artificial Intelligence  Nonhuman artificial intelligence (AI), language models, machine learning, or similar technologies cannot be considered capable of initiating an original piece of research without direction by human authors. They also cannot be accountable for a published work or for research design, which is a generally held requirement of authorship, nor do they have legal standing or the ability to hold or assign copyright. Therefore—in accordance with COPE’s position statement on AI tools—these tools do not qualify for authorship and cannot be listed as an author of an article.  If an author has used this kind of AI tool to develop any portion of a manuscript, its use must be described, transparently and in detail, in the Acknowledgements section or Methods section (if part of formal research design or methods). Authors are fully responsible for the accuracy of any information provided by the tool and for correctly referencing any supporting work on which that information depends. Tools that are used to improve spelling, grammar, and general editing are not included in the scope of these guidelines.  The final decision about whether use of an AI tool is appropriate or permissible in the circumstances of a submitted manuscript or a published article lies with the journal’s editor or other party responsible for the publication’s editorial policy.
200. Declaration of generative AI in scientific writing Where authors use generative artificial intelligence (AI) and AI-assisted technologies in the writing process, authors should only use these technologies to improve readability and language. Applying the technology should be done with human oversight and control, and authors should carefully review and edit the result, as AI can generate authoritative-sounding output that can be incorrect, incomplete or biased. AI and AI-assisted technologies should not be listed as an author or co-author, or be cited as an author. Authorship implies responsibilities and tasks that can only be attributed to and performed by humans, as outlined in Elsevier’s AI policy for authors.  The American Academy of Ophthalmology requires that authors request and obtain permission to use any Academy content (including, but not limited to, anything published in the Ophthalmology family of journals) prior to inputting into, or using with, AI systems such as large language models. Not only are these materials protected by U.S and international copyright laws and the Academy’s own contractual provisions, AI can present concerns regarding data privacy, the accuracy of content online (including liability for erroneous information), patient safety, and discrimination. For additional information and instructions on how to request permission, please see the full statement on artificial intelligence and the use of Academy materials[https://www.aao.org/statement-on-artificial-intelligence].  Authors should disclose in their manuscript the use of AI and AI-assisted technologies in the writing process by following the instructions below. A statement will appear in the published work. Please note that authors are ultimately responsible and accountable for the contents of the work. Prior to inputting any copyrighted material into an AI system, authors should first obtain permission from the copyright holder.  Disclosure instructions  Authors must disclose the use of generative AI and AI-assisted technologies in the writing process by adding a statement at the end of their manuscript in the core manuscript file, before the References list. The statement should be placed in a new section entitled ‘Declaration of Generative AI and AI-assisted technologies in the writing process’.  Statement: During the preparation of this work the author(s) used [NAME TOOL / SERVICE] in order to [REASON]. After using this tool/service, the author(s) reviewed and edited the content as needed and take(s) full responsibility for the content of the publication.  This declaration does not apply to the use of basic tools for checking grammar, spelling, references etc. If there is nothing to disclose, there is no need to add a statement.
201. Generative artificial intelligence (AI) systems such as ChatGPT and Large Language Models are valuable tools for scientific research. However, AOS journal policy, consistent with COPE guidelines, is that generative AI systems are non-legal entities that cannot be listed as authors of a paper. Authors are fully responsible for the content of their manuscript, even those parts produced by an AI tool, and are thus accountable for any inaccuracy or breach of publication ethics. Please note the artificial intelligence landscape is evolving quickly. The journal reserves the right to change this policy based on new conditions and accepted practices as they develop.  The use of generative AI tools in studies submitted for publication must be disclosed (1) in the cover letter and (2) in the paper as follows: Describe in Methods how and which AI tools assisted with data collection and the production of graphics. Report after Acknowledgements if generative AI was used in writing the manuscript, including language translation tools and compilation of references. Label this section ‘Declaration of generative AI in the writing process’ and follow this format:  The author(s) used [name AI tool(s) / service(s) and provide URL(s)] to [provide details]. The author(s) reviewed and edited the generated material as needed and accept(s) full responsibility for the content of the publication.  A disclosure is not required for the use of word processing software for checking grammar and spelling, for literature searches via online search engines (e.g., Google Scholar, Web of Science), or for the use of AI tools to generate computer code for data analysis.
202. For submissions employing machine learning (ML) or artificial intelligence (AI) methods, we recognize that the community has not reached consensus on appropriate reporting requirements. We emphasize, however, that as a biomedical journal it is our mission is to publish research that furthers the understanding of the biology and clinical care of osteoarthritis. As such, it is imperative that any prediction model be sufficiently open and accessible to permit external validation, and we encourage authors to provide applicable data sets or executable code for review.  For authors' convenience, we endorse the CLAIM checklist, https://pubs.rsna.org/doi/full/10.1148/ryai.2020200029. However, until such a consensus has been reached, we will accept adherence to any of the published guidelines proposed by mainstream organizations, such as the RSNA (Bluemke DA et al., https://doi.org/10.1148/radiol.2019192515), theNeurIPS Reproducibility Program (https://arxiv.org/pdf/2003.12206.pdf), or the TRIPOD StatementThe below guidance only refers to the writing process, and not to the use of AI tools to analyse and draw insights from data as part of the research process.  Where authors use generative artificial intelligence (AI) and AI-assisted technologies in the writing process, authors should only use these technologies to improve readability and language. Applying the technology should be done with human oversight and control, and authors should carefully review and edit the result, as AI can generate authoritative-sounding output that can be incorrect, incomplete or biased. AI and AI-assisted technologies should not be listed as an author or co-author, or be cited as an author. Authorship implies responsibilities and tasks that can only be attributed to and performed by humans, as outlined in Elsevier's AI policy for authors.  Authors should disclose in their manuscript the use of AI and AI-assisted technologies in the writing process by following the instructions below. A statement will appear in the published work. Please note that authors are ultimately responsible and accountable for the contents of the work.
203. Any use of generative AI (such as ChatGPT) in the creation of a manuscript must be clearly disclosed by the authors in the Acknowledgements section. Please note that, per section 2.3 of this document, authors are responsible for ensuring the accuracy and appropriate attribution (i.e., citation) of all content contained within the manuscript. Authors are advised to make doubly sure that this provision is upheld in cases of content written with the assistance of generative AI.  
204. 08. Artificial Intelligence (AI) and AI-assisted technologies policy  Where authors use AI and AI-assisted technologies in the writing process, these technologies should only be used to improve readability and language of the manuscript and not to replace key writing tasks. The application of the technology should be carried out with human supervision and control and all work should be carefully reviewed and edited.  Authors should disclose the use of AI and AI-assisted technologies in their manuscript and a statement will appear in the published article.   Authors should not list AI and AI-assisted technologies as an author or co-author, or cite AI as an author.   09. The use of generative AI and AI-assisted tools in figures, images and artwork  Pacini Editore does not allow the use of generative AI or AI-assisted tools to create or alter images in submitted manuscripts. This can include enhancing, darkening, moving, removing, or introducing a specific feature within an image or figure.   The only exception is if the use of AI or AI-assisted tools was part of the research design or methods. In this case, such use must be described in a reproducible way in the methods section, and also include an explanation of how they were used.  The use of generative AI or AI-assisted tools in the production of graphical abstracts is not permitted.
205. ETHICAL/LEGAL CONSIDERATIONS  New Policy, effective for all articles submitted on or after March 22, 2022  Articles that have received funding by major pharmaceutical companies, except Letters to the Editor, will be required to pay the following publication charges. The universal fee for all accepted manuscripts with major pharma funding is: $1500.00 US flat fee. Once published, these articles will be available online by free access. This fee is a journal requirement, if the paper is funded, and is a separate process and fee to the Open Access feature, which involves copyright licenses. Please see below for further information about the Open Access procedure and fees. Please inquire with your sponsor if they require a copyright license.  The advent of Artificial Intelligence (AI) authoring tools (eg, ChatGPT, GPT-3) presents academic scholarship with unique challenges. In recent weeks, several stories concerning the attribution of authorship to AI- authoring tools have circulated (1).  In concordance with the recommendations of other publishers, it is our position that an AI authoring tool does not meet the standards required for authorship as defined by the ICMJE (2). Specifically, the ICMJE recommendations require that every author be “…accountable for all aspects of the work in ensuring that questions related to the accuracy or integrity of any part of the work are appropriately investigated and resolved.” We do not believe that AI Authoring tools meet this standard.   In agreement with the position of the Committee on Publication Ethics (3), we endorse the following recommendation, and suggest that Instructions for Authors be updated accordingly:   Authors who use AI tools in the writing of a manuscript, production of images or graphical elements of the paper, or in the collection and analysis of data, must be transparent in disclosing in the Materials and Methods (or similar section) of the paper how the AI tool was used and which tool was used. Authors are fully responsible for the content of their manuscript, even those parts produced by an AI tool, and are thus liable for any breach of publication ethics.  In addition, authors should not upload an accepted or published manuscript or any part of it into a generative AI tool as this may violate the copyright agreement or licensing terms in effect at the time of acceptance.
206. Skip Nav Destination Pediatrics is the official peer-reviewed journal of the American Academy of Pediatrics. Pediatrics publishes original research, clinical observations, and special feature articles in the field of pediatrics, as broadly defined. Contributions pertinent to pediatrics also include related fields such as nutrition, surgery, dentistry, public health, child health services, human genetics, basic sciences, psychology, psychiatry, education, sociology, and nursing.  Pediatrics considers unsolicited manuscripts in the following categories: reports of original research, particularly clinical research; review articles; special articles; and case reports. When preparing a manuscript for Pediatrics, authors must first determine the manuscript type and then prepare the manuscript according to the specific instructions below.  The digital edition of Pediatrics is the journal of record. Some accepted article types may also be presented in full in print, in addition to the digital edition of Pediatrics.  Introduction  Manuscript Preparation  Manuscript Submission  Article Types  Additional Guidelines  Acceptance Criteria Publication Ethics Artificial Intelligence Use of Race and/or Ethnicity Use of Sex and/or Gender Use of Inclusive Language Reporting Partnership With Patient and Families in Research Journal Style Clinical Trials Reuse of Data Sets Data Sharing Open Access Formatting Requirements   Double-Blind Peer Review Manuscript Formatting Title Page Contributors Statement Page Word Count Figures, Tables & Supplementary Material Cover Letter Getting Started Submitting Your Manuscript Regular Article Research Briefs Advocacy Case Studies Case Report Commentary Diagnostic Dilemmas and Clinical Reasoning Diversity, Equity, Inclusion, and Justice Ethics Rounds Family Partnerships Features SOPT History Global Health COMSEP Health Policy Article Pediatrics Perspectives Quality Report Review Article, Systematic Review & Meta-Analyses Special Article State-of-the-Art Review Article "From the American Academy of Pediatrics" Reader Comments Letters to the Editor Errata Supplements to Pediatrics Pediatrics Editorial Offices    Acceptance Criteria Relevance to readers is of primary importance in manuscript selection. The readership includes general and specialist pediatricians, pediatric researchers and educators, and child health policy-makers. Pediatrics receives many more high-quality manuscripts than can be accommodated in our available space. The acceptance rate is approximately 10%. An article that is thought by the editors to not be relevant to readers, outside of scope, or very unlikely to be accepted may be rejected without review. All manuscripts considered for publication are peer reviewed, including those written by members of the Editorial Board. Peer reviewers are selected by the editors. Selection is based on their expertise in the topic of the manuscript. Generally, at least 2 reviews are required before a decision is rendered. Authors can suggest reviewers who they believe should not review the manuscript but should provide a clear rationale for this request.  Authors should carefully follow instructions for manuscript preparation and ensure that the manuscript is proofread before submission. Manuscripts that do not follow the author instructions will not be considered for review. Careless preparation of a manuscript raises concerns about the quality of the work and makes acceptance less likely. Manuscripts are electronically scanned for plagiarism. Authors will be contacted if there is concern about potential plagiarism. Pediatrics follows the recommendations of the Committee on Publication Ethics for concerns about plagiarism or any other manuscript-related ethical issue.  Manuscripts are judged on the importance, originality, scientific strength, clinical relevance, and clarity of content. Pediatrics does not publish manuscripts that focus only on animal research. Refer to the sections below on the particular considerations for each of the manuscript types that appear in the journal. Authors should also consider the comprehensive reporting guidelines for a wide variety of study designs and for the report of of sex and gender information that are available at http://www.equator-network.org/home/. These can be helpful in improving manuscript clarity and completeness. Note that authors submitting manuscripts describing adverse drug or medical device events or product problems should also report these to the appropriate governmental agency. Responses to a published article should be submitted as online comments. The editors will determine which comments will be published in the journal as Letters to the Editor.  After the reviews are received, the editors may take one of the following actions: Accept; Accept with Revisions; Reject with option to Resubmit; Reject, or Reject and Transfer (if authors opted to have their manuscript transferred to Hospital Pediatrics in not accepted by Pediatrics). A rejected manuscript may not be resubmitted. A manuscript may be rejected with an option to resubmit with extensive revision. The resubmitted manuscript receives an additional round of peer review (which may include new reviewers), and the manuscript may or may not be accepted. A decision of Accept with Revision indicates that the editors intend to accept the manuscript contingent on adequate response to reviewers. A decision of Accept, which is exceedingly rare on first submission, indicates that the manuscript is ready to place into production without further modification. Appeals on decisions will be considered by the editorial board on a case-by-case basis.  ↑ Back to Top ↑   Publication Ethics Authorship. An “author” is someone who has made substantive intellectual contributions to a published study. Each author is required to meet ALL FOUR of the following criteria:  Substantial contribution(s) to conception and design, acquisition of data, or analysis and interpretation of data; and Drafting the article or revising it critically for important intellectual content; and Final approval of the version to be published, and Agreement to be accountable for all aspects of the work in ensuring that questions related to the accuracy or integrity of any part of the work are appropriately investigated and resolved. NOTE: Acquisition of funding, collection of data, or general supervision of the research group alone does not constitute a sufficient basis for authorship.  All persons listed as authors must meet these criteria, and all persons who meet these criteria must be listed as authors. Articles submitted with an unexpectedly large number of authors invite scrutiny by editors and reviewers for clear justification for the presence of each person on the authorship list. Pediatrics permits a statement of equal contribution for two first authors and two senior authors. On the title page, include asterisks by each name and a statement that reads: * Contributed equally as co-first authors or *Contributed equally as co-senior authors.  Decide authorship issues, including the order, before submission. Pediatrics does not allow addition or removal of authors or changes to the author order after a manuscript is submitted without explicit approval from the editors.  If published, author names and affiliations will appear as seen in the submitted manuscript Word document and the final typeset proofs. All authors must ensure that their information is correct.   Conflict of Interest and Disclosure. After a paper is accepted by Pediatrics for publication, all authors must submit conflict of interest and disclosure forms. Pediatrics adheres to the policy and uses the standardized disclosure form of the International Committee of Medical Journal Editors (ICMJE). The collection of the forms is automated within the online system.  IRB Approval. All studies that involve human subjects must be approved or deemed exempt by an official institutional review board; this should be noted in the Methods section of the manuscript.  Industry Sponsorship. All industry sponsorship must be declared in the manuscript. Manuscripts in which all authors are employed by a commercial entity can raise additional scrutiny from the editorial board.   Registration of Clinical Trials. All clinical trials must be registered in a World Health Organization-approved Clinical Trial registry prior to enrollment of the first subject. The registry name and registration number should be included on the title page. Reports of unregistered trials will be returned to authors without review. Publication of the results of a trial that was initiated prior to the ICMJE requirement for trial registration will be considered by the editors on a case-by-case basis.  Suspected Errors and Allegations of Misconduct. Pediatrics follows the processes outlined in the Committee on Publication Ethics (COPE) flowcharts when investigating suspected errors and allegations of misconduct. Please be aware that all investigations are confidential. If an error has been found or misconduct has been identified, the journal will publicly acknowledge the outcome through an erratum or retraction, depending on the severity of the issue. Investigations that result in no error or misconduct being found will not be publicized.  Editorial Board Members as Authors. The journal allows editorial board members to submit articles for consideration. These articles undergo the same rigorous peer review as all other submissions. The manuscript management system automatically blinds a user with administrative access from viewing a manuscript for which they are an author, so author editorial board members cannot view the manuscript from the administrative side once it has been submitted.  Editor Conflict of Interest: Journal editors recuse themselves from manuscripts for which they have a conflict of interest.  ↑ Back to Top ↑   Artificial Intelligence Artificial intelligence (AI) tools do not qualify for authorship. To qualify, authors must meet all four of the following criteria1:  Substantial contribution(s) to conception and design, acquisition of data, or analysis and interpretation of data; and Drafting the article or revising it critically for important intellectual content; and Final approval of the version to be published, and Agreement to be accountable for all aspects of the work in ensuring that questions related to the accuracy or integrity of any part of the work are appropriately investigated and resolved. AI tools cannot take responsibility for the accuracy or integrity of a manuscript and, therefore, do not qualify for authorship.2   While the use of AI tools is discouraged, if generative AI tools are used in any part of manuscript preparation, from writing to data analysis to image creation, the authors must report it in the Methods and Acknowledgments sections3 and note use of an AI tool in the cover letter. Identification of AI must include the name and manufacturer of the AI tool and how it was used in relation to the work being submitted.2 Authors are accountable for the integrity and accuracy of all material in their manuscript, including any content generated by AI.3
207. Large Language Models, such as ChatGPT, are rapidly evolving, and the Physical Review journals continue to observe their uses in creating and modifying text. Authors and Referees may use AI-based writing tools exclusively to polish, condense, or otherwise lightly edit their writing. As always, authors must take full responsibility for the contents of their manuscripts; similarly, referees must take full responsibility for the contents of their reports. Additional guidelines can be found at Appropriate Use of AI-Based Writing Tools.
208. Artificial Intelligence Generated Content (AIGC) policy Background  Generative artificial intelligence (GAI) tools, such as ChatGPT or Gemini, utilise large language models to create textual or image-based responses to user prompts. The use of such tools in academia is proliferating, and we recognise this presents the potential for both benefit and harm to academic literature. The Journal of Physiology has introduced an AIGC policy for authors and reviewers. This policy may be updated as AI technologies develop further. Tools that are solely used to improve spelling and grammar are not included in the scope of this policy.    Policy for authors  The Journal requires authors to fully disclose the use of any GAI tools in the preparation of their manuscript, as per Wiley’s policy, and in accordance with the position statement set out by the Committee on Publication Ethics. Specifically, the term ‘manuscript preparation’ includes, but is not limited to, the writing of a manuscript, the production of images or graphical elements, or data collection and analysis. This disclosure should be placed in the Methods section, and must be transparent and detailed. Specifically, any such disclosure should include the name(s), model and version of AI technology used, and exact details on the purpose for and methods of its use. The Journal will assess whether the utilisation and disclosure of AI align with its publication policies and practices. Content may be rejected or subject to post-publication changes based on insufficient declaration or unsatisfactory circumstances of GAI tool usage.   GAI tools cannot be named as authors. Authors are responsible for both the accuracy of information provided by these tools, and for correctly referencing any supporting work on which that information depends.     Policy for reviewers  The Journal prohibits reviewers from using GAI tools, such as ChatGPT or Gemini. The use of these tools in this context necessarily entails the submission of material which is not in the public domain, and thereby constitutes infringement upon the intellectual property and confidentiality rights of submitting authors.
209. Use of Artificial Intelligence Natural language processing tools driven by artificial intelligence (AI) do not qualify as authors, and the Journal will screen for them in author lists. The use of AI (for example, to help generate content or images, write code, process data, or for translation) should be disclosed both in cover letters to editors and in the Methods or Acknowledgements section of manuscripts. Please see the COPE position statement on AI and authorship for more details.  New policy on Artificial Intelligence as of August 17, 2023
210. Artificial Intelligence Tools and Technologies PLOS expects that articles should report the listed authors’ own work and ideas. Any contributions made by other sources must be clearly and correctly attributed.  Contributions by artificial intelligence (AI) tools and technologies to a study or to an article’s contents must be clearly reported in a dedicated section of the Methods, or in the Acknowledgements section for article types lacking a Methods section. This section should include the name(s) of any tools used, a description of how the authors used the tool(s) and evaluated the validity of the tool’s outputs, and a clear statement of which aspects of the study, article contents, data, or supporting files were affected/generated by AI tool usage.  In cases where Large Language Model (LLM) AI tools or technologies contribute to generating text content for a PLOS submission, the article’s authors are responsible for ensuring that:  the content is accurate and valid, there are no concerns about potential plagiarism, all relevant sources are cited,  all statements in the article reporting hypotheses, interpretations, results, conclusions, limitations, and implications of the study represent the authors’ own ideas. The use of AI tools and technologies to fabricate or otherwise misrepresent primary research data is unacceptable.  Noncompliance with any aspect of this policy will be considered misrepresentation of methods, contributions, and/or results. If concerns arise about noncompliance with this policy, PLOS may notify the authors’ institution(s) and the journal may reject (pre-publication), retract (post-publication), or publish an editorial notice on the article.
211. Ghostwriting is not permitted by the Journal. Manuscripts are received with the understanding that they have not been written by unacknowledged freelance writers. Guest authorship and “gift" authorship are also prohibited.   Professional writers and medical writers who contribute substantially to the writing or editing of a manuscript should be acknowledged with their permission or credited in the author list. The financial nature of their contract must be disclosed.  The Journal does not consider artificial intelligence authoring tools to meet the requirements for authorship as recommended by the ICMJE. The use of such tools must be included in the article’s Acknowledgements if it has been utilized in any capacity.  Much of PRS's authorship policy is adapted from the article "Authorship and Medical Ghostwriting: Plastic and Reconstructive Surgery Policy" (Plast. Reconstr. Surg. 127: 2496, 2011). Please review this article for more information, definitions, and assistance.
212. Artificial intelligence Use of AI and generative AI software, such as Large Language Models or ChatGPT, for manuscript preparation, including drafting or editing text, must be disclosed in the Materials and Methods section (or Acknowledgments, if no Materials and Methods section is available) of the manuscript and may not be listed as an author. Authors are solely accountable for, and must thoroughly fact-check, outputs created with the help of generative AI software. AI tools for creating images or graphics are not permitted to be used unless the software is the subject of the work under consideration. Accordingly, PNAS Nexus does not allow the use of AI in cover art submissions.  Images No specific feature within an image may be enhanced, obscured, moved, removed, or introduced. The grouping or consolidation of images from multiple sources must be made explicit by the arrangement of the figure and in the figure legend. Adjustments of brightness, contrast, or color balance are acceptable if they are applied to the whole image and if they do not obscure, eliminate, or misrepresent any information present in the original, including backgrounds.  Questions about images raised during image screening will be referred to the editors, who may request the original data from the authors for comparison with the prepared figures. If the original data cannot be produced, the manuscript may be rejected. Cases of deliberate misrepresentation of data will result in rejection of the paper and may be reported to the corresponding author's home institution or funding agency as recommended by COPE. Authors must obtain consent for publication of figures with recognizable human faces.
213. Use of AI and generative AI software, such as Large Language Models or ChatGPT, for manuscript preparation, including drafting or editing text, must be disclosed in the Materials and Methods section (or Acknowledgments, if no Materials and Methods section is available) of the manuscript and may not be listed as an author. Authors are solely accountable for, and must thoroughly fact-check, outputs created with the help of generative AI software. AI tools for creating images or graphics are not permitted to be used unless the software is the subject of the work under consideration. Accordingly, PNAS does not allow the use of AI in cover art submissions.
214. These policies have been introduced to provide clarity as Generative AI and LLM use are on the rise. The policies may change to keep in line with future developments and industry standards as appropriate.  For Authors If a Large Language Model (LLM), or other generative AI-based tool (e.g. chatbots or image creators), has been used as part of a study or manuscript, the use must be clearly declared in the manuscript Methods or Acknowledgements section, if the article type does not include a Methods section. Generative AI tools should not be listed as an author of the work, in line with our Authorship and Contributorship and COPE policy. Any software used must be cited in the References, in line with our software citation policy. Authors are responsible for guaranteeing the accuracy and originality of the content of their manuscript. The manuscript must include detail on how the accuracy of any generative AI-based output was verified. Authors are encouraged to include the original input prompts and outputs from the tools used as supplementary material. Failure to comply with the above will be considered a violation of our Editorial Policies and may result in the rejection of a manuscript or post-publication notice, in line with our policy on Misconduct.  For Peer Reviewers It is not appropriate to input any of the contents of a submission under review to a Large Language Model (LLM) or any machine learning algorithm as this would be a violation of the privacy of peer review.
215. AI Application standard section Authors must include the following criteria in their submission for it to be considered an AI Application article. The placement of these requirements is at the authors' discretion. All code implemented in the article must be uploaded as supplementary files or at a persistent DOI (e.g. GitHub, Zenodo). Introduction Ensure this contains motivations for both the study and the techniques used (machine learning, deep learning, algorithms etc) Materials & Methods Include the name and source (DOI/URL) of any 3rd party datasets you have used. Any dataset which is not original and has been curated and uploaded by an external source is a 3rd party dataset. Describe the data preprocessing steps that were implemented. Explain the selection method for the techniques you have chosen to implement. Details about the computing infrastructure must be provided e.g. operating system, hardware, software etc. The evaluation method and the assessment metrics used to evaluate the proposed techniques must be included. The metrics used must also be justified and explained. Results & Discussion The Results section should present the findings clearly, using figures and tables as appropriate. The Discussion section should interpret the results and compare them with existing research, using the assessment metrics previously detailed to evaluate your model/technique. Conclusions Explain and justify the model type proposed and implemented. Identify limitations in your study and any future directions for your research.
216. Introduction Ubiquity Press is committed to maintaining the integrity of the publication process while adapting to new technologies. This policy covers the use of Generative AI (GenAI) tools in all aspects of the publication process, and applies to authors, reviewers, and editorial teams involved in the publication of scholarly works.  Ubiquity does not currently use bespoke or commercially available GenAI tools as part of the editorial process, but would consider their use in the future providing there were controls in place to protect intellectual property and privacy. In such cases, we would permit the use of such tools in an assistive role for the editorial team. GenAI outcomes can never be fully relied upon and human oversight is always necessary.  Our policy takes into account the key issues surrounding the use of GenAI tools in scholarly publishing:   Accountability: GenAI tools cannot be held accountable for their outputs. Transparency: Users must declare any use of GenAI tools and understand the limitations regarding transparency of these tools. Attribution: AI-generated text often lacks proper attribution and referencing standards. Accuracy and Trustworthiness: GenAI tools may introduce inaccuracies and biases and cannot verify their sources. Their outputs can blur the line between fact and fiction. Copyright, Privacy, and Confidentiality: GenAI tools may not provide adequate confidentiality, data security, or copyright protection. In the case of publicly available GenAI platforms, users should assume there are no controls over any future use of their inputs and responses. (Locally run AI tools do not present the same risks). Guidelines for Authors Authors are permitted to use GenAI in the preparation of their manuscript, according to the following stipulations:  Any use of GenAI beyond basic manuscript refinement (e.g. copyediting, formatting) must be explicitly declared, ideally in the Methods section of the manuscript. Authors must ensure they have the necessary rights to all content uploaded to public GenAI platforms, considering confidentiality and proprietary rights. It should be recognised by the author that any content uploaded into a publicly available GenAI platform could be used in future GenAI outputs for other people. We do not permit GenAI tools to be used to create, alter, or manipulate original research data, including images and measurements. AI tools do not qualify for authorship as it is impossible for them to be held accountable for all aspects of the work. An AI tool should not be included in the author list of a manuscript. (See our full authorship guidelines). Guidelines for Reviewers Reviews should only be undertaken by the appointed reviewer. We do not permit the use of GenAI tools in the creation of a review of a paper, due to the problems of accountability, accuracy and trustworthiness. The responsibilities and tasks involved in reviewing a paper can only be attributed to and performed by the human submitting the review.  Manuscripts under review should never be uploaded to publicly available GenAI services. This would create a risk of violating copyright, privacy, security, and confidentiality obligations. While an author may use publicly available GenAI tools as basic author tools, we discourage their use by reviewers because confidentiality and privacy are more important at the review stage.  If reviewers suspect undisclosed GenAI use by authors, they should report this to the editor handling the manuscript.  Guidelines for Editorial Teams Editorial teams should consider the legitimacy of any declared use of GenAI tools on a case-by-case basis.  Editorial teams should not use publicly available GenAI platforms for integrity checks, such as plagiarism detection, due to confidentiality concerns.  Additional reading STM (2023) Generative AI in Scholarly Communications: Ethical and Practical Guidelines for the Use of Generative AI in the Publication Process. Available from: https://www.stm-assoc.org/wp-content/uploads/STM-GENERATIVE-AI-PAPER-2023.pdf  (2023) “Why Nature will not allow the use of generative AI in images and video”, Nature, 618 (214). DOI: https://doi.org/10.1038/d41586-023-01546-4  COPE (13 February 2023) Authorship and AI tools. Available from: https://publicationethics.org/cope-position-statements/ai-author  EASE (25 September 2024) Recommendations on the Use of AI in Scholarly Communication. Available from: https://ease.org.uk/2024/09/recommendations-on-the-use-of-ai-in-scholarly-communication/
217. Use of Generative Artificial Intelligence in Manuscript Preparation and Peer Review Optica Publishing Group is monitoring the rapid developments and adoption of Large Language Models (LLMs) and Artificial Intelligence (AI) tools in scientific publishing. The following policy statements are provided to guide authors, reviewers, and editors.  Authorship. LLMs and AI tools (including generative AI chatbots) cannot accept the varied responsibilities required of authors (as outlined in the Obligations of Authors in the “Guidelines of the Optica Publishing Group Concerning Ethical Practices in the Publication of Research”) and therefore cannot be listed as authors on papers.   Text and Image Integrity. Use of LLMs and AI tools to generate text is not permitted but can be used to enhance and edit original text. Their use to generate figures, images, media, or code must be properly documented in the paper upon submission and must include the type of tool used (including the name, version, model, source) and a description of when and how the tool was used. Generative AI tools cannot be used to create, alter, or manipulate original research data and results such as plots or measurements. Any generative AI tools used to create figures from data, such as graphs or charts, should be listed in the figure caption.  The use of non-generative machine learning tools to manipulate, combine, or enhance existing text, images or figures should be properly documented in the relevant section of the manuscript upon submission.  Authors are responsible for reviewing and appropriately acknowledging content produced by these tools. As a condition of authorship, authors certify that all materials in the paper, including those produced by these tools, are accurate, because AI tools can generate authoritative-sounding output that can be incorrect, incomplete, or biased. Editors may decline to move forward with manuscripts if AI is used inappropriately.  Authors may use generative AI tools and AI-assisted technologies for editing and grammar improvement of their writing without disclosure. Authors should carefully review the results of such AI support.  AI Use by Reviewers and Editors. To protect the confidentiality of peer-reviewed materials, referees and editors should not upload the contents of submitted manuscripts, peer review reports, or decision letters into external AI-assistance tools, even if it is for the purpose of improving language and readability.
218. As Editor-in-Chief Emeritus Alan Jette commented in a 2023 editorial, “Artificial intelligence (AI) technologies are not new to scientific publishing. AI tools have long been available to assist authors with writing, grammar, language, references, statistical analysis, and reporting standards.” PTJ’s current AI policy is as follows:  PTJ does not allow AI technology to serve as an author on submitted work, primarily because AI tools cannot meet the authorship requirements of taking responsibility for the submitted work, asserting the presence or absence of conflicts of interest, or managing copyright and license agreements. PTJ authors are required to disclose any and all applications of AI, including language models, machine learning, or similar technologies that are used to create content, help write code, analyze data, or assist with the writing or editing of manuscripts. Such AI input should be documented in an article’s acknowledgment section or—if the AI was used in the study’s research design or methods—in the manuscript’s Methods section. Except for the use of basic tools for checking grammar, spelling, or references, authors should include a description of the content that was created or edited and the name of the language model or tool and manufacturer. Importantly, authors of manuscripts submitted to PTJ continue to be responsible for the accuracy and integrity of all the content in their manuscript, including that which was developed or edited by an AI technology. Authors continue to be liable for any breach of publication ethics, including parts that are developed by an AI tool.
219. The below guidance only refers to the writing process, and not to the use of AI tools to analyze and draw insights from data as part of the research process.  Where authors use generative artificial intelligence (AI) and AI-assisted technologies in the writing process, authors should only use these technologies to improve readability and language. Applying the technology should be done with human oversight and control, and authors should carefully review and edit the result, as AI can generate authoritative-sounding output that can be incorrect, incomplete or biased. AI and AI-assisted technologies should not be listed as an author or co-author, or be cited as an author. Authorship implies responsibilities and tasks that can only be attributed to and performed by humans, as outlined in AI policy for authors .  Authors should disclose in their manuscript the use of AI and AI-assisted technologies in the writing process by following the instructions below. A statement will appear in the published work. Please note that authors are ultimately responsible and accountable for the contents of the work.  Disclosure instructions Authors must disclose the use of generative AI and AI-assisted technologies in the writing process by adding a statement at the end of their manuscript in the core manuscript file, before the References list. The statement should be placed in a new section entitled ‘Statement on the use of artificial intelligence’.  Statement: During the preparation of this work the author(s) used [NAME TOOL / SERVICE] in order to [REASON]. After using this tool/service, the author(s) reviewed and edited the content as needed and take(s) full responsibility for the content of the publication.  This declaration does not apply to the use of basic tools for checking grammar, spelling, references etc.  Use of AI for data analysis in research The authors have used AI to analyze and extract knowledge from the data as part of the research process, this should be stated in the corresponding section. In addition, the type of tool and the way in which it has been used to make the results reproducible should be indicated in the "Methods" section.
220. Guidelines for Use of Large Language Models AI or AI-assisted technologies do not qualify as authors and must not be listed as authors or co-authors. Nonhuman AI, LLMs, chatbots, machine learning, or similar generative AI technologies do not meet the four ICMJE criteria for authorship. These qualifications were developed to guarantee that all authors accept full responsibility and stand for the integrity of the entire work. Accordingly, only humans can be authors. AI-assisted technologies should be reported in the article as methodological devices used in the completion of the work, but not included as authors. At submission, authors must disclose whether they used AI or AI-assisted technologies in the preparation of the manuscript. Authors who use such technology must clearly describe, in both the cover letter and the manuscript, how AI or AI-assisted technologies (LLMs, chatbots, such as ChatGPT or Bard, and image creators) were used in the study and/or manuscript preparation. Authors should be transparent when AI-assisted technologies are used and provide information about their use. Authors may provide this information in the Materials and Methods section or in the Acknowledgments section or a relevant section of the manuscript (e.g., figure legends for AI-generated figures), Authors should include specific details, such as the name and version of the AI tool, date of access, name of the manufacturer/creator. Authors may use LLMs to assist with medical writing and for content editing to effectively communicate their work. These tasks include assistance with medical writing, grammar, language and reporting standards. Authors must transparently report how they used such tools in the writing or editing of their submitted work, both in the cover letter and in the Methods section or the Acknowledgment section. Authors should include specific details, such as the name of the language model or tool, version number, and manufacturer. All authors are responsible for any submitted material that includes AI-assisted technologies. AI-assisted technologies cannot distinguish between true and false information. Therefore, authors should carefully review and edit the results of AI-assisted content, because AI can generate authoritative-sounding output that can be biased, incomplete, or partially or completely incorrect. Authors should be able to assert that there is no plagiarism in their paper, including in text and images produced by AI. Humans must ensure appropriate attribution to all quoted material, including full citations. Authors should acknowledge all sources (including material produced by the chatbot). Authorship attribution requires accountability for the submitted work. Further, authors are responsible for any text generated by a chatbot in their manuscript (including the accuracy of what is presented and the absence of plagiarism) and for acknowledging all sources (including material produced by the chatbot) and ensuring the accuracy and completeness of citations. ICMJE updated the ‘Manuscript Preparation and Submission’ section to state that ‘referencing AI-generated material as the primary source is not acceptable’. The submission and publication of content/images created by AI, language models, machine learning, or similar technologies is discouraged, unless part of formal research design or methods, and is not permitted without clear description of the content that was created and the name of the model or tool, version and extension numbers, and manufacturer. Authors must take responsibility for the integrity of the content generated by these models and tools. When generative AI itself is the focus of a study, the use of AI should be explicitly detailed. The ICMJE and WAME guidelines states that reviewers should not upload the manuscript to software or other AI technologies where confidentiality cannot be assured. Reviewers are trusted and required to maintain confidentiality throughout the manuscript review process. 
221. La ética en la redacción científica es un tema crucial para la comunidad científica y para la sociedad en general. La redacción científica es una actividad que involucra la creación y difusión de conocimiento, y por lo tanto, debe ser llevada a cabo con integridad y transparencia. La Inteligencia Artificial (IA) es una herramienta que se está utilizando cada vez más en la investigación científica, y por lo tanto, su uso también debe ser guiado por principios éticos.  Cuando se trata de la utilización de la IA en la redacción científica, es importante que los investigadores sean transparentes sobre cómo se está utilizando la tecnología y cómo se están interpretando los resultados. Los algoritmos de la IA pueden ser útiles para procesar grandes cantidades de datos y para identificar patrones y tendencias, pero también pueden llevar a errores si no se utilizan adecuadamente. Los investigadores deben ser claros acerca de cómo se están utilizando los algoritmos y cómo se están interpretando los resultados, y deben asegurarse de que cualquier automatización no perjudique la integridad de la investigación.  
222. Artificial Intelligence and Authorship  Thieme aligns itself with the COPE Position Statement on Artificial Intelligence (AI) and Authorship.  Generative artificial intelligence (GenAI) tools must not be listed as authors, as they do not fulfil all criteria for authorship. They cannot take responsibility for the integrity and the content of a paper, and they cannot take on legal responsibility.  Instead, GenAI use must be transparently documented in the Acknowledgements or Material and Methods sections (see Disclosure and Transparency paragraph). 
223. SIAM Authors SIAM authors must adhere to the following rules on the use of artificial intelligence and large language models (LLMs), such as ChatGPT –  Listed authors must be human beings, rather than AI tools, as authors must be able to be accountable for the work, disclose conflicts of interest, as well as hold and assign copyright.  Every co-author assumes full responsibility for the integrity, accuracy, originality, and copyright of any submitted content. This includes the abstracts/summaries of the work, discussions of related work, theorems and proofs, algorithm statements, computational implementations, and analysis/discussion/presentation of numerical experiments.  Authors are permitted to use AI tools to edit or polish the authors’ written text for spelling, grammar, or general style, with a simple acknowledgement in the Acknowledgements section of the work.  Any other use of artificial intelligence, LLMs, or similar technologies must be fully documented in the Acknowledgements section of the submitted work, with As many details of the specific model/tool and version used as available, e.g., Tool = GPT-4, Date used: Sept 1, 2023 the exact method used, e.g. The following prompt was entered into GPT-4… the specific content changed or generated by AI, including text, citations, images, figures, videos, or similar, e.g. The following text was entirely generated by GPT-4 and included in the article… where possible, the code or data that a reader needs to reproduce the results  The SIAM journal or book editor(s) has final decision on whether the use of the AI tool is appropriate or permitted  Egregious misrepresentations, including those due to use of AI in the writing or analysis, will lead to an investigation and may have consequences including rejection of the submission, limits on future submissions to SIAM publications, notification of the authors’ institutions, and addendum to or retraction of an already published article. SIAM Referees SIAM referees are not permitted to upload papers under review to ChatGPT or similar LLM models as this compromises the confidentiality of material provided by the author during the peer review process.  Note: This policy will be kept under regular review and changed as necessary in light of further technological developments in this area.
224. All authors listed on the manuscript should have contributed significantly to the design or implementation of the experiment or the analysis and interpretation of the data. Any other individuals who contributed to the experiment or the writing of the manuscript should be listed in the Acknowledgment section. During online submission, the corresponding author must certify on behalf of all authors have read and approved the submitted version.  Natural language processing tools driven by artificial intelligence (AI) do not qualify as authors, and the Journal will screen for them in author lists. The use of AI (for example, to help generate content, write code, or process data) should be disclosed both in cover letters to editors and in the Methods or Acknowledgements section of manuscripts. Please see the COPE position statement on Authorship and AI for more details.
225. (1) Any AI and AI-assisted technologies, such as ChatGPT, should not be used to replace key research and should not be listed as an author or co-author.  (2) When creating content, the use of AI technologies or AI-related tools should be clearly noted in the Methods section or in Acknowledgements.  (3) Manuscripts with AI technologies as an author or co-author should not be cited as a reference. If citing is necessary, a detailed discussion should be presented.
226. Mary Ann Liebert, publishers, Inc. understands that emerging computing methodologies and tools are critical parts of advancing research. The policies below will be reviewed and updated as technologies, best practices and ethical considerations in AI evolve.
227. Authors must disclose whether they used artificial intelligence (AI)-assisted technologies (such as Large Language Models [LLMs], chatbots, or image creators) in the production of submitted work. Authors who use such technology should describe, in both the cover letter and the submitted work, how they used it. Chatbots (such as ChatGPT) should not be listed as authors because they cannot be responsible for the accuracy, integrity, and originality of the work. Authors must carefully review and edit the result because AI can generate authoritative-sounding output that can be incorrect, incomplete, or biased. Authors should not list AI and AI-assisted technologies as an author or co-author, nor cite AI as an author. Authors must assert that there is no plagiarism in their paper, including in text and images produced by the AI. Authors must ensure there is appropriate attribution of all quoted material, including full citations. If you used generative AI or AI-assisted technology, include the following statement at the end of your manuscript before the references:  Declaration of generative AI and AI-assisted technologies in the writing process  During the preparation of this work the author(s) used [NAME TOOL / SERVICE] in order to [REASON]. After using this tool/service, the author(s) reviewed and edited the content as needed and take(s) full responsibility for the content of the publication.
228. SciOpen follows the COPE position statement when it comes to the use of Artificial Intelligence (AI) and AI-assisted technology in manuscript preparation. TUP is a member of STM, so we also encourage journals on SciOpen follow the Ethical and Practical Guidelines released by STM Generative AI in Scholarly Communications.  Authors should not list AI and AI-assisted technologies as an author or co-author, nor cite AI as an author. TUP will monitor this development and will adjust or refine this policy when appropriate.  Authors should disclose the use of AI and AI-assisted technologies with sufficient details at submission via the cover letter. Authors should carefully review and edit the AI generative materials, and be responsible for any submitted materials containing AI technologies. Furthermore, authors should declare the use of these tools or technology and disclose details of how the AI tool was used within Method, Acknowledgement or other related sections.
229. (Addition 22 March 2023) Artificial Intelligence (AI) does not qualify for the role of author (see above) and should not be listed as such. If AI was used in the research or preparation of the paper, this should be declared and explained in the description of the tools or methods used. Any requirements concerning copyright and plagiarism continue to apply.
230. Neither symbolic figures such as Camille Noûs nor natural language processing tools driven by artificial intelligence (AI) such as ChatGPT qualify as authors, and OUP will screen for them in author lists. The use of AI (for example, to help generate content, write code, or analyze data) must be disclosed both in cover letters to editors and in the Methods or Acknowledgements section of manuscripts.
231. ISPOR encourages responsible use of artificial intelligence (AI) or AI-assisted technologies. Responsible use includes disclosing whether AI was used to produce submitted work(s), and if so, how it was used. Declaring the use of these technologies supports transparency between authors, readers, reviewers, editors, and contributors and may facilitate compliance with the terms of use of the relevant tool or technology.  ISPOR's complete AI policy is available here: https://www.ispor.org/ai-policy. To view Elsevier's AI policy, please go to https://www.elsevier.com/about/policies-and-standards/generative-ai-policies-for-journals.
232. IWA Publishing allows the use of AI tools used within a manuscript but does not allow for AI-generated content to be used in the place of human authorship:  Authors will be held liable for any errors, potential plagiarism or inconsistencies introduced by AI tools. Authorship must be verifiable, which is not possible from an AI tool or content generator. If AI tools are used in an article submitted to IWA Publishing, their use must be clearly explained within the methodology section. If AI-generated content is included within a manuscript without explanation, this will be grounds for rejection of the work at the discretion of the Editorial Board.   
233. The below guidance only refers to the writing process, and not to the use of AI tools to analyse and draw insights from data as part of the research process.  Where authors use generative artificial intelligence (AI) and AI-assisted technologies in the writing process, authors should only use these technologies to improve readability and language. Applying the technology should be done with human oversight and control, and authors should carefully review and edit the result, as AI can generate authoritative-sounding output that can be incorrect, incomplete or biased. AI and AI-assisted technologies should not be listed as an author or co-author, or be cited as an author. Authorship implies responsibilities and tasks that can only be attributed to and performed by humans, as outlined in Elsevier's AI policy for authors.  Authors should disclose in their manuscript the use of AI and AI-assisted technologies in the writing process by following the instructions below. A statement will appear in the published work. Please note that authors are ultimately responsible and accountable for the contents of the work.  Disclosure instructions  Authors must disclose the use of generative AI and AI-assisted technologies in the writing process by adding a statement at the end of their manuscript in the core manuscript file, before the References list. The statement should be placed in a new section entitled 'Declaration of Generative AI and AI-assisted technologies in the writing process'  Statement: During the preparation of this work the author(s) used [NAME TOOL / SERVICE] in order to [REASON]. After using this tool/service, the author(s) reviewed and edited the content as needed and take(s) full responsibility for the content of the publication  This declaration does not apply to the use of basic tools for checking grammar, spelling, references etc. If there is nothing to disclose, there is no need to add a statement.  Use of inclusive language Inclusive language acknowledges diversity, conveys respect to all people, is sensitive to differences, and promotes equal opportunities. Articles should make no assumptions about the beliefs or commitments of any reader, should contain nothing which might imply that one individual is superior to another on the grounds of race, sex, culture or any other characteristic, and should use inclusive language throughout. Authors should ensure that writing is free from bias, for instance by using 'he or she', 'his/her' instead of 'he' or 'his', and by making use of job titles that are free of stereotyping (e.g. 'chairperson' instead of 'chairman' and 'flight attendant' instead of 'stewardess').  Women and Birth requires that authors use woman centred language including referring to births rather than deliveries, to give birth rather than deliver and women rather than patients. Papers that do not adhere to these guidelines will not proceed to peer review.  Our journal uses UK spelling, for example, recognise rather than recognize. We also spell fetal rather than foetal.
